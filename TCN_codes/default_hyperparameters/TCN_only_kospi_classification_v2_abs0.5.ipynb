{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tcn in /home/work/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (1.21.1)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (0.16.1)\n",
      "Requirement already satisfied: tensorflow in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (14.0.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (22.12.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (4.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.29.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (63.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.35.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: finance-datareader in /home/work/.local/lib/python3.8/site-packages (0.9.50)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.64.0)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.2)\n",
      "Requirement already satisfied: requests-file in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (2.27.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from requests-file->finance-datareader) (1.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn\n",
    "!pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ffe65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-01-25 02:24:46.556309: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 02:24:46.712271: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-25 02:24:50.173357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-25 02:24:50.173553: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-25 02:24:50.173575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452f7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1996-12-11    704.679993\n",
      "1996-12-12    689.380005\n",
      "1996-12-13    689.070007\n",
      "1996-12-16    673.919983\n",
      "1996-12-17    663.349976\n",
      "Name: Close, dtype: float64\n",
      "Date\n",
      "1996-12-11     704.679993\n",
      "1996-12-12     689.380005\n",
      "1996-12-13     689.070007\n",
      "1996-12-16     673.919983\n",
      "1996-12-17     663.349976\n",
      "                 ...     \n",
      "2017-12-21    2429.830078\n",
      "2017-12-22    2440.540039\n",
      "2017-12-26    2427.340088\n",
      "2017-12-27    2436.669922\n",
      "2017-12-28    2467.489990\n",
      "Name: Close, Length: 5341, dtype: float64\n",
      "(5341,)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "kospi_train = fdr.DataReader('KS11', '1990-01-01','2017-12-31')['Close']\n",
    "print(kospi_train.head())\n",
    "print(kospi_train)\n",
    "print(kospi_train.shape)\n",
    "print(kospi_train.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c18820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2018-01-02    2479.649902\n",
      "2018-01-03    2486.350098\n",
      "2018-01-04    2466.459961\n",
      "2018-01-05    2497.520020\n",
      "2018-01-08    2513.280029\n",
      "                 ...     \n",
      "2023-01-17    2379.389893\n",
      "2023-01-18    2368.320068\n",
      "2023-01-19    2380.340088\n",
      "2023-01-20    2395.260010\n",
      "2023-01-25    2428.360107\n",
      "Name: Close, Length: 1246, dtype: float64\n",
      "(1246,)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "kospi_test = fdr.DataReader('KS11', '2018-01-01')['Close']\n",
    "print(kospi_test)\n",
    "print(kospi_test.shape)\n",
    "print(kospi_test.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48c0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1996-12-11     704.679993\n",
      "1996-12-12     689.380005\n",
      "1996-12-13     689.070007\n",
      "1996-12-16     673.919983\n",
      "1996-12-17     663.349976\n",
      "                 ...     \n",
      "2017-12-21    2429.830078\n",
      "2017-12-22    2440.540039\n",
      "2017-12-26    2427.340088\n",
      "2017-12-27    2436.669922\n",
      "2017-12-28    2467.489990\n",
      "Name: Close, Length: 5192, dtype: float64\n",
      "False\n",
      "Date\n",
      "2018-01-02    2479.649902\n",
      "2018-01-03    2486.350098\n",
      "2018-01-04    2466.459961\n",
      "2018-01-05    2497.520020\n",
      "2018-01-08    2513.280029\n",
      "                 ...     \n",
      "2023-01-17    2379.389893\n",
      "2023-01-18    2368.320068\n",
      "2023-01-19    2380.340088\n",
      "2023-01-20    2395.260010\n",
      "2023-01-25    2428.360107\n",
      "Name: Close, Length: 1246, dtype: float64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "kospi_train = kospi_train.dropna()\n",
    "kospi_test = kospi_test.dropna()\n",
    "\n",
    "print(kospi_train)\n",
    "print(kospi_train.isnull().any())\n",
    "print(kospi_test)\n",
    "print(kospi_test.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8396c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kospi_train = kospi_train.values\n",
    "kospi_test = kospi_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1334a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_window = 60\n",
    "x_train_1, y_train_1 = [], []\n",
    "x_train_7, y_train_7 = [], []\n",
    "x_train_15, y_train_15 = [], []\n",
    "x_train_30, y_train_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ad8662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_train)-1):\n",
    "    x_train_1.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_1.append(kospi_train[i] - kospi_train[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train)-6):\n",
    "    x_train_7.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_7.append(kospi_train[i+6] - kospi_train[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train)-14):\n",
    "    x_train_15.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_15.append(kospi_train[i+14] - kospi_train[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train)-29):\n",
    "    x_train_30.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_30.append(kospi_train[i+29] - kospi_train[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02aedcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_train_1)):\n",
    "    if y_train_1[index]>= -0.5 and y_train_1[index] < 0.5:\n",
    "        y_train_1[index] = 'neutral'\n",
    "    elif y_train_1[index] >= 0.5:\n",
    "        y_train_1[index] = 'increase'\n",
    "    else:\n",
    "        y_train_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_train_7)):\n",
    "    if y_train_7[index]>= -0.5 and y_train_7[index] < 0.5:\n",
    "        y_train_7[index] = 'neutral'\n",
    "    elif y_train_7[index] >= 0.5:\n",
    "        y_train_7[index] = 'increase'\n",
    "    else:\n",
    "        y_train_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_15)):\n",
    "    if y_train_15[index]>= -0.5 and y_train_15[index] < 0.5:\n",
    "        y_train_15[index] = 'neutral'\n",
    "    elif y_train_15[index] >= 0.5:\n",
    "        y_train_15[index] = 'increase'\n",
    "    else:\n",
    "        y_train_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_30)):\n",
    "    if y_train_30[index]>= -0.5 and y_train_30[index] < 0.5:\n",
    "        y_train_30[index] = 'neutral'\n",
    "    elif y_train_30[index] >= 0.5:\n",
    "        y_train_30[index] = 'increase'\n",
    "    else:\n",
    "        y_train_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5ef8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5131, 60, 1) (5126, 60, 1) (5118, 60, 1) (5103, 60, 1)\n",
      "(5131,) (5126,) (5118,) (5103,)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(x_train_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "x_train_1 = x_train_1.reshape((5131, -1, 1))\n",
    "#y_train_1 = y_train_1.reshape((-1, 1))\n",
    "\n",
    "x_train_7 = np.array(x_train_7)\n",
    "y_train_7 = np.array(y_train_7)\n",
    "x_train_7 = x_train_7.reshape((5126, -1, 1))\n",
    "#y_train_7 = y_train_7.reshape((-1, 1))\n",
    "\n",
    "x_train_15 = np.array(x_train_15)\n",
    "y_train_15 = np.array(y_train_15)\n",
    "x_train_15 = x_train_15.reshape((5118, -1, 1))\n",
    "#y_train_15 = y_train_15.reshape((-1, 1))\n",
    "\n",
    "x_train_30 = np.array(x_train_30)\n",
    "y_train_30 = np.array(y_train_30)\n",
    "x_train_30 = x_train_30.reshape((5103, -1, 1))\n",
    "#y_train_30 = y_train_30.reshape((-1, 1))\n",
    "\n",
    "print(x_train_1.shape, x_train_7.shape, x_train_15.shape, x_train_30.shape)\n",
    "print(y_train_1.shape, y_train_7.shape, y_train_15.shape, y_train_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "612667a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1, y_test_1 = [], []\n",
    "x_test_7, y_test_7 = [], []\n",
    "x_test_15, y_test_15 = [], []\n",
    "x_test_30, y_test_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c77c5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_test)):\n",
    "    x_test_1.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_1.append(kospi_test[i] - kospi_test[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test)-6):\n",
    "    x_test_7.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_7.append(kospi_test[i+6] - kospi_test[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test)-14):\n",
    "    x_test_15.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_15.append(kospi_test[i+14] - kospi_test[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test)-29):\n",
    "    x_test_30.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_30.append(kospi_test[i+29] - kospi_test[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb64b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_test_1)):\n",
    "    if y_test_1[index]>= -0.5 and y_test_1[index] < 0.5:\n",
    "        y_test_1[index] = 'neutral'\n",
    "    elif y_test_1[index] >= 0.5:\n",
    "        y_test_1[index] = 'increase'\n",
    "    else:\n",
    "        y_test_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_test_7)):\n",
    "    if y_test_7[index]>= -0.5 and y_test_7[index] < 0.5:\n",
    "        y_test_7[index] = 'neutral'\n",
    "    elif y_test_7[index] >= 0.5:\n",
    "        y_test_7[index] = 'increase'\n",
    "    else:\n",
    "        y_test_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_15)):\n",
    "    if y_test_15[index]>= -0.5 and y_test_15[index] < 0.5:\n",
    "        y_test_15[index] = 'neutral'\n",
    "    elif y_test_15[index] >= 0.5:\n",
    "        y_test_15[index] = 'increase'\n",
    "    else:\n",
    "        y_test_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_30)):\n",
    "    if y_test_30[index]>= -0.5 and y_test_30[index] < 0.5:\n",
    "        y_test_30[index] = 'neutral'\n",
    "    elif y_test_30[index] >= 0.5:\n",
    "        y_test_30[index] = 'increase'\n",
    "    else:\n",
    "        y_test_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d9be8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = np.array(x_test_1)\n",
    "y_test_1 = np.array(y_test_1)\n",
    "x_test_1 = x_test_1.reshape((1186, -1, 1))\n",
    "#y_test_1 = y_test_1.reshape((-1, 1))\n",
    "\n",
    "x_test_7 = np.array(x_test_7)\n",
    "y_test_7 = np.array(y_test_7)\n",
    "x_test_7 = x_test_7.reshape((1180, -1, 1))\n",
    "#y_test_7 = y_test_7.reshape((-1, 1))\n",
    "\n",
    "x_test_15 = np.array(x_test_15)\n",
    "y_test_15 = np.array(y_test_15)\n",
    "x_test_15 = x_test_15.reshape((1172, -1, 1))\n",
    "#y_test_15 = y_test_15.reshape((-1, 1))\n",
    "\n",
    "x_test_30 = np.array(x_test_30)\n",
    "y_test_30 = np.array(y_test_30)\n",
    "x_test_30 = x_test_30.reshape((1157, -1, 1))\n",
    "#y_test_30 = y_test_30.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c3afe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1186, 60, 1) (1180, 60, 1) (1172, 60, 1) (1157, 60, 1)\n",
      "(1186,) (1180,) (1172,) (1157,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_1.shape, x_test_7.shape, x_test_15.shape, x_test_30.shape)\n",
    "print(y_test_1.shape, y_test_7.shape, y_test_15.shape, y_test_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cd5460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_1)\n",
    "\n",
    "y_train_1_e = to_categorical(encoder.transform(y_train_1))\n",
    "y_train_7_e = to_categorical(encoder.transform(y_train_7))\n",
    "y_train_15_e = to_categorical(encoder.transform(y_train_15))\n",
    "y_train_30_e = to_categorical(encoder.transform(y_train_30))\n",
    "\n",
    "y_test_1_e = to_categorical(encoder.transform(y_test_1))\n",
    "y_test_7_e = to_categorical(encoder.transform(y_test_7))\n",
    "y_test_15_e = to_categorical(encoder.transform(y_test_15))\n",
    "y_test_30_e = to_categorical(encoder.transform(y_test_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8cb8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 03:03:38.754817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-25 03:03:38.754909: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-25 03:03:38.754961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-01-25 03:03:38.755779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 64)                91136     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_1 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_2 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_3 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_7 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_7.summary()\n",
    "model_7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_15 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_15.summary()\n",
    "model_15.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_30 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_30.summary()\n",
    "model_30.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac14f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/100\n",
      "161/161 - 6s - loss: 1082.1036 - accuracy: 0.4726 - 6s/epoch - 36ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 3s - loss: 252.8105 - accuracy: 0.4732 - 3s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 3s - loss: 197.5741 - accuracy: 0.4681 - 3s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 3s - loss: 152.8845 - accuracy: 0.4683 - 3s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 3s - loss: 123.6322 - accuracy: 0.4761 - 3s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 3s - loss: 143.0998 - accuracy: 0.4925 - 3s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 3s - loss: 92.1990 - accuracy: 0.4800 - 3s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 3s - loss: 87.0174 - accuracy: 0.4777 - 3s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 3s - loss: 68.8598 - accuracy: 0.4611 - 3s/epoch - 18ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 3s - loss: 71.0317 - accuracy: 0.4654 - 3s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "161/161 - 3s - loss: 76.1801 - accuracy: 0.4752 - 3s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "161/161 - 3s - loss: 77.5754 - accuracy: 0.4697 - 3s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "161/161 - 3s - loss: 67.9781 - accuracy: 0.4656 - 3s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "161/161 - 3s - loss: 64.0241 - accuracy: 0.4594 - 3s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "161/161 - 3s - loss: 54.1501 - accuracy: 0.4703 - 3s/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "161/161 - 3s - loss: 42.4532 - accuracy: 0.4896 - 3s/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "161/161 - 3s - loss: 41.9354 - accuracy: 0.4790 - 3s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "161/161 - 3s - loss: 44.2906 - accuracy: 0.4609 - 3s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "161/161 - 3s - loss: 52.3009 - accuracy: 0.4742 - 3s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "161/161 - 3s - loss: 47.8236 - accuracy: 0.4695 - 3s/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "161/161 - 3s - loss: 53.8955 - accuracy: 0.4796 - 3s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "161/161 - 3s - loss: 43.5615 - accuracy: 0.4658 - 3s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "161/161 - 3s - loss: 49.6635 - accuracy: 0.4728 - 3s/epoch - 19ms/step\n",
      "Epoch 24/100\n",
      "161/161 - 3s - loss: 52.0242 - accuracy: 0.4714 - 3s/epoch - 19ms/step\n",
      "Epoch 25/100\n",
      "161/161 - 3s - loss: 44.8849 - accuracy: 0.4681 - 3s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "161/161 - 3s - loss: 33.4567 - accuracy: 0.4765 - 3s/epoch - 19ms/step\n",
      "Epoch 27/100\n",
      "161/161 - 3s - loss: 35.8115 - accuracy: 0.4724 - 3s/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "161/161 - 3s - loss: 57.6120 - accuracy: 0.4746 - 3s/epoch - 18ms/step\n",
      "Epoch 29/100\n",
      "161/161 - 3s - loss: 34.3325 - accuracy: 0.4703 - 3s/epoch - 19ms/step\n",
      "Epoch 30/100\n",
      "161/161 - 3s - loss: 30.2072 - accuracy: 0.4853 - 3s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "161/161 - 3s - loss: 36.1224 - accuracy: 0.4707 - 3s/epoch - 19ms/step\n",
      "Epoch 32/100\n",
      "161/161 - 3s - loss: 49.3662 - accuracy: 0.4681 - 3s/epoch - 19ms/step\n",
      "Epoch 33/100\n",
      "161/161 - 3s - loss: 30.2870 - accuracy: 0.4767 - 3s/epoch - 19ms/step\n",
      "Epoch 34/100\n",
      "161/161 - 3s - loss: 46.6885 - accuracy: 0.4685 - 3s/epoch - 19ms/step\n",
      "Epoch 35/100\n",
      "161/161 - 3s - loss: 33.3713 - accuracy: 0.4652 - 3s/epoch - 19ms/step\n",
      "Epoch 36/100\n",
      "161/161 - 3s - loss: 34.2292 - accuracy: 0.4683 - 3s/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "161/161 - 3s - loss: 26.3212 - accuracy: 0.4672 - 3s/epoch - 19ms/step\n",
      "Epoch 38/100\n",
      "161/161 - 3s - loss: 26.9152 - accuracy: 0.4820 - 3s/epoch - 19ms/step\n",
      "Epoch 39/100\n",
      "161/161 - 3s - loss: 26.3320 - accuracy: 0.4753 - 3s/epoch - 19ms/step\n",
      "Epoch 40/100\n",
      "161/161 - 3s - loss: 43.7831 - accuracy: 0.4674 - 3s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "161/161 - 3s - loss: 29.1387 - accuracy: 0.4769 - 3s/epoch - 19ms/step\n",
      "Epoch 42/100\n",
      "161/161 - 3s - loss: 21.3541 - accuracy: 0.4701 - 3s/epoch - 19ms/step\n",
      "Epoch 43/100\n",
      "161/161 - 3s - loss: 34.6000 - accuracy: 0.4586 - 3s/epoch - 19ms/step\n",
      "Epoch 44/100\n",
      "161/161 - 3s - loss: 29.3199 - accuracy: 0.4635 - 3s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "161/161 - 3s - loss: 25.7206 - accuracy: 0.4798 - 3s/epoch - 19ms/step\n",
      "Epoch 46/100\n",
      "161/161 - 3s - loss: 20.2433 - accuracy: 0.4779 - 3s/epoch - 19ms/step\n",
      "Epoch 47/100\n",
      "161/161 - 3s - loss: 21.3510 - accuracy: 0.4695 - 3s/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "161/161 - 3s - loss: 34.6132 - accuracy: 0.4668 - 3s/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "161/161 - 3s - loss: 22.6908 - accuracy: 0.4820 - 3s/epoch - 19ms/step\n",
      "Epoch 50/100\n",
      "161/161 - 3s - loss: 20.5113 - accuracy: 0.4662 - 3s/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "161/161 - 3s - loss: 18.5189 - accuracy: 0.4664 - 3s/epoch - 19ms/step\n",
      "Epoch 52/100\n",
      "161/161 - 3s - loss: 18.8375 - accuracy: 0.4707 - 3s/epoch - 19ms/step\n",
      "Epoch 53/100\n",
      "161/161 - 3s - loss: 18.1757 - accuracy: 0.4701 - 3s/epoch - 19ms/step\n",
      "Epoch 54/100\n",
      "161/161 - 3s - loss: 21.7860 - accuracy: 0.4769 - 3s/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "161/161 - 3s - loss: 23.2994 - accuracy: 0.4736 - 3s/epoch - 19ms/step\n",
      "Epoch 56/100\n",
      "161/161 - 3s - loss: 23.7281 - accuracy: 0.4677 - 3s/epoch - 19ms/step\n",
      "Epoch 57/100\n",
      "161/161 - 3s - loss: 21.2382 - accuracy: 0.4771 - 3s/epoch - 19ms/step\n",
      "Epoch 58/100\n",
      "161/161 - 3s - loss: 25.1249 - accuracy: 0.4761 - 3s/epoch - 19ms/step\n",
      "Epoch 59/100\n",
      "161/161 - 3s - loss: 21.3580 - accuracy: 0.4726 - 3s/epoch - 19ms/step\n",
      "Epoch 60/100\n",
      "161/161 - 3s - loss: 20.1444 - accuracy: 0.4670 - 3s/epoch - 19ms/step\n",
      "Epoch 61/100\n",
      "161/161 - 3s - loss: 22.3277 - accuracy: 0.4808 - 3s/epoch - 19ms/step\n",
      "Epoch 62/100\n",
      "161/161 - 3s - loss: 13.5382 - accuracy: 0.4767 - 3s/epoch - 19ms/step\n",
      "Epoch 63/100\n",
      "161/161 - 3s - loss: 24.5322 - accuracy: 0.4796 - 3s/epoch - 19ms/step\n",
      "Epoch 64/100\n",
      "161/161 - 3s - loss: 20.9274 - accuracy: 0.4775 - 3s/epoch - 19ms/step\n",
      "Epoch 65/100\n",
      "161/161 - 3s - loss: 25.8189 - accuracy: 0.4775 - 3s/epoch - 19ms/step\n",
      "Epoch 66/100\n",
      "161/161 - 3s - loss: 13.4960 - accuracy: 0.4824 - 3s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "161/161 - 3s - loss: 18.7872 - accuracy: 0.4644 - 3s/epoch - 19ms/step\n",
      "Epoch 68/100\n",
      "161/161 - 3s - loss: 18.0199 - accuracy: 0.4648 - 3s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "161/161 - 3s - loss: 19.0935 - accuracy: 0.4714 - 3s/epoch - 19ms/step\n",
      "Epoch 70/100\n",
      "161/161 - 3s - loss: 20.5561 - accuracy: 0.4633 - 3s/epoch - 19ms/step\n",
      "Epoch 71/100\n",
      "161/161 - 3s - loss: 15.5186 - accuracy: 0.4685 - 3s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "161/161 - 3s - loss: 19.5263 - accuracy: 0.4789 - 3s/epoch - 19ms/step\n",
      "Epoch 73/100\n",
      "161/161 - 3s - loss: 21.6652 - accuracy: 0.4722 - 3s/epoch - 18ms/step\n",
      "Epoch 74/100\n",
      "161/161 - 3s - loss: 13.4903 - accuracy: 0.4718 - 3s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "161/161 - 3s - loss: 17.7923 - accuracy: 0.4769 - 3s/epoch - 19ms/step\n",
      "Epoch 76/100\n",
      "161/161 - 3s - loss: 21.8174 - accuracy: 0.4676 - 3s/epoch - 19ms/step\n",
      "Epoch 77/100\n",
      "161/161 - 3s - loss: 12.7889 - accuracy: 0.4796 - 3s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "161/161 - 3s - loss: 11.2441 - accuracy: 0.4787 - 3s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "161/161 - 3s - loss: 13.2436 - accuracy: 0.4666 - 3s/epoch - 19ms/step\n",
      "Epoch 80/100\n",
      "161/161 - 3s - loss: 18.1904 - accuracy: 0.4676 - 3s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "161/161 - 3s - loss: 15.5215 - accuracy: 0.4730 - 3s/epoch - 19ms/step\n",
      "Epoch 82/100\n",
      "161/161 - 3s - loss: 17.7606 - accuracy: 0.4779 - 3s/epoch - 19ms/step\n",
      "Epoch 83/100\n",
      "161/161 - 3s - loss: 18.0915 - accuracy: 0.4642 - 3s/epoch - 19ms/step\n",
      "Epoch 84/100\n",
      "161/161 - 3s - loss: 15.3078 - accuracy: 0.4773 - 3s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "161/161 - 3s - loss: 13.0040 - accuracy: 0.4757 - 3s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "161/161 - 3s - loss: 14.3699 - accuracy: 0.4635 - 3s/epoch - 19ms/step\n",
      "Epoch 87/100\n",
      "161/161 - 3s - loss: 14.7676 - accuracy: 0.4718 - 3s/epoch - 19ms/step\n",
      "Epoch 88/100\n",
      "161/161 - 3s - loss: 10.1154 - accuracy: 0.4763 - 3s/epoch - 19ms/step\n",
      "Epoch 89/100\n",
      "161/161 - 3s - loss: 14.9282 - accuracy: 0.4642 - 3s/epoch - 19ms/step\n",
      "Epoch 90/100\n",
      "161/161 - 3s - loss: 15.1384 - accuracy: 0.4765 - 3s/epoch - 19ms/step\n",
      "Epoch 91/100\n",
      "161/161 - 3s - loss: 13.4401 - accuracy: 0.4674 - 3s/epoch - 19ms/step\n",
      "Epoch 92/100\n",
      "161/161 - 3s - loss: 18.9077 - accuracy: 0.4792 - 3s/epoch - 19ms/step\n",
      "Epoch 93/100\n",
      "161/161 - 3s - loss: 11.0179 - accuracy: 0.4753 - 3s/epoch - 20ms/step\n",
      "Epoch 94/100\n",
      "161/161 - 3s - loss: 11.9720 - accuracy: 0.4676 - 3s/epoch - 18ms/step\n",
      "Epoch 95/100\n",
      "161/161 - 3s - loss: 10.6229 - accuracy: 0.4777 - 3s/epoch - 19ms/step\n",
      "Epoch 96/100\n",
      "161/161 - 3s - loss: 10.5715 - accuracy: 0.4642 - 3s/epoch - 19ms/step\n",
      "Epoch 97/100\n",
      "161/161 - 3s - loss: 11.4438 - accuracy: 0.4736 - 3s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "161/161 - 3s - loss: 14.1004 - accuracy: 0.4697 - 3s/epoch - 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "161/161 - 3s - loss: 13.8462 - accuracy: 0.4722 - 3s/epoch - 19ms/step\n",
      "Epoch 100/100\n",
      "161/161 - 3s - loss: 10.0431 - accuracy: 0.4681 - 3s/epoch - 19ms/step\n",
      "38/38 [==============================] - 1s 7ms/step\n",
      "Train...\n",
      "Epoch 1/100\n",
      "161/161 - 6s - loss: 1099.6788 - accuracy: 0.4930 - 6s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "161/161 - 3s - loss: 262.5837 - accuracy: 0.4922 - 3s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "161/161 - 3s - loss: 173.9264 - accuracy: 0.5025 - 3s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "161/161 - 3s - loss: 161.2151 - accuracy: 0.5099 - 3s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "161/161 - 3s - loss: 108.3744 - accuracy: 0.4984 - 3s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "161/161 - 3s - loss: 105.7679 - accuracy: 0.4990 - 3s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "161/161 - 3s - loss: 82.9257 - accuracy: 0.5090 - 3s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "161/161 - 3s - loss: 78.3811 - accuracy: 0.4957 - 3s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "161/161 - 3s - loss: 71.0074 - accuracy: 0.5016 - 3s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "161/161 - 3s - loss: 62.6031 - accuracy: 0.4908 - 3s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "161/161 - 3s - loss: 55.7313 - accuracy: 0.5000 - 3s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "161/161 - 3s - loss: 75.1778 - accuracy: 0.4961 - 3s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "161/161 - 3s - loss: 63.2318 - accuracy: 0.5072 - 3s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "161/161 - 3s - loss: 69.1903 - accuracy: 0.4918 - 3s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "161/161 - 3s - loss: 55.5681 - accuracy: 0.4967 - 3s/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "161/161 - 3s - loss: 40.6480 - accuracy: 0.4957 - 3s/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "161/161 - 3s - loss: 37.1530 - accuracy: 0.5119 - 3s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "161/161 - 3s - loss: 28.6286 - accuracy: 0.5057 - 3s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "161/161 - 3s - loss: 36.6896 - accuracy: 0.4928 - 3s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "161/161 - 3s - loss: 29.5987 - accuracy: 0.5109 - 3s/epoch - 19ms/step\n",
      "Epoch 21/100\n",
      "161/161 - 3s - loss: 31.1377 - accuracy: 0.5070 - 3s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "161/161 - 3s - loss: 27.5347 - accuracy: 0.5059 - 3s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "161/161 - 3s - loss: 47.1512 - accuracy: 0.4930 - 3s/epoch - 19ms/step\n",
      "Epoch 24/100\n",
      "161/161 - 3s - loss: 64.1681 - accuracy: 0.4994 - 3s/epoch - 19ms/step\n",
      "Epoch 25/100\n",
      "161/161 - 3s - loss: 49.1776 - accuracy: 0.4971 - 3s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "161/161 - 3s - loss: 25.3027 - accuracy: 0.5016 - 3s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "161/161 - 3s - loss: 24.2562 - accuracy: 0.4893 - 3s/epoch - 19ms/step\n",
      "Epoch 28/100\n",
      "161/161 - 3s - loss: 17.6203 - accuracy: 0.4977 - 3s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "161/161 - 3s - loss: 17.1473 - accuracy: 0.4943 - 3s/epoch - 18ms/step\n",
      "Epoch 30/100\n",
      "161/161 - 3s - loss: 13.6066 - accuracy: 0.5064 - 3s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "161/161 - 3s - loss: 21.5818 - accuracy: 0.4975 - 3s/epoch - 19ms/step\n",
      "Epoch 32/100\n",
      "161/161 - 3s - loss: 18.8420 - accuracy: 0.4902 - 3s/epoch - 19ms/step\n",
      "Epoch 33/100\n",
      "161/161 - 3s - loss: 18.4078 - accuracy: 0.5080 - 3s/epoch - 19ms/step\n",
      "Epoch 34/100\n",
      "161/161 - 3s - loss: 9.2471 - accuracy: 0.4967 - 3s/epoch - 19ms/step\n",
      "Epoch 35/100\n",
      "161/161 - 3s - loss: 12.4308 - accuracy: 0.4904 - 3s/epoch - 19ms/step\n",
      "Epoch 36/100\n",
      "161/161 - 3s - loss: 14.7264 - accuracy: 0.5105 - 3s/epoch - 19ms/step\n",
      "Epoch 37/100\n",
      "161/161 - 3s - loss: 11.6315 - accuracy: 0.4977 - 3s/epoch - 19ms/step\n",
      "Epoch 38/100\n",
      "161/161 - 3s - loss: 8.9691 - accuracy: 0.4930 - 3s/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "161/161 - 3s - loss: 10.7224 - accuracy: 0.5072 - 3s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "161/161 - 3s - loss: 18.3688 - accuracy: 0.4980 - 3s/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "161/161 - 3s - loss: 12.2619 - accuracy: 0.4996 - 3s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "161/161 - 3s - loss: 12.0216 - accuracy: 0.4932 - 3s/epoch - 19ms/step\n",
      "Epoch 43/100\n",
      "161/161 - 3s - loss: 11.5399 - accuracy: 0.4897 - 3s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "161/161 - 3s - loss: 10.9870 - accuracy: 0.5066 - 3s/epoch - 19ms/step\n",
      "Epoch 45/100\n",
      "161/161 - 3s - loss: 9.1345 - accuracy: 0.5006 - 3s/epoch - 19ms/step\n",
      "Epoch 46/100\n",
      "161/161 - 3s - loss: 10.3527 - accuracy: 0.4988 - 3s/epoch - 19ms/step\n",
      "Epoch 47/100\n",
      "161/161 - 3s - loss: 11.1192 - accuracy: 0.4959 - 3s/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "161/161 - 3s - loss: 9.7472 - accuracy: 0.4920 - 3s/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "161/161 - 3s - loss: 13.9614 - accuracy: 0.5043 - 3s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "161/161 - 3s - loss: 18.7737 - accuracy: 0.4902 - 3s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "161/161 - 3s - loss: 9.3850 - accuracy: 0.5099 - 3s/epoch - 19ms/step\n",
      "Epoch 52/100\n",
      "161/161 - 3s - loss: 10.8350 - accuracy: 0.5082 - 3s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "161/161 - 3s - loss: 11.4866 - accuracy: 0.5168 - 3s/epoch - 19ms/step\n",
      "Epoch 54/100\n",
      "161/161 - 3s - loss: 7.3965 - accuracy: 0.4986 - 3s/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "161/161 - 3s - loss: 8.9229 - accuracy: 0.4986 - 3s/epoch - 19ms/step\n",
      "Epoch 56/100\n",
      "161/161 - 3s - loss: 9.9998 - accuracy: 0.4883 - 3s/epoch - 19ms/step\n",
      "Epoch 57/100\n",
      "161/161 - 3s - loss: 11.2294 - accuracy: 0.5064 - 3s/epoch - 19ms/step\n",
      "Epoch 58/100\n",
      "161/161 - 3s - loss: 13.3691 - accuracy: 0.5004 - 3s/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "161/161 - 3s - loss: 7.9642 - accuracy: 0.4885 - 3s/epoch - 19ms/step\n",
      "Epoch 60/100\n",
      "161/161 - 3s - loss: 8.5005 - accuracy: 0.4928 - 3s/epoch - 19ms/step\n",
      "Epoch 61/100\n",
      "161/161 - 3s - loss: 10.7250 - accuracy: 0.5020 - 3s/epoch - 19ms/step\n",
      "Epoch 62/100\n",
      "161/161 - 3s - loss: 9.5372 - accuracy: 0.4979 - 3s/epoch - 19ms/step\n",
      "Epoch 63/100\n",
      "161/161 - 3s - loss: 7.8065 - accuracy: 0.5059 - 3s/epoch - 19ms/step\n",
      "Epoch 64/100\n",
      "161/161 - 3s - loss: 10.2083 - accuracy: 0.4842 - 3s/epoch - 19ms/step\n",
      "Epoch 65/100\n",
      "161/161 - 3s - loss: 12.1727 - accuracy: 0.4996 - 3s/epoch - 19ms/step\n",
      "Epoch 66/100\n",
      "161/161 - 3s - loss: 6.5135 - accuracy: 0.4881 - 3s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "161/161 - 3s - loss: 8.6306 - accuracy: 0.4973 - 3s/epoch - 19ms/step\n",
      "Epoch 68/100\n",
      "161/161 - 3s - loss: 9.7350 - accuracy: 0.4996 - 3s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "161/161 - 3s - loss: 9.8995 - accuracy: 0.4934 - 3s/epoch - 18ms/step\n",
      "Epoch 70/100\n",
      "161/161 - 3s - loss: 9.6528 - accuracy: 0.4936 - 3s/epoch - 19ms/step\n",
      "Epoch 71/100\n",
      "161/161 - 3s - loss: 9.0041 - accuracy: 0.4930 - 3s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "161/161 - 3s - loss: 5.4540 - accuracy: 0.5039 - 3s/epoch - 19ms/step\n",
      "Epoch 73/100\n",
      "161/161 - 3s - loss: 9.0021 - accuracy: 0.4901 - 3s/epoch - 19ms/step\n",
      "Epoch 74/100\n",
      "161/161 - 3s - loss: 7.3314 - accuracy: 0.5029 - 3s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "161/161 - 3s - loss: 6.3161 - accuracy: 0.4986 - 3s/epoch - 19ms/step\n",
      "Epoch 76/100\n",
      "161/161 - 3s - loss: 8.8051 - accuracy: 0.4922 - 3s/epoch - 19ms/step\n",
      "Epoch 77/100\n",
      "161/161 - 3s - loss: 8.8636 - accuracy: 0.5043 - 3s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "161/161 - 3s - loss: 8.3670 - accuracy: 0.4979 - 3s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "161/161 - 3s - loss: 8.8864 - accuracy: 0.4912 - 3s/epoch - 19ms/step\n",
      "Epoch 80/100\n",
      "161/161 - 3s - loss: 7.7637 - accuracy: 0.4979 - 3s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "161/161 - 3s - loss: 7.4293 - accuracy: 0.5035 - 3s/epoch - 19ms/step\n",
      "Epoch 82/100\n",
      "161/161 - 3s - loss: 8.8955 - accuracy: 0.4941 - 3s/epoch - 19ms/step\n",
      "Epoch 83/100\n",
      "161/161 - 3s - loss: 7.2557 - accuracy: 0.4957 - 3s/epoch - 19ms/step\n",
      "Epoch 84/100\n",
      "161/161 - 3s - loss: 7.4181 - accuracy: 0.4938 - 3s/epoch - 19ms/step\n",
      "Epoch 85/100\n",
      "161/161 - 3s - loss: 8.4355 - accuracy: 0.4979 - 3s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "161/161 - 3s - loss: 9.0729 - accuracy: 0.4912 - 3s/epoch - 19ms/step\n",
      "Epoch 87/100\n",
      "161/161 - 3s - loss: 5.3445 - accuracy: 0.4807 - 3s/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "161/161 - 3s - loss: 8.7745 - accuracy: 0.4893 - 3s/epoch - 19ms/step\n",
      "Epoch 89/100\n",
      "161/161 - 3s - loss: 10.7888 - accuracy: 0.4901 - 3s/epoch - 19ms/step\n",
      "Epoch 90/100\n",
      "161/161 - 3s - loss: 6.1228 - accuracy: 0.4848 - 3s/epoch - 19ms/step\n",
      "Epoch 91/100\n",
      "161/161 - 3s - loss: 9.5555 - accuracy: 0.4973 - 3s/epoch - 19ms/step\n",
      "Epoch 92/100\n",
      "161/161 - 3s - loss: 7.8131 - accuracy: 0.4858 - 3s/epoch - 19ms/step\n",
      "Epoch 93/100\n",
      "161/161 - 3s - loss: 12.1434 - accuracy: 0.4891 - 3s/epoch - 19ms/step\n",
      "Epoch 94/100\n",
      "161/161 - 3s - loss: 5.9886 - accuracy: 0.4967 - 3s/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "161/161 - 3s - loss: 8.1104 - accuracy: 0.4901 - 3s/epoch - 19ms/step\n",
      "Epoch 96/100\n",
      "161/161 - 3s - loss: 6.3118 - accuracy: 0.4992 - 3s/epoch - 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "161/161 - 3s - loss: 8.9297 - accuracy: 0.4916 - 3s/epoch - 19ms/step\n",
      "Epoch 98/100\n",
      "161/161 - 3s - loss: 7.1152 - accuracy: 0.4967 - 3s/epoch - 19ms/step\n",
      "Epoch 99/100\n",
      "161/161 - 3s - loss: 7.4768 - accuracy: 0.5000 - 3s/epoch - 19ms/step\n",
      "Epoch 100/100\n",
      "161/161 - 3s - loss: 8.7963 - accuracy: 0.5014 - 3s/epoch - 19ms/step\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Train...\n",
      "Epoch 1/100\n",
      "160/160 - 6s - loss: 1552.8459 - accuracy: 0.5188 - 6s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "160/160 - 3s - loss: 407.6935 - accuracy: 0.4941 - 3s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "160/160 - 3s - loss: 204.0381 - accuracy: 0.5190 - 3s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "160/160 - 3s - loss: 242.4633 - accuracy: 0.5125 - 3s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "160/160 - 3s - loss: 151.2382 - accuracy: 0.4957 - 3s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "160/160 - 3s - loss: 70.5611 - accuracy: 0.5094 - 3s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "160/160 - 3s - loss: 87.7695 - accuracy: 0.5123 - 3s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "160/160 - 3s - loss: 90.7066 - accuracy: 0.5063 - 3s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "160/160 - 3s - loss: 72.4833 - accuracy: 0.5135 - 3s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "160/160 - 3s - loss: 124.4197 - accuracy: 0.4965 - 3s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "160/160 - 3s - loss: 74.8936 - accuracy: 0.5107 - 3s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "160/160 - 3s - loss: 68.4033 - accuracy: 0.5049 - 3s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "160/160 - 3s - loss: 70.8657 - accuracy: 0.5139 - 3s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "160/160 - 3s - loss: 56.3313 - accuracy: 0.5147 - 3s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "160/160 - 3s - loss: 59.2287 - accuracy: 0.5016 - 3s/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "160/160 - 3s - loss: 57.0299 - accuracy: 0.5107 - 3s/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "160/160 - 3s - loss: 30.1149 - accuracy: 0.5195 - 3s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "160/160 - 3s - loss: 30.6948 - accuracy: 0.5106 - 3s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "160/160 - 3s - loss: 36.1806 - accuracy: 0.4982 - 3s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "160/160 - 3s - loss: 29.1684 - accuracy: 0.5061 - 3s/epoch - 19ms/step\n",
      "Epoch 21/100\n",
      "160/160 - 3s - loss: 44.8715 - accuracy: 0.5059 - 3s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "160/160 - 3s - loss: 52.9062 - accuracy: 0.5006 - 3s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "160/160 - 3s - loss: 30.2468 - accuracy: 0.5033 - 3s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "160/160 - 3s - loss: 35.8459 - accuracy: 0.5088 - 3s/epoch - 19ms/step\n",
      "Epoch 25/100\n",
      "160/160 - 3s - loss: 43.8395 - accuracy: 0.5057 - 3s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "160/160 - 3s - loss: 41.3524 - accuracy: 0.5041 - 3s/epoch - 19ms/step\n",
      "Epoch 27/100\n",
      "160/160 - 3s - loss: 41.2753 - accuracy: 0.5008 - 3s/epoch - 20ms/step\n",
      "Epoch 28/100\n",
      "160/160 - 3s - loss: 36.1299 - accuracy: 0.5000 - 3s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "160/160 - 3s - loss: 20.5011 - accuracy: 0.5115 - 3s/epoch - 19ms/step\n",
      "Epoch 30/100\n",
      "160/160 - 3s - loss: 18.8622 - accuracy: 0.5043 - 3s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "160/160 - 3s - loss: 39.6282 - accuracy: 0.4994 - 3s/epoch - 19ms/step\n",
      "Epoch 32/100\n",
      "160/160 - 3s - loss: 27.4303 - accuracy: 0.5104 - 3s/epoch - 19ms/step\n",
      "Epoch 33/100\n",
      "160/160 - 3s - loss: 18.2183 - accuracy: 0.5033 - 3s/epoch - 19ms/step\n",
      "Epoch 34/100\n",
      "160/160 - 3s - loss: 23.3276 - accuracy: 0.5100 - 3s/epoch - 19ms/step\n",
      "Epoch 35/100\n",
      "160/160 - 3s - loss: 16.5403 - accuracy: 0.5074 - 3s/epoch - 20ms/step\n",
      "Epoch 36/100\n",
      "160/160 - 3s - loss: 18.6586 - accuracy: 0.5201 - 3s/epoch - 19ms/step\n",
      "Epoch 37/100\n",
      "160/160 - 3s - loss: 23.0940 - accuracy: 0.5096 - 3s/epoch - 20ms/step\n",
      "Epoch 38/100\n",
      "160/160 - 3s - loss: 24.8596 - accuracy: 0.5000 - 3s/epoch - 19ms/step\n",
      "Epoch 39/100\n",
      "160/160 - 3s - loss: 12.3736 - accuracy: 0.5137 - 3s/epoch - 19ms/step\n",
      "Epoch 40/100\n",
      "160/160 - 3s - loss: 16.2630 - accuracy: 0.5162 - 3s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "160/160 - 3s - loss: 16.0492 - accuracy: 0.5021 - 3s/epoch - 19ms/step\n",
      "Epoch 42/100\n",
      "160/160 - 3s - loss: 13.6735 - accuracy: 0.5160 - 3s/epoch - 19ms/step\n",
      "Epoch 43/100\n",
      "160/160 - 3s - loss: 16.2263 - accuracy: 0.5010 - 3s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "160/160 - 3s - loss: 11.0772 - accuracy: 0.5090 - 3s/epoch - 19ms/step\n",
      "Epoch 45/100\n",
      "160/160 - 3s - loss: 19.9613 - accuracy: 0.5068 - 3s/epoch - 19ms/step\n",
      "Epoch 46/100\n",
      "160/160 - 3s - loss: 14.5376 - accuracy: 0.5012 - 3s/epoch - 20ms/step\n",
      "Epoch 47/100\n",
      "160/160 - 3s - loss: 24.2070 - accuracy: 0.4939 - 3s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "160/160 - 3s - loss: 18.3838 - accuracy: 0.5064 - 3s/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "160/160 - 3s - loss: 14.6524 - accuracy: 0.5021 - 3s/epoch - 19ms/step\n",
      "Epoch 50/100\n",
      "160/160 - 3s - loss: 13.8883 - accuracy: 0.5027 - 3s/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "160/160 - 3s - loss: 14.1751 - accuracy: 0.5100 - 3s/epoch - 19ms/step\n",
      "Epoch 52/100\n",
      "160/160 - 3s - loss: 16.2640 - accuracy: 0.5082 - 3s/epoch - 19ms/step\n",
      "Epoch 53/100\n",
      "160/160 - 3s - loss: 9.8191 - accuracy: 0.5084 - 3s/epoch - 19ms/step\n",
      "Epoch 54/100\n",
      "160/160 - 3s - loss: 11.3021 - accuracy: 0.5270 - 3s/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "160/160 - 3s - loss: 14.5583 - accuracy: 0.4961 - 3s/epoch - 19ms/step\n",
      "Epoch 56/100\n",
      "160/160 - 3s - loss: 10.6738 - accuracy: 0.5078 - 3s/epoch - 19ms/step\n",
      "Epoch 57/100\n",
      "160/160 - 3s - loss: 13.2105 - accuracy: 0.5020 - 3s/epoch - 19ms/step\n",
      "Epoch 58/100\n",
      "160/160 - 3s - loss: 21.8587 - accuracy: 0.5008 - 3s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "160/160 - 3s - loss: 15.1643 - accuracy: 0.5061 - 3s/epoch - 20ms/step\n",
      "Epoch 60/100\n",
      "160/160 - 3s - loss: 16.3564 - accuracy: 0.5107 - 3s/epoch - 19ms/step\n",
      "Epoch 61/100\n",
      "160/160 - 3s - loss: 12.0076 - accuracy: 0.5041 - 3s/epoch - 19ms/step\n",
      "Epoch 62/100\n",
      "160/160 - 3s - loss: 16.5008 - accuracy: 0.4908 - 3s/epoch - 20ms/step\n",
      "Epoch 63/100\n",
      "160/160 - 3s - loss: 9.2277 - accuracy: 0.5147 - 3s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "160/160 - 3s - loss: 10.8301 - accuracy: 0.4965 - 3s/epoch - 19ms/step\n",
      "Epoch 65/100\n",
      "160/160 - 3s - loss: 11.3052 - accuracy: 0.5016 - 3s/epoch - 19ms/step\n",
      "Epoch 66/100\n",
      "160/160 - 3s - loss: 11.8941 - accuracy: 0.5051 - 3s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "160/160 - 3s - loss: 12.9860 - accuracy: 0.5072 - 3s/epoch - 19ms/step\n",
      "Epoch 68/100\n",
      "160/160 - 3s - loss: 12.1601 - accuracy: 0.5148 - 3s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "160/160 - 3s - loss: 14.2801 - accuracy: 0.5055 - 3s/epoch - 19ms/step\n",
      "Epoch 70/100\n",
      "160/160 - 3s - loss: 15.7513 - accuracy: 0.5055 - 3s/epoch - 19ms/step\n",
      "Epoch 71/100\n",
      "160/160 - 3s - loss: 15.5433 - accuracy: 0.5049 - 3s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "160/160 - 3s - loss: 12.8888 - accuracy: 0.5018 - 3s/epoch - 19ms/step\n",
      "Epoch 73/100\n",
      "160/160 - 3s - loss: 10.6831 - accuracy: 0.5064 - 3s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "160/160 - 3s - loss: 9.8391 - accuracy: 0.5154 - 3s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "160/160 - 3s - loss: 14.7316 - accuracy: 0.4994 - 3s/epoch - 19ms/step\n",
      "Epoch 76/100\n",
      "160/160 - 3s - loss: 10.5872 - accuracy: 0.5125 - 3s/epoch - 19ms/step\n",
      "Epoch 77/100\n",
      "160/160 - 3s - loss: 12.8656 - accuracy: 0.5055 - 3s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "160/160 - 3s - loss: 10.1220 - accuracy: 0.5063 - 3s/epoch - 20ms/step\n",
      "Epoch 79/100\n",
      "160/160 - 3s - loss: 13.0291 - accuracy: 0.5061 - 3s/epoch - 19ms/step\n",
      "Epoch 80/100\n",
      "160/160 - 3s - loss: 9.5983 - accuracy: 0.5021 - 3s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "160/160 - 3s - loss: 12.2838 - accuracy: 0.4986 - 3s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "160/160 - 3s - loss: 8.9695 - accuracy: 0.5006 - 3s/epoch - 19ms/step\n",
      "Epoch 83/100\n",
      "160/160 - 3s - loss: 11.3941 - accuracy: 0.4859 - 3s/epoch - 19ms/step\n",
      "Epoch 84/100\n",
      "160/160 - 3s - loss: 11.0509 - accuracy: 0.5061 - 3s/epoch - 20ms/step\n",
      "Epoch 85/100\n",
      "160/160 - 3s - loss: 12.4790 - accuracy: 0.4900 - 3s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "160/160 - 3s - loss: 14.2722 - accuracy: 0.5080 - 3s/epoch - 20ms/step\n",
      "Epoch 87/100\n",
      "160/160 - 3s - loss: 6.3960 - accuracy: 0.5084 - 3s/epoch - 20ms/step\n",
      "Epoch 88/100\n",
      "160/160 - 3s - loss: 10.6561 - accuracy: 0.5016 - 3s/epoch - 20ms/step\n",
      "Epoch 89/100\n",
      "160/160 - 3s - loss: 10.1171 - accuracy: 0.4941 - 3s/epoch - 19ms/step\n",
      "Epoch 90/100\n",
      "160/160 - 3s - loss: 10.1466 - accuracy: 0.5037 - 3s/epoch - 20ms/step\n",
      "Epoch 91/100\n",
      "160/160 - 3s - loss: 10.5937 - accuracy: 0.5063 - 3s/epoch - 19ms/step\n",
      "Epoch 92/100\n",
      "160/160 - 3s - loss: 10.0563 - accuracy: 0.5018 - 3s/epoch - 19ms/step\n",
      "Epoch 93/100\n",
      "160/160 - 3s - loss: 8.2836 - accuracy: 0.5127 - 3s/epoch - 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "160/160 - 3s - loss: 8.1823 - accuracy: 0.4861 - 3s/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "160/160 - 3s - loss: 6.7995 - accuracy: 0.5117 - 3s/epoch - 19ms/step\n",
      "Epoch 96/100\n",
      "160/160 - 3s - loss: 11.2597 - accuracy: 0.5066 - 3s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "160/160 - 3s - loss: 11.4574 - accuracy: 0.5006 - 3s/epoch - 19ms/step\n",
      "Epoch 98/100\n",
      "160/160 - 3s - loss: 10.6992 - accuracy: 0.5006 - 3s/epoch - 19ms/step\n",
      "Epoch 99/100\n",
      "160/160 - 3s - loss: 12.6951 - accuracy: 0.5074 - 3s/epoch - 19ms/step\n",
      "Epoch 100/100\n",
      "160/160 - 3s - loss: 9.0685 - accuracy: 0.5098 - 3s/epoch - 19ms/step\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Train...\n",
      "Epoch 1/100\n",
      "160/160 - 6s - loss: 840.3288 - accuracy: 0.5142 - 6s/epoch - 37ms/step\n",
      "Epoch 2/100\n",
      "160/160 - 3s - loss: 372.5275 - accuracy: 0.5093 - 3s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "160/160 - 3s - loss: 193.1499 - accuracy: 0.5150 - 3s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "160/160 - 3s - loss: 144.9919 - accuracy: 0.5181 - 3s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "160/160 - 3s - loss: 77.0137 - accuracy: 0.5126 - 3s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "160/160 - 3s - loss: 64.3435 - accuracy: 0.5097 - 3s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "160/160 - 3s - loss: 92.3450 - accuracy: 0.5068 - 3s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "160/160 - 3s - loss: 43.3317 - accuracy: 0.5173 - 3s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "160/160 - 3s - loss: 73.0713 - accuracy: 0.5064 - 3s/epoch - 20ms/step\n",
      "Epoch 10/100\n",
      "160/160 - 3s - loss: 78.3402 - accuracy: 0.5087 - 3s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "160/160 - 3s - loss: 43.9820 - accuracy: 0.5189 - 3s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "160/160 - 3s - loss: 33.8263 - accuracy: 0.5226 - 3s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "160/160 - 3s - loss: 83.0536 - accuracy: 0.5075 - 3s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "160/160 - 3s - loss: 35.9546 - accuracy: 0.5164 - 3s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "160/160 - 3s - loss: 34.9160 - accuracy: 0.5017 - 3s/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "160/160 - 3s - loss: 47.1942 - accuracy: 0.5077 - 3s/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "160/160 - 3s - loss: 49.6149 - accuracy: 0.5183 - 3s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "160/160 - 3s - loss: 37.7078 - accuracy: 0.5230 - 3s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "160/160 - 3s - loss: 48.0963 - accuracy: 0.5122 - 3s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "160/160 - 3s - loss: 35.9132 - accuracy: 0.5064 - 3s/epoch - 20ms/step\n",
      "Epoch 21/100\n",
      "160/160 - 3s - loss: 30.5651 - accuracy: 0.5109 - 3s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "160/160 - 3s - loss: 31.6880 - accuracy: 0.5054 - 3s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "160/160 - 3s - loss: 40.5409 - accuracy: 0.5079 - 3s/epoch - 19ms/step\n",
      "Epoch 24/100\n",
      "160/160 - 3s - loss: 28.8226 - accuracy: 0.5117 - 3s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "160/160 - 3s - loss: 21.4002 - accuracy: 0.5244 - 3s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "160/160 - 3s - loss: 31.5601 - accuracy: 0.5228 - 3s/epoch - 19ms/step\n",
      "Epoch 27/100\n",
      "160/160 - 3s - loss: 25.5199 - accuracy: 0.5160 - 3s/epoch - 19ms/step\n",
      "Epoch 28/100\n",
      "160/160 - 3s - loss: 23.0121 - accuracy: 0.5119 - 3s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "160/160 - 3s - loss: 13.2919 - accuracy: 0.5142 - 3s/epoch - 19ms/step\n",
      "Epoch 30/100\n",
      "160/160 - 3s - loss: 17.1227 - accuracy: 0.5262 - 3s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "160/160 - 3s - loss: 15.0789 - accuracy: 0.5136 - 3s/epoch - 20ms/step\n",
      "Epoch 32/100\n",
      "160/160 - 3s - loss: 15.9758 - accuracy: 0.5260 - 3s/epoch - 19ms/step\n",
      "Epoch 33/100\n",
      "160/160 - 3s - loss: 13.3970 - accuracy: 0.5234 - 3s/epoch - 20ms/step\n",
      "Epoch 34/100\n",
      "160/160 - 3s - loss: 13.3978 - accuracy: 0.5218 - 3s/epoch - 19ms/step\n",
      "Epoch 35/100\n",
      "160/160 - 3s - loss: 15.1614 - accuracy: 0.5111 - 3s/epoch - 19ms/step\n",
      "Epoch 36/100\n",
      "160/160 - 3s - loss: 8.2050 - accuracy: 0.5226 - 3s/epoch - 19ms/step\n",
      "Epoch 37/100\n",
      "160/160 - 3s - loss: 16.4510 - accuracy: 0.5026 - 3s/epoch - 19ms/step\n",
      "Epoch 38/100\n",
      "160/160 - 3s - loss: 16.7132 - accuracy: 0.5316 - 3s/epoch - 19ms/step\n",
      "Epoch 39/100\n",
      "160/160 - 3s - loss: 10.9826 - accuracy: 0.5103 - 3s/epoch - 19ms/step\n",
      "Epoch 40/100\n",
      "160/160 - 3s - loss: 9.9848 - accuracy: 0.5064 - 3s/epoch - 20ms/step\n",
      "Epoch 41/100\n",
      "160/160 - 3s - loss: 8.2003 - accuracy: 0.5193 - 3s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "160/160 - 3s - loss: 9.3013 - accuracy: 0.5138 - 3s/epoch - 19ms/step\n",
      "Epoch 43/100\n",
      "160/160 - 3s - loss: 8.9070 - accuracy: 0.5177 - 3s/epoch - 19ms/step\n",
      "Epoch 44/100\n",
      "160/160 - 3s - loss: 11.5249 - accuracy: 0.5099 - 3s/epoch - 19ms/step\n",
      "Epoch 45/100\n",
      "160/160 - 3s - loss: 7.6271 - accuracy: 0.5179 - 3s/epoch - 19ms/step\n",
      "Epoch 46/100\n",
      "160/160 - 3s - loss: 9.0345 - accuracy: 0.5171 - 3s/epoch - 20ms/step\n",
      "Epoch 47/100\n",
      "160/160 - 3s - loss: 8.3292 - accuracy: 0.5152 - 3s/epoch - 19ms/step\n",
      "Epoch 48/100\n",
      "160/160 - 3s - loss: 8.6264 - accuracy: 0.5238 - 3s/epoch - 19ms/step\n",
      "Epoch 49/100\n",
      "160/160 - 3s - loss: 9.0304 - accuracy: 0.5142 - 3s/epoch - 19ms/step\n",
      "Epoch 50/100\n",
      "160/160 - 3s - loss: 7.8022 - accuracy: 0.5185 - 3s/epoch - 19ms/step\n",
      "Epoch 51/100\n",
      "160/160 - 3s - loss: 5.5171 - accuracy: 0.5217 - 3s/epoch - 20ms/step\n",
      "Epoch 52/100\n",
      "160/160 - 3s - loss: 9.4477 - accuracy: 0.5230 - 3s/epoch - 19ms/step\n",
      "Epoch 53/100\n",
      "160/160 - 3s - loss: 8.7045 - accuracy: 0.5358 - 3s/epoch - 19ms/step\n",
      "Epoch 54/100\n",
      "160/160 - 3s - loss: 7.0410 - accuracy: 0.5048 - 3s/epoch - 19ms/step\n",
      "Epoch 55/100\n",
      "160/160 - 3s - loss: 4.9434 - accuracy: 0.5064 - 3s/epoch - 19ms/step\n",
      "Epoch 56/100\n",
      "160/160 - 3s - loss: 6.2398 - accuracy: 0.5242 - 3s/epoch - 19ms/step\n",
      "Epoch 57/100\n",
      "160/160 - 3s - loss: 8.0685 - accuracy: 0.5011 - 3s/epoch - 19ms/step\n",
      "Epoch 58/100\n",
      "160/160 - 3s - loss: 9.2656 - accuracy: 0.5124 - 3s/epoch - 19ms/step\n",
      "Epoch 59/100\n",
      "160/160 - 3s - loss: 5.0198 - accuracy: 0.5085 - 3s/epoch - 19ms/step\n",
      "Epoch 60/100\n",
      "160/160 - 3s - loss: 5.0848 - accuracy: 0.5211 - 3s/epoch - 19ms/step\n",
      "Epoch 61/100\n",
      "160/160 - 3s - loss: 7.2758 - accuracy: 0.5222 - 3s/epoch - 19ms/step\n",
      "Epoch 62/100\n",
      "160/160 - 3s - loss: 7.4328 - accuracy: 0.5177 - 3s/epoch - 19ms/step\n",
      "Epoch 63/100\n",
      "160/160 - 3s - loss: 10.1568 - accuracy: 0.5081 - 3s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "160/160 - 3s - loss: 8.5648 - accuracy: 0.4956 - 3s/epoch - 19ms/step\n",
      "Epoch 65/100\n",
      "160/160 - 3s - loss: 7.1129 - accuracy: 0.5091 - 3s/epoch - 19ms/step\n",
      "Epoch 66/100\n",
      "160/160 - 3s - loss: 8.8192 - accuracy: 0.5181 - 3s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "160/160 - 3s - loss: 5.9865 - accuracy: 0.5095 - 3s/epoch - 20ms/step\n",
      "Epoch 68/100\n",
      "160/160 - 3s - loss: 7.2565 - accuracy: 0.5038 - 3s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "160/160 - 3s - loss: 13.4947 - accuracy: 0.5111 - 3s/epoch - 19ms/step\n",
      "Epoch 70/100\n",
      "160/160 - 3s - loss: 9.0048 - accuracy: 0.5011 - 3s/epoch - 19ms/step\n",
      "Epoch 71/100\n",
      "160/160 - 3s - loss: 5.8192 - accuracy: 0.5197 - 3s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "160/160 - 3s - loss: 5.7193 - accuracy: 0.5189 - 3s/epoch - 19ms/step\n",
      "Epoch 73/100\n",
      "160/160 - 3s - loss: 9.5684 - accuracy: 0.5075 - 3s/epoch - 19ms/step\n",
      "Epoch 74/100\n",
      "160/160 - 3s - loss: 9.3026 - accuracy: 0.5056 - 3s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "160/160 - 3s - loss: 7.1752 - accuracy: 0.5115 - 3s/epoch - 19ms/step\n",
      "Epoch 76/100\n",
      "160/160 - 3s - loss: 3.9549 - accuracy: 0.5091 - 3s/epoch - 19ms/step\n",
      "Epoch 77/100\n",
      "160/160 - 3s - loss: 7.3634 - accuracy: 0.5058 - 3s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "160/160 - 3s - loss: 5.9208 - accuracy: 0.5134 - 3s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "160/160 - 3s - loss: 7.5339 - accuracy: 0.5103 - 3s/epoch - 19ms/step\n",
      "Epoch 80/100\n",
      "160/160 - 3s - loss: 6.2364 - accuracy: 0.5064 - 3s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "160/160 - 3s - loss: 6.8714 - accuracy: 0.5164 - 3s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "160/160 - 3s - loss: 8.4091 - accuracy: 0.5042 - 3s/epoch - 20ms/step\n",
      "Epoch 83/100\n",
      "160/160 - 3s - loss: 7.9457 - accuracy: 0.5097 - 3s/epoch - 19ms/step\n",
      "Epoch 84/100\n",
      "160/160 - 3s - loss: 104.2528 - accuracy: 0.4946 - 3s/epoch - 19ms/step\n",
      "Epoch 85/100\n",
      "160/160 - 3s - loss: 59.2379 - accuracy: 0.5197 - 3s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "160/160 - 3s - loss: 18.6618 - accuracy: 0.5121 - 3s/epoch - 19ms/step\n",
      "Epoch 87/100\n",
      "160/160 - 3s - loss: 16.7875 - accuracy: 0.5154 - 3s/epoch - 19ms/step\n",
      "Epoch 88/100\n",
      "160/160 - 3s - loss: 16.1908 - accuracy: 0.5134 - 3s/epoch - 20ms/step\n",
      "Epoch 89/100\n",
      "160/160 - 3s - loss: 15.6894 - accuracy: 0.5056 - 3s/epoch - 19ms/step\n",
      "Epoch 90/100\n",
      "160/160 - 3s - loss: 10.3299 - accuracy: 0.5115 - 3s/epoch - 19ms/step\n",
      "Epoch 91/100\n",
      "160/160 - 3s - loss: 9.5551 - accuracy: 0.5060 - 3s/epoch - 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "160/160 - 3s - loss: 8.9416 - accuracy: 0.5175 - 3s/epoch - 19ms/step\n",
      "Epoch 93/100\n",
      "160/160 - 3s - loss: 9.8916 - accuracy: 0.5058 - 3s/epoch - 19ms/step\n",
      "Epoch 94/100\n",
      "160/160 - 3s - loss: 9.4130 - accuracy: 0.5179 - 3s/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "160/160 - 3s - loss: 9.5585 - accuracy: 0.5093 - 3s/epoch - 19ms/step\n",
      "Epoch 96/100\n",
      "160/160 - 3s - loss: 13.0052 - accuracy: 0.5107 - 3s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "160/160 - 3s - loss: 8.4812 - accuracy: 0.5128 - 3s/epoch - 19ms/step\n",
      "Epoch 98/100\n",
      "160/160 - 3s - loss: 10.6291 - accuracy: 0.5097 - 3s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "160/160 - 3s - loss: 8.6501 - accuracy: 0.5126 - 3s/epoch - 20ms/step\n",
      "Epoch 100/100\n",
      "160/160 - 3s - loss: 8.9667 - accuracy: 0.5117 - 3s/epoch - 19ms/step\n",
      "37/37 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model_1.fit(x_train_1, y_train_1_e, epochs=100, verbose=2)\n",
    "p_test_1 = model_1.predict(x_test_1)\n",
    "\n",
    "print('Train...')\n",
    "model_7.fit(x_train_7, y_train_7_e, epochs=100, verbose=2)\n",
    "p_test_7 = model_7.predict(x_test_7)\n",
    "\n",
    "print('Train...')\n",
    "model_15.fit(x_train_15, y_train_15_e, epochs=100, verbose=2)\n",
    "p_test_15 = model_15.predict(x_test_15)\n",
    "\n",
    "print('Train...')\n",
    "model_30.fit(x_train_30, y_train_30_e, epochs=100, verbose=2)\n",
    "p_test_30 = model_30.predict(x_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11fc61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('kospi_1day_classification_v2.h5')\n",
    "model_7.save('kospi_7days_classification_v2.h5')\n",
    "model_15.save('kospi_15days_classification_v2.h5')\n",
    "model_30.save('kospi_30days_classification_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0178c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 10ms/step - loss: 37.9323 - accuracy: 0.5261\n",
      "\n",
      " Accuracy: 0.5261\n",
      "37/37 [==============================] - 1s 10ms/step - loss: 6.3236 - accuracy: 0.4763\n",
      "\n",
      " Accuracy: 0.4763\n",
      "37/37 [==============================] - 1s 10ms/step - loss: 38.2471 - accuracy: 0.5000\n",
      "\n",
      " Accuracy: 0.5000\n",
      "37/37 [==============================] - 1s 9ms/step - loss: 5.9613 - accuracy: 0.4978\n",
      "\n",
      " Accuracy: 0.4978\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy: %.4f' % (model_1.evaluate(x_test_1, y_test_1_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_7.evaluate(x_test_7, y_test_7_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_15.evaluate(x_test_15, y_test_15_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_30.evaluate(x_test_30, y_test_30_e)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.05 / TensorFlow 2.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

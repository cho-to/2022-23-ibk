{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tcn in /home/work/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (0.16.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (1.21.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (63.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (14.0.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (3.19.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.29.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (22.12.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.35.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: finance-datareader in /home/work/.local/lib/python3.8/site-packages (0.9.50)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (2.27.1)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.64.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.5.0)\n",
      "Requirement already satisfied: requests-file in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from requests-file->finance-datareader) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn\n",
    "!pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ffe65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-01-31 02:58:33.359249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-31 02:58:33.497848: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-31 02:58:36.411639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-31 02:58:36.411849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-31 02:58:36.411874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452f7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1996-12-11    704.679993\n",
      "1996-12-12    689.380005\n",
      "1996-12-13    689.070007\n",
      "1996-12-16    673.919983\n",
      "1996-12-17    663.349976\n",
      "Name: Close, dtype: float64\n",
      "Date\n",
      "1996-12-11     704.679993\n",
      "1996-12-12     689.380005\n",
      "1996-12-13     689.070007\n",
      "1996-12-16     673.919983\n",
      "1996-12-17     663.349976\n",
      "                 ...     \n",
      "2017-12-21    2429.830078\n",
      "2017-12-22    2440.540039\n",
      "2017-12-26    2427.340088\n",
      "2017-12-27    2436.669922\n",
      "2017-12-28    2467.489990\n",
      "Name: Close, Length: 5341, dtype: float64\n",
      "(5341,)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "kospi_train = fdr.DataReader('KS11', '1990-01-01','2017-12-31')['Close']\n",
    "print(kospi_train.head())\n",
    "print(kospi_train)\n",
    "print(kospi_train.shape)\n",
    "print(kospi_train.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c18820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2018-01-02    2479.649902\n",
      "2018-01-03    2486.350098\n",
      "2018-01-04    2466.459961\n",
      "2018-01-05    2497.520020\n",
      "2018-01-08    2513.280029\n",
      "                 ...     \n",
      "2023-01-25    2428.570068\n",
      "2023-01-26    2468.649902\n",
      "2023-01-27    2484.020020\n",
      "2023-01-30    2450.469971\n",
      "2023-01-31    2441.229980\n",
      "Name: Close, Length: 1250, dtype: float64\n",
      "(1250,)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "kospi_test = fdr.DataReader('KS11', '2018-01-01')['Close']\n",
    "print(kospi_test)\n",
    "print(kospi_test.shape)\n",
    "print(kospi_test.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48c0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1996-12-11     704.679993\n",
      "1996-12-12     689.380005\n",
      "1996-12-13     689.070007\n",
      "1996-12-16     673.919983\n",
      "1996-12-17     663.349976\n",
      "                 ...     \n",
      "2017-12-21    2429.830078\n",
      "2017-12-22    2440.540039\n",
      "2017-12-26    2427.340088\n",
      "2017-12-27    2436.669922\n",
      "2017-12-28    2467.489990\n",
      "Name: Close, Length: 5192, dtype: float64\n",
      "False\n",
      "Date\n",
      "2018-01-02    2479.649902\n",
      "2018-01-03    2486.350098\n",
      "2018-01-04    2466.459961\n",
      "2018-01-05    2497.520020\n",
      "2018-01-08    2513.280029\n",
      "                 ...     \n",
      "2023-01-25    2428.570068\n",
      "2023-01-26    2468.649902\n",
      "2023-01-27    2484.020020\n",
      "2023-01-30    2450.469971\n",
      "2023-01-31    2441.229980\n",
      "Name: Close, Length: 1250, dtype: float64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "kospi_train = kospi_train.dropna()\n",
    "kospi_test = kospi_test.dropna()\n",
    "\n",
    "print(kospi_train)\n",
    "print(kospi_train.isnull().any())\n",
    "print(kospi_test)\n",
    "print(kospi_test.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8396c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kospi_train = kospi_train.values\n",
    "kospi_test = kospi_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1334a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_window = 60\n",
    "x_train_1, y_train_1 = [], []\n",
    "x_train_7, y_train_7 = [], []\n",
    "x_train_15, y_train_15 = [], []\n",
    "x_train_30, y_train_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad8662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_train)-1):\n",
    "    x_train_1.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_1.append(kospi_train[i] - kospi_train[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train)-6):\n",
    "    x_train_7.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_7.append(kospi_train[i+6] - kospi_train[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train)-14):\n",
    "    x_train_15.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_15.append(kospi_train[i+14] - kospi_train[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train)-29):\n",
    "    x_train_30.append(kospi_train[i - lookback_window:i])\n",
    "    y_train_30.append(kospi_train[i+29] - kospi_train[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02aedcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_train_1)):\n",
    "    if y_train_1[index]>= -10 and y_train_1[index] < 10:\n",
    "        y_train_1[index] = 'neutral'\n",
    "    elif y_train_1[index] >= 10:\n",
    "        y_train_1[index] = 'increase'\n",
    "    else:\n",
    "        y_train_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_train_7)):\n",
    "    if y_train_7[index]>= -10 and y_train_7[index] < 10:\n",
    "        y_train_7[index] = 'neutral'\n",
    "    elif y_train_7[index] >= 10:\n",
    "        y_train_7[index] = 'increase'\n",
    "    else:\n",
    "        y_train_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_15)):\n",
    "    if y_train_15[index]>= -10 and y_train_15[index] < 10:\n",
    "        y_train_15[index] = 'neutral'\n",
    "    elif y_train_15[index] >= 10:\n",
    "        y_train_15[index] = 'increase'\n",
    "    else:\n",
    "        y_train_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_30)):\n",
    "    if y_train_30[index]>= -10 and y_train_30[index] < 10:\n",
    "        y_train_30[index] = 'neutral'\n",
    "    elif y_train_30[index] >= 10:\n",
    "        y_train_30[index] = 'increase'\n",
    "    else:\n",
    "        y_train_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ef8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5131, 60, 1) (5126, 60, 1) (5118, 60, 1) (5103, 60, 1)\n",
      "(5131,) (5126,) (5118,) (5103,)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(x_train_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "x_train_1 = x_train_1.reshape((5131, -1, 1))\n",
    "#y_train_1 = y_train_1.reshape((-1, 1))\n",
    "\n",
    "x_train_7 = np.array(x_train_7)\n",
    "y_train_7 = np.array(y_train_7)\n",
    "x_train_7 = x_train_7.reshape((5126, -1, 1))\n",
    "#y_train_7 = y_train_7.reshape((-1, 1))\n",
    "\n",
    "x_train_15 = np.array(x_train_15)\n",
    "y_train_15 = np.array(y_train_15)\n",
    "x_train_15 = x_train_15.reshape((5118, -1, 1))\n",
    "#y_train_15 = y_train_15.reshape((-1, 1))\n",
    "\n",
    "x_train_30 = np.array(x_train_30)\n",
    "y_train_30 = np.array(y_train_30)\n",
    "x_train_30 = x_train_30.reshape((5103, -1, 1))\n",
    "#y_train_30 = y_train_30.reshape((-1, 1))\n",
    "\n",
    "print(x_train_1.shape, x_train_7.shape, x_train_15.shape, x_train_30.shape)\n",
    "print(y_train_1.shape, y_train_7.shape, y_train_15.shape, y_train_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612667a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1, y_test_1 = [], []\n",
    "x_test_7, y_test_7 = [], []\n",
    "x_test_15, y_test_15 = [], []\n",
    "x_test_30, y_test_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77c5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_test)):\n",
    "    x_test_1.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_1.append(kospi_test[i] - kospi_test[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test)-6):\n",
    "    x_test_7.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_7.append(kospi_test[i+6] - kospi_test[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test)-14):\n",
    "    x_test_15.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_15.append(kospi_test[i+14] - kospi_test[i-1])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test)-29):\n",
    "    x_test_30.append(kospi_test[i - lookback_window:i])\n",
    "    y_test_30.append(kospi_test[i+29] - kospi_test[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb64b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_test_1)):\n",
    "    if y_test_1[index]>= -10 and y_test_1[index] < 10:\n",
    "        y_test_1[index] = 'neutral'\n",
    "    elif y_test_1[index] >= 10:\n",
    "        y_test_1[index] = 'increase'\n",
    "    else:\n",
    "        y_test_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_test_7)):\n",
    "    if y_test_7[index]>= -10 and y_test_7[index] < 10:\n",
    "        y_test_7[index] = 'neutral'\n",
    "    elif y_test_7[index] >= 10:\n",
    "        y_test_7[index] = 'increase'\n",
    "    else:\n",
    "        y_test_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_15)):\n",
    "    if y_test_15[index]>= -10 and y_test_15[index] < 10:\n",
    "        y_test_15[index] = 'neutral'\n",
    "    elif y_test_15[index] >= 10:\n",
    "        y_test_15[index] = 'increase'\n",
    "    else:\n",
    "        y_test_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_30)):\n",
    "    if y_test_30[index]>= -10 and y_test_30[index] < 10:\n",
    "        y_test_30[index] = 'neutral'\n",
    "    elif y_test_30[index] >= 10:\n",
    "        y_test_30[index] = 'increase'\n",
    "    else:\n",
    "        y_test_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d9be8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = np.array(x_test_1)\n",
    "y_test_1 = np.array(y_test_1)\n",
    "x_test_1 = x_test_1.reshape((1190, -1, 1))\n",
    "#y_test_1 = y_test_1.reshape((-1, 1))\n",
    "\n",
    "x_test_7 = np.array(x_test_7)\n",
    "y_test_7 = np.array(y_test_7)\n",
    "x_test_7 = x_test_7.reshape((1184, -1, 1))\n",
    "#y_test_7 = y_test_7.reshape((-1, 1))\n",
    "\n",
    "x_test_15 = np.array(x_test_15)\n",
    "y_test_15 = np.array(y_test_15)\n",
    "x_test_15 = x_test_15.reshape((1176, -1, 1))\n",
    "#y_test_15 = y_test_15.reshape((-1, 1))\n",
    "\n",
    "x_test_30 = np.array(x_test_30)\n",
    "y_test_30 = np.array(y_test_30)\n",
    "x_test_30 = x_test_30.reshape((1161, -1, 1))\n",
    "#y_test_30 = y_test_30.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3afe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1190, 60, 1) (1184, 60, 1) (1176, 60, 1) (1161, 60, 1)\n",
      "(1190,) (1184,) (1176,) (1161,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_1.shape, x_test_7.shape, x_test_15.shape, x_test_30.shape)\n",
    "print(y_test_1.shape, y_test_7.shape, y_test_15.shape, y_test_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cd5460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_1)\n",
    "\n",
    "y_train_1_e = to_categorical(encoder.transform(y_train_1))\n",
    "y_train_7_e = to_categorical(encoder.transform(y_train_7))\n",
    "y_train_15_e = to_categorical(encoder.transform(y_train_15))\n",
    "y_train_30_e = to_categorical(encoder.transform(y_train_30))\n",
    "\n",
    "y_test_1_e = to_categorical(encoder.transform(y_test_1))\n",
    "y_test_7_e = to_categorical(encoder.transform(y_test_7))\n",
    "y_test_15_e = to_categorical(encoder.transform(y_test_15))\n",
    "y_test_30_e = to_categorical(encoder.transform(y_test_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8cb8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 02:59:26.155579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-31 02:59:26.155643: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-31 02:59:26.155691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-01-31 02:59:26.156282: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 64)                91136     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_1 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_2 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_3 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_7 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_7.summary()\n",
    "model_7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_15 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_15.summary()\n",
    "model_15.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_30 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_30.summary()\n",
    "model_30.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac14f04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model_1...\n",
      "Epoch 1/100\n",
      "161/161 [==============================] - 6s 19ms/step - loss: 1263.3472 - accuracy: 0.3912\n",
      "Epoch 2/100\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 306.1275 - accuracy: 0.3894\n",
      "Epoch 3/100\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 290.9110 - accuracy: 0.3806\n",
      "Epoch 4/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 115.4473 - accuracy: 0.3952\n",
      "Epoch 5/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 148.3853 - accuracy: 0.3820\n",
      "Epoch 6/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 95.1834 - accuracy: 0.3991\n",
      "Epoch 7/100\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 112.7346 - accuracy: 0.3974\n",
      "Epoch 8/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 76.4622 - accuracy: 0.3968\n",
      "Epoch 9/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 68.0676 - accuracy: 0.3972\n",
      "Epoch 10/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 68.0549 - accuracy: 0.3964\n",
      "Epoch 11/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 58.8307 - accuracy: 0.3908\n",
      "Epoch 12/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 50.8240 - accuracy: 0.4007\n",
      "Epoch 13/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 55.8435 - accuracy: 0.4005\n",
      "Epoch 14/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 58.0210 - accuracy: 0.3845\n",
      "Epoch 15/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 45.7405 - accuracy: 0.3910\n",
      "Epoch 16/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 53.3666 - accuracy: 0.3941\n",
      "Epoch 17/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 45.4742 - accuracy: 0.3839\n",
      "Epoch 18/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 50.1829 - accuracy: 0.4056\n",
      "Epoch 19/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 39.0612 - accuracy: 0.3931\n",
      "Epoch 20/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 46.5926 - accuracy: 0.3974\n",
      "Epoch 21/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 35.8577 - accuracy: 0.3921\n",
      "Epoch 22/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 35.5730 - accuracy: 0.3873\n",
      "Epoch 23/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 52.0892 - accuracy: 0.3933\n",
      "Epoch 24/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 53.2026 - accuracy: 0.3921\n",
      "Epoch 25/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 31.6822 - accuracy: 0.4028\n",
      "Epoch 26/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 40.8743 - accuracy: 0.3964\n",
      "Epoch 27/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 54.0780 - accuracy: 0.4017\n",
      "Epoch 28/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 29.3106 - accuracy: 0.3952\n",
      "Epoch 29/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 42.6731 - accuracy: 0.3878\n",
      "Epoch 30/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 31.5963 - accuracy: 0.3882\n",
      "Epoch 31/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 35.9333 - accuracy: 0.3894\n",
      "Epoch 32/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 26.6090 - accuracy: 0.3929\n",
      "Epoch 33/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 17.8451 - accuracy: 0.4046\n",
      "Epoch 34/100\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 20.8939 - accuracy: 0.3925\n",
      "Epoch 35/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 15.5499 - accuracy: 0.3894\n",
      "Epoch 36/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 23.8681 - accuracy: 0.3954\n",
      "Epoch 37/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 21.1616 - accuracy: 0.3949\n",
      "Epoch 38/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 26.8584 - accuracy: 0.3943\n",
      "Epoch 39/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 18.8819 - accuracy: 0.3915\n",
      "Epoch 40/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 21.9416 - accuracy: 0.3972\n",
      "Epoch 41/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 18.5144 - accuracy: 0.3982\n",
      "Epoch 42/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 15.9144 - accuracy: 0.3935\n",
      "Epoch 43/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 19.7208 - accuracy: 0.3906\n",
      "Epoch 44/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 15.9069 - accuracy: 0.3929\n",
      "Epoch 45/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 15.9969 - accuracy: 0.4005\n",
      "Epoch 46/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 14.8478 - accuracy: 0.3863\n",
      "Epoch 47/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 14.2502 - accuracy: 0.3886\n",
      "Epoch 48/100\n",
      "161/161 [==============================] - 2s 16ms/step - loss: 11.6182 - accuracy: 0.3952\n",
      "Epoch 49/100\n",
      "161/161 [==============================] - 2s 15ms/step - loss: 13.1898 - accuracy: 0.4015\n",
      "Epoch 50/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 15.8817 - accuracy: 0.4054\n",
      "Epoch 51/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 10.5084 - accuracy: 0.3970\n",
      "Epoch 52/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 12.5364 - accuracy: 0.4058\n",
      "Epoch 53/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 9.6235 - accuracy: 0.4025\n",
      "Epoch 54/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 10.1729 - accuracy: 0.4134\n",
      "Epoch 55/100\n",
      "161/161 [==============================] - 2s 16ms/step - loss: 10.4581 - accuracy: 0.3952\n",
      "Epoch 56/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 13.3522 - accuracy: 0.3910\n",
      "Epoch 57/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 11.8244 - accuracy: 0.3962\n",
      "Epoch 58/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 13.1728 - accuracy: 0.3939\n",
      "Epoch 59/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.7379 - accuracy: 0.4114\n",
      "Epoch 60/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 16.6371 - accuracy: 0.3941\n",
      "Epoch 61/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.6749 - accuracy: 0.4171\n",
      "Epoch 62/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.7477 - accuracy: 0.3935\n",
      "Epoch 63/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.7149 - accuracy: 0.4023\n",
      "Epoch 64/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.6424 - accuracy: 0.3869\n",
      "Epoch 65/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.0991 - accuracy: 0.3890\n",
      "Epoch 66/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.8048 - accuracy: 0.4054\n",
      "Epoch 67/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.8698 - accuracy: 0.3997\n",
      "Epoch 68/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.1453 - accuracy: 0.3964\n",
      "Epoch 69/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.9946 - accuracy: 0.3978\n",
      "Epoch 70/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.2533 - accuracy: 0.3974\n",
      "Epoch 71/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.7107 - accuracy: 0.4007\n",
      "Epoch 72/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.3100 - accuracy: 0.3974\n",
      "Epoch 73/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.3698 - accuracy: 0.3906\n",
      "Epoch 74/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.9623 - accuracy: 0.3779\n",
      "Epoch 75/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.6010 - accuracy: 0.4058\n",
      "Epoch 76/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.1774 - accuracy: 0.3960\n",
      "Epoch 77/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 9.5785 - accuracy: 0.3802\n",
      "Epoch 78/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.2828 - accuracy: 0.3814\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 16ms/step - loss: 6.3486 - accuracy: 0.4030\n",
      "Epoch 80/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.8085 - accuracy: 0.3972\n",
      "Epoch 81/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.3832 - accuracy: 0.3993\n",
      "Epoch 82/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 5.3480 - accuracy: 0.4067\n",
      "Epoch 83/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.6159 - accuracy: 0.3880\n",
      "Epoch 84/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.2811 - accuracy: 0.3902\n",
      "Epoch 85/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.4372 - accuracy: 0.3855\n",
      "Epoch 86/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.2208 - accuracy: 0.3837\n",
      "Epoch 87/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 5.8564 - accuracy: 0.3929\n",
      "Epoch 88/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 5.4142 - accuracy: 0.4027\n",
      "Epoch 89/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.4443 - accuracy: 0.3939\n",
      "Epoch 90/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 5.6256 - accuracy: 0.3941\n",
      "Epoch 91/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.1321 - accuracy: 0.4050\n",
      "Epoch 92/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.9614 - accuracy: 0.3947\n",
      "Epoch 93/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.3801 - accuracy: 0.3908\n",
      "Epoch 94/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 6.8963 - accuracy: 0.3993\n",
      "Epoch 95/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 5.3074 - accuracy: 0.3943\n",
      "Epoch 96/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.8081 - accuracy: 0.3964\n",
      "Epoch 97/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.5248 - accuracy: 0.3927\n",
      "Epoch 98/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.5641 - accuracy: 0.3847\n",
      "Epoch 99/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 7.3742 - accuracy: 0.3917\n",
      "Epoch 100/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 8.0173 - accuracy: 0.3935\n",
      "38/38 [==============================] - 1s 19ms/step\n",
      "Train model_7...\n",
      "Epoch 1/100\n",
      "161/161 [==============================] - 5s 17ms/step - loss: 1137.5203 - accuracy: 0.3650\n",
      "Epoch 2/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 237.8169 - accuracy: 0.3666\n",
      "Epoch 3/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 216.4949 - accuracy: 0.3777\n",
      "Epoch 4/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 172.5912 - accuracy: 0.3632\n",
      "Epoch 5/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 129.8149 - accuracy: 0.3695\n",
      "Epoch 6/100\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 107.0071 - accuracy: 0.3753\n",
      "Epoch 7/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 101.2936 - accuracy: 0.3621\n",
      "Epoch 8/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 128.3571 - accuracy: 0.3687\n",
      "Epoch 9/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 67.2836 - accuracy: 0.3724\n",
      "Epoch 10/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 87.0018 - accuracy: 0.3771\n",
      "Epoch 11/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 75.4289 - accuracy: 0.3746\n",
      "Epoch 12/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 76.8149 - accuracy: 0.3738\n",
      "Epoch 13/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 66.9499 - accuracy: 0.3794\n",
      "Epoch 14/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 57.7353 - accuracy: 0.3722\n",
      "Epoch 15/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 58.8543 - accuracy: 0.3773\n",
      "Epoch 16/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 62.7711 - accuracy: 0.3584\n",
      "Epoch 17/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 66.0492 - accuracy: 0.3710\n",
      "Epoch 18/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 82.6185 - accuracy: 0.3783\n",
      "Epoch 19/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 50.1474 - accuracy: 0.3709\n",
      "Epoch 20/100\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 55.6120 - accuracy: 0.3646\n",
      "Epoch 21/100\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 61.9178 - accuracy: 0.3714\n",
      "Epoch 22/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 57.4056 - accuracy: 0.3730\n",
      "Epoch 23/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 43.4593 - accuracy: 0.3591\n",
      "Epoch 24/100\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 43.6827 - accuracy: 0.3670\n",
      "Epoch 25/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 36.4459 - accuracy: 0.3707\n",
      "Epoch 26/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 34.1101 - accuracy: 0.3623\n",
      "Epoch 27/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 46.0663 - accuracy: 0.3757\n",
      "Epoch 28/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 31.5742 - accuracy: 0.3646\n",
      "Epoch 29/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 37.7858 - accuracy: 0.3627\n",
      "Epoch 30/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 36.7250 - accuracy: 0.3867\n",
      "Epoch 31/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 35.0146 - accuracy: 0.3818\n",
      "Epoch 32/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 27.0752 - accuracy: 0.3779\n",
      "Epoch 33/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 30.9533 - accuracy: 0.3707\n",
      "Epoch 34/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 30.6808 - accuracy: 0.3687\n",
      "Epoch 35/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 40.2183 - accuracy: 0.3597\n",
      "Epoch 36/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 78.0152 - accuracy: 0.3720\n",
      "Epoch 37/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 28.1613 - accuracy: 0.3683\n",
      "Epoch 38/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 24.3183 - accuracy: 0.3718\n",
      "Epoch 39/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 24.3739 - accuracy: 0.3586\n",
      "Epoch 40/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 25.4070 - accuracy: 0.3683\n",
      "Epoch 41/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 27.6218 - accuracy: 0.3712\n",
      "Epoch 42/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 20.3610 - accuracy: 0.3750\n",
      "Epoch 43/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 18.6129 - accuracy: 0.3781\n",
      "Epoch 44/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 27.3546 - accuracy: 0.3701\n",
      "Epoch 45/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 27.5524 - accuracy: 0.3601\n",
      "Epoch 46/100\n",
      "161/161 [==============================] - 3s 16ms/step - loss: 21.7680 - accuracy: 0.3779\n",
      "Epoch 47/100\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 19.9360 - accuracy: 0.3792\n",
      "Epoch 48/100\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 19.4446 - accuracy: 0.3699\n",
      "Epoch 49/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 18.1093 - accuracy: 0.3820\n",
      "Epoch 50/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 15.7803 - accuracy: 0.3648\n",
      "Epoch 51/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 14.1208 - accuracy: 0.3761\n",
      "Epoch 52/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 15.4845 - accuracy: 0.3699\n",
      "Epoch 53/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 19.9699 - accuracy: 0.3761\n",
      "Epoch 54/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 17.7752 - accuracy: 0.3673\n",
      "Epoch 55/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.6620 - accuracy: 0.3742\n",
      "Epoch 56/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 17.3073 - accuracy: 0.3677\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 4s 26ms/step - loss: 15.9389 - accuracy: 0.3595\n",
      "Epoch 58/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 19.2748 - accuracy: 0.3712\n",
      "Epoch 59/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.7730 - accuracy: 0.3658\n",
      "Epoch 60/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 15.6489 - accuracy: 0.3658\n",
      "Epoch 61/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.1039 - accuracy: 0.3876\n",
      "Epoch 62/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.5771 - accuracy: 0.3691\n",
      "Epoch 63/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.6135 - accuracy: 0.3818\n",
      "Epoch 64/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.9759 - accuracy: 0.3679\n",
      "Epoch 65/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.8307 - accuracy: 0.3650\n",
      "Epoch 66/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.4841 - accuracy: 0.3693\n",
      "Epoch 67/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.7448 - accuracy: 0.3720\n",
      "Epoch 68/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.7612 - accuracy: 0.3765\n",
      "Epoch 69/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 17.2794 - accuracy: 0.3664\n",
      "Epoch 70/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 14.1925 - accuracy: 0.3601\n",
      "Epoch 71/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 11.8746 - accuracy: 0.3691\n",
      "Epoch 72/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 15.5198 - accuracy: 0.3705\n",
      "Epoch 73/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 14.2414 - accuracy: 0.3714\n",
      "Epoch 74/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 11.5558 - accuracy: 0.3701\n",
      "Epoch 75/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 10.6961 - accuracy: 0.3687\n",
      "Epoch 76/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 10.9932 - accuracy: 0.3654\n",
      "Epoch 77/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 11.0032 - accuracy: 0.3671\n",
      "Epoch 78/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.3838 - accuracy: 0.3781\n",
      "Epoch 79/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 16.7709 - accuracy: 0.3599\n",
      "Epoch 80/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.6824 - accuracy: 0.3726\n",
      "Epoch 81/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 10.4646 - accuracy: 0.3789\n",
      "Epoch 82/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.5477 - accuracy: 0.3720\n",
      "Epoch 83/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 14.4035 - accuracy: 0.3552\n",
      "Epoch 84/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.5379 - accuracy: 0.3746\n",
      "Epoch 85/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 16.2449 - accuracy: 0.3779\n",
      "Epoch 86/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 11.0055 - accuracy: 0.3617\n",
      "Epoch 87/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.3143 - accuracy: 0.3709\n",
      "Epoch 88/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 13.2128 - accuracy: 0.3709\n",
      "Epoch 89/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.1586 - accuracy: 0.3642\n",
      "Epoch 90/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 11.9691 - accuracy: 0.3656\n",
      "Epoch 91/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 10.4908 - accuracy: 0.3671\n",
      "Epoch 92/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.4077 - accuracy: 0.3732\n",
      "Epoch 93/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 15.9184 - accuracy: 0.3670\n",
      "Epoch 94/100\n",
      "161/161 [==============================] - 4s 27ms/step - loss: 9.3946 - accuracy: 0.3705\n",
      "Epoch 95/100\n",
      "161/161 [==============================] - 4s 27ms/step - loss: 15.3396 - accuracy: 0.3611\n",
      "Epoch 96/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.8544 - accuracy: 0.3810\n",
      "Epoch 97/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 9.6961 - accuracy: 0.3584\n",
      "Epoch 98/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 11.5487 - accuracy: 0.3759\n",
      "Epoch 99/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 10.0044 - accuracy: 0.3697\n",
      "Epoch 100/100\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 12.4512 - accuracy: 0.3763\n",
      "37/37 [==============================] - 1s 8ms/step\n",
      "Train model_15...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 6s 26ms/step - loss: 1669.6880 - accuracy: 0.4148\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 452.9454 - accuracy: 0.4140\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 202.1279 - accuracy: 0.4089\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 260.1525 - accuracy: 0.4213\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 145.1199 - accuracy: 0.4193\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 140.4062 - accuracy: 0.4134\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 150.8073 - accuracy: 0.4142\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 98.4650 - accuracy: 0.4230\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 83.4919 - accuracy: 0.4174\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 95.4711 - accuracy: 0.4078\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 93.3419 - accuracy: 0.4131\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 65.4062 - accuracy: 0.4254\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 103.6495 - accuracy: 0.4070\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 73.5230 - accuracy: 0.4248\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 77.6125 - accuracy: 0.4177\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 81.8096 - accuracy: 0.4152\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 54.5146 - accuracy: 0.3998\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 54.8384 - accuracy: 0.4179\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 58.6112 - accuracy: 0.4113\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 64.9001 - accuracy: 0.4047\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 42.3597 - accuracy: 0.4201\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 60.2839 - accuracy: 0.4105\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 58.1081 - accuracy: 0.4136\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 49.4039 - accuracy: 0.4074\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 48.5229 - accuracy: 0.4056\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 47.2033 - accuracy: 0.4170\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 40.8912 - accuracy: 0.4209\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 43.1603 - accuracy: 0.4189\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 46.3967 - accuracy: 0.4201\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 51.2248 - accuracy: 0.4230\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 40.5181 - accuracy: 0.4123\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 43.8280 - accuracy: 0.4240\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 55.9036 - accuracy: 0.4154\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 43.4491 - accuracy: 0.4123\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s 26ms/step - loss: 39.9480 - accuracy: 0.4158\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 41.6549 - accuracy: 0.4109\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 4s 24ms/step - loss: 23.9780 - accuracy: 0.4117\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 4s 23ms/step - loss: 27.8416 - accuracy: 0.4162\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 28.3264 - accuracy: 0.4078\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 33.7278 - accuracy: 0.4175\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 38.4108 - accuracy: 0.4144\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 32.8645 - accuracy: 0.4074\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 23.9158 - accuracy: 0.4089\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 26.6730 - accuracy: 0.4099\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 25.4338 - accuracy: 0.4172\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 21.9835 - accuracy: 0.4154\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 20.7476 - accuracy: 0.4142\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 27.6839 - accuracy: 0.4142\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 26.6528 - accuracy: 0.4168\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 29.1917 - accuracy: 0.4152\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 22.0417 - accuracy: 0.4060\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 27.5229 - accuracy: 0.4039\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 17.7304 - accuracy: 0.4029\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.3979 - accuracy: 0.4142\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 19.3451 - accuracy: 0.4203\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.1146 - accuracy: 0.4209\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 21.0772 - accuracy: 0.4146\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.0157 - accuracy: 0.4166\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.0970 - accuracy: 0.4285\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.5974 - accuracy: 0.4095\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.3563 - accuracy: 0.4129\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.5242 - accuracy: 0.4127\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 21.0053 - accuracy: 0.4117\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 19.1564 - accuracy: 0.4039\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 20.3655 - accuracy: 0.4017\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.3140 - accuracy: 0.4259\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 11.7377 - accuracy: 0.4031\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 17.7935 - accuracy: 0.4025\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.8621 - accuracy: 0.4197\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 17.9945 - accuracy: 0.4148\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.3508 - accuracy: 0.4240\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 17.8614 - accuracy: 0.4064\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.8381 - accuracy: 0.4136\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.6858 - accuracy: 0.4185\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.9158 - accuracy: 0.4152\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 17.4007 - accuracy: 0.4011\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 16.9043 - accuracy: 0.4121\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.6983 - accuracy: 0.4121\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 11.8030 - accuracy: 0.4191\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.2828 - accuracy: 0.4068\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.0217 - accuracy: 0.4088\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.2776 - accuracy: 0.4086\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 11.9278 - accuracy: 0.4131\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 16.4577 - accuracy: 0.4179\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 9.7063 - accuracy: 0.4174\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.8158 - accuracy: 0.4123\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.9520 - accuracy: 0.4150\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.9829 - accuracy: 0.4025\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.3491 - accuracy: 0.4035\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.0052 - accuracy: 0.4113\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.6874 - accuracy: 0.4091\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.0309 - accuracy: 0.4209\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.3434 - accuracy: 0.4203\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.9338 - accuracy: 0.4123\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 9.9606 - accuracy: 0.4058\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.8829 - accuracy: 0.4101\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.7586 - accuracy: 0.4105\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 8.9905 - accuracy: 0.4211\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.2889 - accuracy: 0.4172\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.0187 - accuracy: 0.4209\n",
      "37/37 [==============================] - 1s 8ms/step\n",
      "Train model_30...\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 6s 26ms/step - loss: 1212.2358 - accuracy: 0.4452\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 174.7778 - accuracy: 0.4413\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 139.7901 - accuracy: 0.4460\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 90.5793 - accuracy: 0.4405\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 67.4367 - accuracy: 0.4533\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 71.5135 - accuracy: 0.4540\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 56.0588 - accuracy: 0.4470\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 70.4229 - accuracy: 0.4587\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 44.6162 - accuracy: 0.4519\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 49.7721 - accuracy: 0.4425\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 53.8495 - accuracy: 0.4452\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 50.0772 - accuracy: 0.4415\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s 26ms/step - loss: 45.8307 - accuracy: 0.4680\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 43.7670 - accuracy: 0.4456\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 53.3488 - accuracy: 0.4560\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 37.7990 - accuracy: 0.4460\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 31.5257 - accuracy: 0.4568\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 37.9613 - accuracy: 0.4560\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 34.9914 - accuracy: 0.4531\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 27.9972 - accuracy: 0.4540\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 30.0813 - accuracy: 0.4419\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 33.0732 - accuracy: 0.4511\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 44.0892 - accuracy: 0.4560\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 31.1140 - accuracy: 0.4470\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 29.3293 - accuracy: 0.4586\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 29.7545 - accuracy: 0.4503\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 4s 24ms/step - loss: 27.6225 - accuracy: 0.4446\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 3s 22ms/step - loss: 25.1054 - accuracy: 0.4535\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 29.4236 - accuracy: 0.4411\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 21.7499 - accuracy: 0.4523\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 20.5109 - accuracy: 0.4392\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 21.0819 - accuracy: 0.4472\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 26.9177 - accuracy: 0.4423\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 26.0535 - accuracy: 0.4470\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 18.9620 - accuracy: 0.4523\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 22.3484 - accuracy: 0.4535\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 15.1309 - accuracy: 0.4478\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 16.3365 - accuracy: 0.4478\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 21.3247 - accuracy: 0.4362\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.8613 - accuracy: 0.4442\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.3525 - accuracy: 0.4580\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.8112 - accuracy: 0.4431\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 14.6905 - accuracy: 0.4580\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.0136 - accuracy: 0.4531\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 12.5581 - accuracy: 0.4472\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 10.8315 - accuracy: 0.4509\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 16.6411 - accuracy: 0.4470\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 8.6735 - accuracy: 0.4589\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 10.5719 - accuracy: 0.4603\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 9.5429 - accuracy: 0.4419\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 10.4470 - accuracy: 0.4488\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 13.9598 - accuracy: 0.4437\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 7.3629 - accuracy: 0.4503\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 11.3270 - accuracy: 0.4515\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 10.0850 - accuracy: 0.4601\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 9.8107 - accuracy: 0.4531\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 7.2505 - accuracy: 0.4491\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 6.6344 - accuracy: 0.4542\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 8.5734 - accuracy: 0.4468\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 11.1760 - accuracy: 0.4488\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 7.9218 - accuracy: 0.4493\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 7.3410 - accuracy: 0.4560\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 6.4488 - accuracy: 0.4525\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 7.0664 - accuracy: 0.4470\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.8834 - accuracy: 0.4550\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 10.8197 - accuracy: 0.4474\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 9.3893 - accuracy: 0.4548\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.7426 - accuracy: 0.4544\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.3957 - accuracy: 0.4586\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 7.9954 - accuracy: 0.4439\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 8.6489 - accuracy: 0.4519\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 8.1060 - accuracy: 0.4617\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.3978 - accuracy: 0.4633\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 6.2109 - accuracy: 0.4576\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.0688 - accuracy: 0.4607\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 8.0092 - accuracy: 0.4384\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 7.7233 - accuracy: 0.4343\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 6.9801 - accuracy: 0.4388\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 5.2559 - accuracy: 0.4392\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 3.9413 - accuracy: 0.4419\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.7976 - accuracy: 0.4345\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 3.9310 - accuracy: 0.4421\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 3.7544 - accuracy: 0.4397\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.3347 - accuracy: 0.4505\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.7506 - accuracy: 0.4358\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 6.3906 - accuracy: 0.4472\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.6016 - accuracy: 0.4250\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 5.3357 - accuracy: 0.4358\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.6122 - accuracy: 0.4517\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.3736 - accuracy: 0.4437\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.7762 - accuracy: 0.4505\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 4s 27ms/step - loss: 4.1914 - accuracy: 0.4411\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 3.3153 - accuracy: 0.4435\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.0106 - accuracy: 0.4368\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 4s 27ms/step - loss: 5.9800 - accuracy: 0.4407\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.1403 - accuracy: 0.4623\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.3023 - accuracy: 0.4384\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.9221 - accuracy: 0.4384\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 5.7082 - accuracy: 0.4486\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 4.6070 - accuracy: 0.4584\n",
      "37/37 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Train model_1...')\n",
    "model_1.fit(x_train_1, y_train_1_e, epochs=100, verbose=1)\n",
    "p_test_1 = model_1.predict(x_test_1)\n",
    "\n",
    "print('Train model_7...')\n",
    "model_7.fit(x_train_7, y_train_7_e, epochs=100, verbose=1)\n",
    "p_test_7 = model_7.predict(x_test_7)\n",
    "\n",
    "print('Train model_15...')\n",
    "model_15.fit(x_train_15, y_train_15_e, epochs=100, verbose=1)\n",
    "p_test_15 = model_15.predict(x_test_15)\n",
    "\n",
    "print('Train model_30...')\n",
    "model_30.fit(x_train_30, y_train_30_e, epochs=100, verbose=1)\n",
    "p_test_30 = model_30.predict(x_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fc61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('/home/work/nlp/TCN_models/classification_model/v3/kospi_1day_classification_v3.h5')\n",
    "model_7.save('/home/work/nlp/TCN_models/classification_model/v3/kospi_7days_classification_v3.h5')\n",
    "model_15.save('/home/work/nlp/TCN_models/classification_model/v3/kospi_15days_classification_v3.h5')\n",
    "model_30.save('/home/work/nlp/TCN_models/classification_model/v3/kospi_30days_classification_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0178c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 25ms/step - loss: 4.7377 - accuracy: 0.3538\n",
      "\n",
      " Accuracy: 0.3538\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 31.6821 - accuracy: 0.4088\n",
      "\n",
      " Accuracy: 0.4088\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 22.4626 - accuracy: 0.4609\n",
      "\n",
      " Accuracy: 0.4609\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 26.4980 - accuracy: 0.4729\n",
      "\n",
      " Accuracy: 0.4729\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy: %.4f' % (model_1.evaluate(x_test_1, y_test_1_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_7.evaluate(x_test_7, y_test_7_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_15.evaluate(x_test_15, y_test_15_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_30.evaluate(x_test_30, y_test_30_e)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.05 / TensorFlow 2.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

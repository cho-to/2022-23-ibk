{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tcn in /home/work/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (1.21.1)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (0.16.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (63.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (22.12.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (4.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.29.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (14.0.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (3.19.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: finance-datareader in /home/work/.local/lib/python3.8/site-packages (0.9.50)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.64.0)\n",
      "Requirement already satisfied: requests-file in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (2.27.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.5.0)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from requests-file->finance-datareader) (1.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn\n",
    "!pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ffe65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-01-26 08:42:08.314667: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-26 08:42:08.510172: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-26 08:42:11.537569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-26 08:42:11.537771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-26 08:42:11.537793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "452f7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "1996-12-11  705.989990  709.479980  704.429993  704.679993  704.679993   \n",
      "1996-12-12  705.109985  706.010010  688.739990  689.380005  689.380005   \n",
      "1996-12-13  690.440002  695.719971  677.640015  689.070007  689.070007   \n",
      "1996-12-16  686.969971  686.969971  667.710022  673.919983  673.919983   \n",
      "1996-12-17  675.349976  680.090027  660.390015  663.349976  663.349976   \n",
      "\n",
      "             Volume   Change1  Change7  Change15  Change30  \n",
      "Date                                                        \n",
      "1996-12-11  28000.0       NaN      NaN       NaN       NaN  \n",
      "1996-12-12  25900.0 -0.021712      NaN       NaN       NaN  \n",
      "1996-12-13  26500.0 -0.000450      NaN       NaN       NaN  \n",
      "1996-12-16  22800.0 -0.021986      NaN       NaN       NaN  \n",
      "1996-12-17  31600.0 -0.015684      NaN       NaN       NaN  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_train = fdr.DataReader('KS11', '1990-01-01','2017-12-31')\n",
    "kospi_train['Change1'] = kospi_train['Close']/kospi_train['Close'].shift(1) - 1\n",
    "kospi_train['Change7'] = kospi_train['Close']/kospi_train['Close'].shift(7) - 1\n",
    "kospi_train['Change15'] = kospi_train['Close']/kospi_train['Close'].shift(15) - 1\n",
    "kospi_train['Change30'] = kospi_train['Close']/kospi_train['Close'].shift(30) - 1\n",
    "print(kospi_train.head())\n",
    "print(kospi_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2415e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "1997-01-24  669.030029  679.559998  658.179993  679.559998  679.559998   \n",
      "1997-01-27  684.309998  685.460022  664.679993  664.700012  664.700012   \n",
      "1997-01-28  661.659973  677.630005  653.419983  662.849976  662.849976   \n",
      "1997-01-29  663.330017  672.900024  654.950012  663.559998  663.559998   \n",
      "1997-01-30  663.650024  679.039978  662.270020  676.520020  676.520020   \n",
      "\n",
      "             Volume   Change1   Change7  Change15  Change30  \n",
      "Date                                                         \n",
      "1997-01-24  35500.0  0.003915 -0.028867  0.039416 -0.013801  \n",
      "1997-01-27  28300.0 -0.021867 -0.066249  0.060347 -0.013681  \n",
      "1997-01-28  30400.0 -0.002783 -0.054665  0.084772 -0.000754  \n",
      "1997-01-29  30200.0  0.001071 -0.076413  0.067830  0.003281  \n",
      "1997-01-30  28800.0  0.019531 -0.020303  0.057277 -0.020913  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_train = kospi_train.dropna()\n",
    "print(kospi_train.head())\n",
    "print(kospi_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff64154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1997-01-24     679.559998\n",
      "1997-01-27     664.700012\n",
      "1997-01-28     662.849976\n",
      "1997-01-29     663.559998\n",
      "1997-01-30     676.520020\n",
      "                 ...     \n",
      "2017-12-21    2429.830078\n",
      "2017-12-22    2440.540039\n",
      "2017-12-26    2427.340088\n",
      "2017-12-27    2436.669922\n",
      "2017-12-28    2467.489990\n",
      "Name: Close, Length: 4668, dtype: float64 Date\n",
      "1997-01-24    0.003915\n",
      "1997-01-27   -0.021867\n",
      "1997-01-28   -0.002783\n",
      "1997-01-29    0.001071\n",
      "1997-01-30    0.019531\n",
      "                ...   \n",
      "2017-12-21   -0.019649\n",
      "2017-12-22    0.004408\n",
      "2017-12-26   -0.005409\n",
      "2017-12-27    0.003844\n",
      "2017-12-28    0.012648\n",
      "Name: Change1, Length: 4668, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kospi_train_close = kospi_train['Close']\n",
    "kospi_train_c1 = kospi_train['Change1']\n",
    "kospi_train_c7 = kospi_train['Change7']\n",
    "kospi_train_c15 = kospi_train['Change15']\n",
    "kospi_train_c30 = kospi_train['Change30']\n",
    "print(kospi_train_close, kospi_train_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c18820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2018-01-02  2474.860107  2481.020020  2465.939941  2479.649902  2479.649902   \n",
      "2018-01-03  2484.629883  2493.399902  2481.909912  2486.350098  2486.350098   \n",
      "2018-01-04  2502.500000  2502.500000  2466.449951  2466.459961  2466.459961   \n",
      "2018-01-05  2476.850098  2497.520020  2475.510010  2497.520020  2497.520020   \n",
      "2018-01-08  2510.699951  2515.370117  2494.179932  2513.280029  2513.280029   \n",
      "\n",
      "            Volume   Change1  Change7  Change15  Change30  \n",
      "Date                                                       \n",
      "2018-01-02  262200       NaN      NaN       NaN       NaN  \n",
      "2018-01-03  331100  0.002702      NaN       NaN       NaN  \n",
      "2018-01-04  333800 -0.008000      NaN       NaN       NaN  \n",
      "2018-01-05  308800  0.012593      NaN       NaN       NaN  \n",
      "2018-01-08  311400  0.006310      NaN       NaN       NaN  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_test = fdr.DataReader('KS11', '2018-01-01')\n",
    "kospi_test['Change1'] = kospi_test['Close']/kospi_test['Close'].shift(1) - 1\n",
    "kospi_test['Change7'] = kospi_test['Close']/kospi_test['Close'].shift(7) - 1\n",
    "kospi_test['Change15'] = kospi_test['Close']/kospi_test['Close'].shift(15) - 1\n",
    "kospi_test['Change30'] = kospi_test['Close']/kospi_test['Close'].shift(30) - 1\n",
    "print(kospi_test.head())\n",
    "print(kospi_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c764202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2018-02-13  2402.889893  2421.800049  2388.540039  2395.189941  2395.189941   \n",
      "2018-02-14  2412.469971  2426.629883  2408.020020  2421.830078  2421.830078   \n",
      "2018-02-19  2452.520020  2455.120117  2428.149902  2442.820068  2442.820068   \n",
      "2018-02-20  2433.350098  2438.479980  2411.229980  2415.120117  2415.120117   \n",
      "2018-02-21  2417.729980  2432.449951  2404.020020  2429.649902  2429.649902   \n",
      "\n",
      "            Volume   Change1   Change7  Change15  Change30  \n",
      "Date                                                        \n",
      "2018-02-13  423400  0.004113 -0.051556 -0.055748 -0.034061  \n",
      "2018-02-14  305700  0.011122 -0.028061 -0.045772 -0.025950  \n",
      "2018-02-19  322100  0.008667 -0.004276 -0.046604 -0.009585  \n",
      "2018-02-20  421500 -0.011339  0.007744 -0.062002 -0.032993  \n",
      "2018-02-21  432300  0.006016  0.009150 -0.064868 -0.033275  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_test = kospi_test.dropna()\n",
    "print(kospi_test.head())\n",
    "print(kospi_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48c0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2018-02-13    2395.189941\n",
      "2018-02-14    2421.830078\n",
      "2018-02-19    2442.820068\n",
      "2018-02-20    2415.120117\n",
      "2018-02-21    2429.649902\n",
      "                 ...     \n",
      "2023-01-18    2368.320068\n",
      "2023-01-19    2380.340088\n",
      "2023-01-20    2395.260010\n",
      "2023-01-25    2428.570068\n",
      "2023-01-26    2468.649902\n",
      "Name: Close, Length: 1217, dtype: float64 Date\n",
      "2018-02-13    0.004113\n",
      "2018-02-14    0.011122\n",
      "2018-02-19    0.008667\n",
      "2018-02-20   -0.011339\n",
      "2018-02-21    0.006016\n",
      "                ...   \n",
      "2023-01-18   -0.004652\n",
      "2023-01-19    0.005075\n",
      "2023-01-20    0.006268\n",
      "2023-01-25    0.013907\n",
      "2023-01-26    0.016503\n",
      "Name: Change1, Length: 1217, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kospi_test_close = kospi_test['Close']\n",
    "kospi_test_c1 = kospi_test['Change1']\n",
    "kospi_test_c7 = kospi_test['Change7']\n",
    "kospi_test_c15 = kospi_test['Change15']\n",
    "kospi_test_c30 = kospi_test['Change30']\n",
    "print(kospi_test_close, kospi_test_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8396c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41125768 1.11223484 0.86669953 ... 0.62679791 1.39066564 1.65034703]\n"
     ]
    }
   ],
   "source": [
    "kospi_train_close = kospi_train_close.values\n",
    "kospi_train_c1 = 100 * kospi_train_c1.values\n",
    "kospi_train_c7 = 100 * kospi_train_c7.values\n",
    "kospi_train_c15 = 100 * kospi_train_c15.values\n",
    "kospi_train_c30 = 100 * kospi_train_c30.values\n",
    "\n",
    "kospi_test_close = kospi_test_close.values\n",
    "kospi_test_c1 = 100 * kospi_test_c1.values\n",
    "kospi_test_c7 = 100 * kospi_test_c7.values\n",
    "kospi_test_c15 = 100 * kospi_test_c15.values\n",
    "kospi_test_c30 = 100 * kospi_test_c30.values\n",
    "print(kospi_test_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1334a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_window = 60\n",
    "x_train_1, y_train_1 = [], []\n",
    "x_train_7, y_train_7 = [], []\n",
    "x_train_15, y_train_15 = [], []\n",
    "x_train_30, y_train_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ad8662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_train_close)-1):\n",
    "    x_train_1.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_1.append(kospi_train_c1[i])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train_close)-6):\n",
    "    x_train_7.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_7.append(kospi_train_c7[i+6])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train_close)-14):\n",
    "    x_train_15.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_15.append(kospi_train_c15[i+14])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train_close)-29):\n",
    "    x_train_30.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_30.append(kospi_train_c30[i+29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02aedcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_train_1)):\n",
    "    if y_train_1[index]>= -0.5 and y_train_1[index] < 0.5:\n",
    "        y_train_1[index] = 'neutral'\n",
    "    elif y_train_1[index] >= 0.5:\n",
    "        y_train_1[index] = 'increase'\n",
    "    else:\n",
    "        y_train_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_train_7)):\n",
    "    if y_train_7[index]>= -0.5 and y_train_7[index] < 0.5:\n",
    "        y_train_7[index] = 'neutral'\n",
    "    elif y_train_7[index] >= 0.5:\n",
    "        y_train_7[index] = 'increase'\n",
    "    else:\n",
    "        y_train_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_15)):\n",
    "    if y_train_15[index]>= -0.5 and y_train_15[index] < 0.5:\n",
    "        y_train_15[index] = 'neutral'\n",
    "    elif y_train_15[index] >= 0.5:\n",
    "        y_train_15[index] = 'increase'\n",
    "    else:\n",
    "        y_train_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_30)):\n",
    "    if y_train_30[index]>= -0.5 and y_train_30[index] < 0.5:\n",
    "        y_train_30[index] = 'neutral'\n",
    "    elif y_train_30[index] >= 0.5:\n",
    "        y_train_30[index] = 'increase'\n",
    "    else:\n",
    "        y_train_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5ef8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4607, 60, 1) (4602, 60, 1) (4594, 60, 1) (4579, 60, 1)\n",
      "(4607,) (4602,) (4594,) (4579,)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(x_train_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "x_train_1 = x_train_1.reshape((4607, -1, 1))\n",
    "#y_train_1 = y_train_1.reshape((-1, 1))\n",
    "\n",
    "x_train_7 = np.array(x_train_7)\n",
    "y_train_7 = np.array(y_train_7)\n",
    "x_train_7 = x_train_7.reshape((4602, -1, 1))\n",
    "#y_train_7 = y_train_7.reshape((-1, 1))\n",
    "\n",
    "x_train_15 = np.array(x_train_15)\n",
    "y_train_15 = np.array(y_train_15)\n",
    "x_train_15 = x_train_15.reshape((4594, -1, 1))\n",
    "#y_train_15 = y_train_15.reshape((-1, 1))\n",
    "\n",
    "x_train_30 = np.array(x_train_30)\n",
    "y_train_30 = np.array(y_train_30)\n",
    "x_train_30 = x_train_30.reshape((4579, -1, 1))\n",
    "#y_train_30 = y_train_30.reshape((-1, 1))\n",
    "\n",
    "print(x_train_1.shape, x_train_7.shape, x_train_15.shape, x_train_30.shape)\n",
    "print(y_train_1.shape, y_train_7.shape, y_train_15.shape, y_train_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "612667a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1, y_test_1 = [], []\n",
    "x_test_7, y_test_7 = [], []\n",
    "x_test_15, y_test_15 = [], []\n",
    "x_test_30, y_test_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c77c5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_test_close)-1):\n",
    "    x_test_1.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_1.append(kospi_test_c1[i])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test_close)-6):\n",
    "    x_test_7.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_7.append(kospi_test_c7[i+6])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test_close)-14):\n",
    "    x_test_15.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_15.append(kospi_test_c15[i+14])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test_close)-29):\n",
    "    x_test_30.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_30.append(kospi_test_c30[i+29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb64b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_test_1)):\n",
    "    if y_test_1[index]>= -0.5 and y_test_1[index] < 0.5:\n",
    "        y_test_1[index] = 'neutral'\n",
    "    elif y_test_1[index] >= 0.5:\n",
    "        y_test_1[index] = 'increase'\n",
    "    else:\n",
    "        y_test_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_test_7)):\n",
    "    if y_test_7[index]>= -0.5 and y_test_7[index] < 0.5:\n",
    "        y_test_7[index] = 'neutral'\n",
    "    elif y_test_7[index] >= 0.5:\n",
    "        y_test_7[index] = 'increase'\n",
    "    else:\n",
    "        y_test_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_15)):\n",
    "    if y_test_15[index]>= -0.5 and y_test_15[index] < 0.5:\n",
    "        y_test_15[index] = 'neutral'\n",
    "    elif y_test_15[index] >= 0.5:\n",
    "        y_test_15[index] = 'increase'\n",
    "    else:\n",
    "        y_test_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_30)):\n",
    "    if y_test_30[index]>= -0.5 and y_test_30[index] < 0.5:\n",
    "        y_test_30[index] = 'neutral'\n",
    "    elif y_test_30[index] >= 0.5:\n",
    "        y_test_30[index] = 'increase'\n",
    "    else:\n",
    "        y_test_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d9be8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = np.array(x_test_1)\n",
    "y_test_1 = np.array(y_test_1)\n",
    "x_test_1 = x_test_1.reshape((1156, -1, 1))\n",
    "#y_test_1 = y_test_1.reshape((-1, 1))\n",
    "\n",
    "x_test_7 = np.array(x_test_7)\n",
    "y_test_7 = np.array(y_test_7)\n",
    "x_test_7 = x_test_7.reshape((1151, -1, 1))\n",
    "#y_test_7 = y_test_7.reshape((-1, 1))\n",
    "\n",
    "x_test_15 = np.array(x_test_15)\n",
    "y_test_15 = np.array(y_test_15)\n",
    "x_test_15 = x_test_15.reshape((1143, -1, 1))\n",
    "#y_test_15 = y_test_15.reshape((-1, 1))\n",
    "\n",
    "x_test_30 = np.array(x_test_30)\n",
    "y_test_30 = np.array(y_test_30)\n",
    "x_test_30 = x_test_30.reshape((1128, -1, 1))\n",
    "#y_test_30 = y_test_30.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c3afe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1156, 60, 1) (1151, 60, 1) (1143, 60, 1) (1128, 60, 1)\n",
      "(1156,) (1151,) (1143,) (1128,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_1.shape, x_test_7.shape, x_test_15.shape, x_test_30.shape)\n",
    "print(y_test_1.shape, y_test_7.shape, y_test_15.shape, y_test_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cd5460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_1)\n",
    "\n",
    "y_train_1_e = to_categorical(encoder.transform(y_train_1))\n",
    "y_train_7_e = to_categorical(encoder.transform(y_train_7))\n",
    "y_train_15_e = to_categorical(encoder.transform(y_train_15))\n",
    "y_train_30_e = to_categorical(encoder.transform(y_train_30))\n",
    "\n",
    "y_test_1_e = to_categorical(encoder.transform(y_test_1))\n",
    "y_test_7_e = to_categorical(encoder.transform(y_test_7))\n",
    "y_test_15_e = to_categorical(encoder.transform(y_test_15))\n",
    "y_test_30_e = to_categorical(encoder.transform(y_test_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8cb8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 09:28:18.053989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-26 09:28:18.054030: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-26 09:28:18.054052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-01-26 09:28:18.054351: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 64)                91136     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_1 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_2 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_3 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_7 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_7.summary()\n",
    "model_7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_15 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_15.summary()\n",
    "model_15.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_30 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_30.summary()\n",
    "model_30.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac14f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model_1...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 35.4982 - accuracy: 0.3605\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 29.2631 - accuracy: 0.3740\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 44.1744 - accuracy: 0.3469\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 31.9573 - accuracy: 0.3597\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 28.7271 - accuracy: 0.3568\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 24.4462 - accuracy: 0.3736\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 23.2888 - accuracy: 0.3647\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.9780 - accuracy: 0.3725\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 29.2586 - accuracy: 0.3621\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.6180 - accuracy: 0.3595\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.7509 - accuracy: 0.3664\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.6911 - accuracy: 0.3521\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.8798 - accuracy: 0.3510\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 23.0634 - accuracy: 0.3694\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.9281 - accuracy: 0.3603\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.6094 - accuracy: 0.3571\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 36.5478 - accuracy: 0.3681\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.2183 - accuracy: 0.3579\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 27.7096 - accuracy: 0.3710\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 38.0148 - accuracy: 0.3386\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 32.3199 - accuracy: 0.3514\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.5877 - accuracy: 0.3579\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.0339 - accuracy: 0.3657\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.7870 - accuracy: 0.3707\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.7195 - accuracy: 0.3527\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.4040 - accuracy: 0.3482\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.3911 - accuracy: 0.3545\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 17.9133 - accuracy: 0.3636\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.6972 - accuracy: 0.3566\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.0823 - accuracy: 0.3634\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.4268 - accuracy: 0.3608\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.0015 - accuracy: 0.3610\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.1093 - accuracy: 0.3464\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.1270 - accuracy: 0.3647\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.1441 - accuracy: 0.3666\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.3684 - accuracy: 0.3668\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.1376 - accuracy: 0.3529\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.0252 - accuracy: 0.3516\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.1505 - accuracy: 0.3575\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.2223 - accuracy: 0.3605\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.8959 - accuracy: 0.3623\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.3634 - accuracy: 0.3560\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.5641 - accuracy: 0.3605\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.9190 - accuracy: 0.3636\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.1661 - accuracy: 0.3640\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.1906 - accuracy: 0.3599\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.3545 - accuracy: 0.3601\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.4567 - accuracy: 0.3495\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.8349 - accuracy: 0.3690\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.3317 - accuracy: 0.3783\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.4166 - accuracy: 0.3597\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.2907 - accuracy: 0.3629\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9133 - accuracy: 0.3657\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.0859 - accuracy: 0.3547\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.2853 - accuracy: 0.3464\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.2963 - accuracy: 0.3653\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.7383 - accuracy: 0.3584\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.8501 - accuracy: 0.3720\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.8027 - accuracy: 0.3595\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.0078 - accuracy: 0.3740\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.2397 - accuracy: 0.3560\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.6423 - accuracy: 0.3603\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.5483 - accuracy: 0.3571\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.0492 - accuracy: 0.3651\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9259 - accuracy: 0.3458\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.0127 - accuracy: 0.3651\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.1365 - accuracy: 0.3614\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.4422 - accuracy: 0.3636\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.0872 - accuracy: 0.3566\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.8028 - accuracy: 0.3603\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.5960 - accuracy: 0.3540\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.2411 - accuracy: 0.3562\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.8509 - accuracy: 0.3508\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.5860 - accuracy: 0.3618\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.2936 - accuracy: 0.3623\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.8593 - accuracy: 0.3579\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.6487 - accuracy: 0.3577\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.5760 - accuracy: 0.3662\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.2322 - accuracy: 0.3479\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.2668 - accuracy: 0.3684\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.5521 - accuracy: 0.3453\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.6593 - accuracy: 0.3542\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.1455 - accuracy: 0.3538\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.1974 - accuracy: 0.3529\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.5330 - accuracy: 0.3575\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.6610 - accuracy: 0.3631\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.0934 - accuracy: 0.3625\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.3199 - accuracy: 0.3558\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.1112 - accuracy: 0.3586\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.1612 - accuracy: 0.3614\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.3569 - accuracy: 0.3577\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.1834 - accuracy: 0.3612\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.7295 - accuracy: 0.3634\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.5257 - accuracy: 0.3542\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.0341 - accuracy: 0.3627\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.0123 - accuracy: 0.3727\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.0624 - accuracy: 0.3547\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.7570 - accuracy: 0.3666\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.9205 - accuracy: 0.3597\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.5272 - accuracy: 0.3549\n",
      "37/37 [==============================] - 1s 9ms/step\n",
      "Train model_7...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 6s 26ms/step - loss: 1573.2311 - accuracy: 0.3903\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 417.1668 - accuracy: 0.4105\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 257.0611 - accuracy: 0.3959\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 197.8930 - accuracy: 0.3935\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 157.6496 - accuracy: 0.3866\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 154.2864 - accuracy: 0.4046\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 119.7319 - accuracy: 0.3994\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 151.9285 - accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 133.8005 - accuracy: 0.3994\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 85.7210 - accuracy: 0.3927\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 87.9593 - accuracy: 0.3981\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 3s 19ms/step - loss: 94.6543 - accuracy: 0.3957\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 87.4862 - accuracy: 0.3985\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 73.2482 - accuracy: 0.4053\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 44.3323 - accuracy: 0.4018\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 53.1098 - accuracy: 0.4116\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 74.5679 - accuracy: 0.3953\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 56.7750 - accuracy: 0.4111\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 59.0672 - accuracy: 0.3909\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 69.1403 - accuracy: 0.4061\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 57.0111 - accuracy: 0.3994\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 67.0292 - accuracy: 0.3907\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 46.8504 - accuracy: 0.3957\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 49.7716 - accuracy: 0.3998\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 52.5997 - accuracy: 0.4053\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 37.0149 - accuracy: 0.4079\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 55.5237 - accuracy: 0.4031\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 40.3482 - accuracy: 0.4094\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 35.9077 - accuracy: 0.4031\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 49.4281 - accuracy: 0.3961\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 39.5372 - accuracy: 0.3905\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 44.9425 - accuracy: 0.3820\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.7890 - accuracy: 0.3927\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 37.5032 - accuracy: 0.4011\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 43.4976 - accuracy: 0.3948\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 43.4194 - accuracy: 0.4005\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 32.4428 - accuracy: 0.4022\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 32.1741 - accuracy: 0.4022\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 32.7408 - accuracy: 0.3922\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 48.1483 - accuracy: 0.3996\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 28.6708 - accuracy: 0.3955\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 30.9877 - accuracy: 0.4083\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 26.9753 - accuracy: 0.4057\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 43.5496 - accuracy: 0.3896\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 23.9826 - accuracy: 0.3911\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.7893 - accuracy: 0.4094\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 26.1872 - accuracy: 0.3931\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 22.8646 - accuracy: 0.4126\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 22.4301 - accuracy: 0.3942\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.7676 - accuracy: 0.3857\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 26.0445 - accuracy: 0.3879\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 23.1209 - accuracy: 0.3990\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.1021 - accuracy: 0.4037\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.3170 - accuracy: 0.4020\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.8980 - accuracy: 0.4092\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.5249 - accuracy: 0.3918\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 26ms/step - loss: 18.4279 - accuracy: 0.4016\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.5026 - accuracy: 0.3896\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.4727 - accuracy: 0.3861\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.1656 - accuracy: 0.4033\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.2171 - accuracy: 0.3977\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.6237 - accuracy: 0.4020\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 37.4156 - accuracy: 0.3968\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 27.2288 - accuracy: 0.3950\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.2914 - accuracy: 0.4040\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.7755 - accuracy: 0.4074\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.9757 - accuracy: 0.4087\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.7295 - accuracy: 0.4100\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.2118 - accuracy: 0.4048\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.3671 - accuracy: 0.3848\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.5980 - accuracy: 0.3957\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9754 - accuracy: 0.4061\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.3460 - accuracy: 0.4018\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9853 - accuracy: 0.3916\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.6857 - accuracy: 0.4063\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.9584 - accuracy: 0.4007\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.0798 - accuracy: 0.3914\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.7060 - accuracy: 0.3922\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.7101 - accuracy: 0.4113\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.4091 - accuracy: 0.3983\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.7409 - accuracy: 0.3968\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.4053 - accuracy: 0.4066\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.6563 - accuracy: 0.3977\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.7798 - accuracy: 0.3905\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.9288 - accuracy: 0.4155\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.6034 - accuracy: 0.4011\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.5431 - accuracy: 0.4040\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.7624 - accuracy: 0.4063\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.7920 - accuracy: 0.4020\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.5608 - accuracy: 0.4083\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.5205 - accuracy: 0.3981\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.6781 - accuracy: 0.4116\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.7974 - accuracy: 0.4005\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.0973 - accuracy: 0.3985\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.7678 - accuracy: 0.4142\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.8298 - accuracy: 0.4042\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.9633 - accuracy: 0.4040\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.1643 - accuracy: 0.4046\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.9851 - accuracy: 0.4144\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.5553 - accuracy: 0.4103\n",
      "36/36 [==============================] - 1s 9ms/step\n",
      "Train model_15...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 6s 26ms/step - loss: 924.4559 - accuracy: 0.4397\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 221.7415 - accuracy: 0.4306\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 222.8714 - accuracy: 0.4504\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 163.8064 - accuracy: 0.4430\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 117.7386 - accuracy: 0.4423\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 78.4550 - accuracy: 0.4269\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 74.0343 - accuracy: 0.4397\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 65.9874 - accuracy: 0.4354\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 56.5102 - accuracy: 0.4419\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 84.8700 - accuracy: 0.4423\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 57.3449 - accuracy: 0.4445\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 68.5756 - accuracy: 0.4325\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 61.1849 - accuracy: 0.4364\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 58.2384 - accuracy: 0.4356\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 50.0292 - accuracy: 0.4351\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 49.6593 - accuracy: 0.4358\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 50.1977 - accuracy: 0.4454\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 36.5464 - accuracy: 0.4393\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 48.9291 - accuracy: 0.4316\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 17ms/step - loss: 45.1019 - accuracy: 0.4428\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 52.6576 - accuracy: 0.4343\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.6797 - accuracy: 0.4349\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 44.1394 - accuracy: 0.4419\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.5698 - accuracy: 0.4373\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 25.2452 - accuracy: 0.4454\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 60.4999 - accuracy: 0.4203\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 35.8426 - accuracy: 0.4282\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 24.6307 - accuracy: 0.4486\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 22.6456 - accuracy: 0.4408\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.3460 - accuracy: 0.4369\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 21.9847 - accuracy: 0.4349\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 22.9207 - accuracy: 0.4321\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 29.3518 - accuracy: 0.4460\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.7633 - accuracy: 0.4380\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 25.9411 - accuracy: 0.4541\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.1753 - accuracy: 0.4417\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.1468 - accuracy: 0.4358\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 22.7381 - accuracy: 0.4312\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 31.6396 - accuracy: 0.4360\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 34.5868 - accuracy: 0.4367\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 27.5791 - accuracy: 0.4412\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.9407 - accuracy: 0.4327\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.5860 - accuracy: 0.4382\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.8413 - accuracy: 0.4386\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.1318 - accuracy: 0.4316\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.1013 - accuracy: 0.4330\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.6457 - accuracy: 0.4471\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.6561 - accuracy: 0.4384\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.6865 - accuracy: 0.4417\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.5730 - accuracy: 0.4491\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.4418 - accuracy: 0.4336\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.4319 - accuracy: 0.4360\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.2648 - accuracy: 0.4391\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.7755 - accuracy: 0.4358\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.8273 - accuracy: 0.4360\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.1890 - accuracy: 0.4423\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 20.9647 - accuracy: 0.4451\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.6381 - accuracy: 0.4301\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.1837 - accuracy: 0.4334\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.1785 - accuracy: 0.4565\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.5208 - accuracy: 0.4221\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.6536 - accuracy: 0.4297\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.4963 - accuracy: 0.4375\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.5412 - accuracy: 0.4369\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.6007 - accuracy: 0.4330\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.7285 - accuracy: 0.4445\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.9281 - accuracy: 0.4417\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.2526 - accuracy: 0.4443\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.9809 - accuracy: 0.4271\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.5391 - accuracy: 0.4358\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.6873 - accuracy: 0.4369\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.3934 - accuracy: 0.4332\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.5004 - accuracy: 0.4351\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.9467 - accuracy: 0.4210\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.4890 - accuracy: 0.4523\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.3981 - accuracy: 0.4541\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.8446 - accuracy: 0.4351\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.3754 - accuracy: 0.4534\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.0044 - accuracy: 0.4369\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.7058 - accuracy: 0.4423\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.3595 - accuracy: 0.4469\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.7840 - accuracy: 0.4484\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.9487 - accuracy: 0.4560\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.4525 - accuracy: 0.4469\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.7178 - accuracy: 0.4349\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.2848 - accuracy: 0.4488\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.3733 - accuracy: 0.4269\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 6.9449 - accuracy: 0.4334\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.9274 - accuracy: 0.4434\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.7408 - accuracy: 0.4441\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.3631 - accuracy: 0.4345\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.7857 - accuracy: 0.4345\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 9.3486 - accuracy: 0.4456\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.3303 - accuracy: 0.4382\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.2182 - accuracy: 0.4456\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 6.4043 - accuracy: 0.4393\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.6595 - accuracy: 0.4347\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 6.2637 - accuracy: 0.4447\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 5.9760 - accuracy: 0.4375\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.2606 - accuracy: 0.4375\n",
      "36/36 [==============================] - 1s 20ms/step\n",
      "Train model_30...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 4s 17ms/step - loss: 1218.4095 - accuracy: 0.4518\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 206.8484 - accuracy: 0.4654\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 192.5151 - accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 144.3831 - accuracy: 0.4604\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 105.6700 - accuracy: 0.4660\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 121.4529 - accuracy: 0.4708\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 84.8118 - accuracy: 0.4473\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 93.4516 - accuracy: 0.4440\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 69.0138 - accuracy: 0.4649\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 58.1078 - accuracy: 0.4660\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 53.0239 - accuracy: 0.4573\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 59.9901 - accuracy: 0.4597\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 16ms/step - loss: 31.7027 - accuracy: 0.4689\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 55.5530 - accuracy: 0.4604\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 53.0450 - accuracy: 0.4636\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 51.3048 - accuracy: 0.4534\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 51.0413 - accuracy: 0.4551\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 52.1776 - accuracy: 0.4525\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 46.1441 - accuracy: 0.4562\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 51.8223 - accuracy: 0.4591\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 42.4416 - accuracy: 0.4591\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 36.9149 - accuracy: 0.4486\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 29.7683 - accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 32.7008 - accuracy: 0.4641\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 26.2232 - accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 43.0586 - accuracy: 0.4545\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 27.0523 - accuracy: 0.4549\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 31.7042 - accuracy: 0.4669\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 25.7239 - accuracy: 0.4652\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 31.3359 - accuracy: 0.4582\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 32.9820 - accuracy: 0.4540\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 29.5535 - accuracy: 0.4588\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 22.3188 - accuracy: 0.4433\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.6788 - accuracy: 0.4831\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.9017 - accuracy: 0.4608\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 20.7397 - accuracy: 0.4717\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 21.7527 - accuracy: 0.4634\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 21.2908 - accuracy: 0.4484\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.5240 - accuracy: 0.4588\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 24.8431 - accuracy: 0.4536\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 36.6229 - accuracy: 0.4514\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.7607 - accuracy: 0.4527\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 18.2002 - accuracy: 0.4604\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 8.8052 - accuracy: 0.4628\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 20.4353 - accuracy: 0.4684\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 46.8437 - accuracy: 0.4484\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 18.0843 - accuracy: 0.4667\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.0348 - accuracy: 0.4510\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.9872 - accuracy: 0.4630\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.8201 - accuracy: 0.4647\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 10.0786 - accuracy: 0.4508\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 13.7014 - accuracy: 0.4558\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.8160 - accuracy: 0.4564\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.6760 - accuracy: 0.4562\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.0730 - accuracy: 0.4529\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.1777 - accuracy: 0.4667\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.9472 - accuracy: 0.4521\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 9.5422 - accuracy: 0.4695\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.1855 - accuracy: 0.4674\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.3263 - accuracy: 0.4630\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.6458 - accuracy: 0.4621\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.5517 - accuracy: 0.4593\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.0987 - accuracy: 0.4717\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.1270 - accuracy: 0.4647\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.5805 - accuracy: 0.4741\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.2430 - accuracy: 0.4682\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.3117 - accuracy: 0.4601\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.5636 - accuracy: 0.4811\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 6.7954 - accuracy: 0.4693\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.0406 - accuracy: 0.4641\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.2289 - accuracy: 0.4634\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 7.5750 - accuracy: 0.4553\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 6.7893 - accuracy: 0.4704\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.3616 - accuracy: 0.4656\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.4504 - accuracy: 0.4586\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 7.9639 - accuracy: 0.4680\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.3430 - accuracy: 0.4549\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 7.0450 - accuracy: 0.4652\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.0316 - accuracy: 0.4625\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 4.9156 - accuracy: 0.4730\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 13.8575 - accuracy: 0.4514\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.0084 - accuracy: 0.4508\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 9.3744 - accuracy: 0.4562\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.1080 - accuracy: 0.4573\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 9.2785 - accuracy: 0.4842\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.4046 - accuracy: 0.4641\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.9845 - accuracy: 0.4623\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.1038 - accuracy: 0.4518\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.4807 - accuracy: 0.4584\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.0177 - accuracy: 0.4730\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.6059 - accuracy: 0.4748\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.9019 - accuracy: 0.4593\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.8544 - accuracy: 0.4706\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 7.6421 - accuracy: 0.4628\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.1711 - accuracy: 0.4599\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 6.9319 - accuracy: 0.4608\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.9097 - accuracy: 0.4649\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.1738 - accuracy: 0.4584\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.5573 - accuracy: 0.4516\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 6.9640 - accuracy: 0.4671\n",
      "36/36 [==============================] - 1s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Train model_1...')\n",
    "model_1.fit(x_train_1, y_train_1_e, epochs=100, verbose=1)\n",
    "p_test_1 = model_1.predict(x_test_1)\n",
    "\n",
    "print('Train model_7...')\n",
    "model_7.fit(x_train_7, y_train_7_e, epochs=100, verbose=1)\n",
    "p_test_7 = model_7.predict(x_test_7)\n",
    "\n",
    "print('Train model_15...')\n",
    "model_15.fit(x_train_15, y_train_15_e, epochs=100, verbose=1)\n",
    "p_test_15 = model_15.predict(x_test_15)\n",
    "\n",
    "print('Train model_30...')\n",
    "model_30.fit(x_train_30, y_train_30_e, epochs=100, verbose=1)\n",
    "p_test_30 = model_30.predict(x_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11fc61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('/home/work/nlp/TCN_models/classification_model/v4/kospi_1day_classification_v4.h5')\n",
    "model_7.save('/home/work/nlp/TCN_models/classification_model/v4/kospi_7days_classification_v4.h5')\n",
    "model_15.save('/home/work/nlp/TCN_models/classification_model/v4/kospi_15days_classification_v4.h5')\n",
    "model_30.save('/home/work/nlp/TCN_models/classification_model/v4/kospi_30days_classification_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0178c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 21ms/step - loss: 10.9633 - accuracy: 0.2855\n",
      "\n",
      " Accuracy: 0.2855\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 14.2504 - accuracy: 0.3675\n",
      "\n",
      " Accuracy: 0.3675\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.3879 - accuracy: 0.4532\n",
      "\n",
      " Accuracy: 0.4532\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 13.5162 - accuracy: 0.4583\n",
      "\n",
      " Accuracy: 0.4583\n"
     ]
    }
   ],
   "source": [
    "print('\\n Accuracy: %.4f' % (model_1.evaluate(x_test_1, y_test_1_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_7.evaluate(x_test_7, y_test_7_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_15.evaluate(x_test_15, y_test_15_e)[1]))\n",
    "print('\\n Accuracy: %.4f' % (model_30.evaluate(x_test_30, y_test_30_e)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.05 / TensorFlow 2.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

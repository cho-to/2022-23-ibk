{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tcn in /home/work/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: tensorflow in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (0.16.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (1.21.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (22.12.6)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (14.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.29.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (63.2.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: finance-datareader in /home/work/.local/lib/python3.8/site-packages (0.9.50)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.2)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (2.27.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.5.0)\n",
      "Requirement already satisfied: requests-file in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.64.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from requests-file->finance-datareader) (1.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn\n",
    "!pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ffe65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-01-31 03:04:51.660783: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-31 03:04:51.808130: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-31 03:04:53.847082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-31 03:04:53.847199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-31 03:04:53.847207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452f7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "1996-12-11  705.989990  709.479980  704.429993  704.679993  704.679993   \n",
      "1996-12-12  705.109985  706.010010  688.739990  689.380005  689.380005   \n",
      "1996-12-13  690.440002  695.719971  677.640015  689.070007  689.070007   \n",
      "1996-12-16  686.969971  686.969971  667.710022  673.919983  673.919983   \n",
      "1996-12-17  675.349976  680.090027  660.390015  663.349976  663.349976   \n",
      "\n",
      "             Volume   Change1  Change7  Change15  Change30  \n",
      "Date                                                        \n",
      "1996-12-11  28000.0       NaN      NaN       NaN       NaN  \n",
      "1996-12-12  25900.0 -0.021712      NaN       NaN       NaN  \n",
      "1996-12-13  26500.0 -0.000450      NaN       NaN       NaN  \n",
      "1996-12-16  22800.0 -0.021986      NaN       NaN       NaN  \n",
      "1996-12-17  31600.0 -0.015684      NaN       NaN       NaN  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_train = fdr.DataReader('KS11', '1990-01-01','2017-12-31')\n",
    "kospi_train['Change1'] = kospi_train['Close']/kospi_train['Close'].shift(1) - 1\n",
    "kospi_train['Change7'] = kospi_train['Close']/kospi_train['Close'].shift(7) - 1\n",
    "kospi_train['Change15'] = kospi_train['Close']/kospi_train['Close'].shift(15) - 1\n",
    "kospi_train['Change30'] = kospi_train['Close']/kospi_train['Close'].shift(30) - 1\n",
    "print(kospi_train.head())\n",
    "print(kospi_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2415e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "1997-01-24  669.030029  679.559998  658.179993  679.559998  679.559998   \n",
      "1997-01-27  684.309998  685.460022  664.679993  664.700012  664.700012   \n",
      "1997-01-28  661.659973  677.630005  653.419983  662.849976  662.849976   \n",
      "1997-01-29  663.330017  672.900024  654.950012  663.559998  663.559998   \n",
      "1997-01-30  663.650024  679.039978  662.270020  676.520020  676.520020   \n",
      "\n",
      "             Volume   Change1   Change7  Change15  Change30  \n",
      "Date                                                         \n",
      "1997-01-24  35500.0  0.003915 -0.028867  0.039416 -0.013801  \n",
      "1997-01-27  28300.0 -0.021867 -0.066249  0.060347 -0.013681  \n",
      "1997-01-28  30400.0 -0.002783 -0.054665  0.084772 -0.000754  \n",
      "1997-01-29  30200.0  0.001071 -0.076413  0.067830  0.003281  \n",
      "1997-01-30  28800.0  0.019531 -0.020303  0.057277 -0.020913  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_train = kospi_train.dropna()\n",
    "print(kospi_train.head())\n",
    "print(kospi_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff64154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1997-01-24     679.559998\n",
      "1997-01-27     664.700012\n",
      "1997-01-28     662.849976\n",
      "1997-01-29     663.559998\n",
      "1997-01-30     676.520020\n",
      "                 ...     \n",
      "2017-12-21    2429.830078\n",
      "2017-12-22    2440.540039\n",
      "2017-12-26    2427.340088\n",
      "2017-12-27    2436.669922\n",
      "2017-12-28    2467.489990\n",
      "Name: Close, Length: 4668, dtype: float64 Date\n",
      "1997-01-24    0.003915\n",
      "1997-01-27   -0.021867\n",
      "1997-01-28   -0.002783\n",
      "1997-01-29    0.001071\n",
      "1997-01-30    0.019531\n",
      "                ...   \n",
      "2017-12-21   -0.019649\n",
      "2017-12-22    0.004408\n",
      "2017-12-26   -0.005409\n",
      "2017-12-27    0.003844\n",
      "2017-12-28    0.012648\n",
      "Name: Change1, Length: 4668, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kospi_train_close = kospi_train['Close']\n",
    "kospi_train_c1 = kospi_train['Change1']\n",
    "kospi_train_c7 = kospi_train['Change7']\n",
    "kospi_train_c15 = kospi_train['Change15']\n",
    "kospi_train_c30 = kospi_train['Change30']\n",
    "print(kospi_train_close, kospi_train_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c18820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2018-01-02  2474.860107  2481.020020  2465.939941  2479.649902  2479.649902   \n",
      "2018-01-03  2484.629883  2493.399902  2481.909912  2486.350098  2486.350098   \n",
      "2018-01-04  2502.500000  2502.500000  2466.449951  2466.459961  2466.459961   \n",
      "2018-01-05  2476.850098  2497.520020  2475.510010  2497.520020  2497.520020   \n",
      "2018-01-08  2510.699951  2515.370117  2494.179932  2513.280029  2513.280029   \n",
      "\n",
      "            Volume   Change1  Change7  Change15  Change30  \n",
      "Date                                                       \n",
      "2018-01-02  262200       NaN      NaN       NaN       NaN  \n",
      "2018-01-03  331100  0.002702      NaN       NaN       NaN  \n",
      "2018-01-04  333800 -0.008000      NaN       NaN       NaN  \n",
      "2018-01-05  308800  0.012593      NaN       NaN       NaN  \n",
      "2018-01-08  311400  0.006310      NaN       NaN       NaN  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_test = fdr.DataReader('KS11', '2018-01-01')\n",
    "kospi_test['Change1'] = kospi_test['Close']/kospi_test['Close'].shift(1) - 1\n",
    "kospi_test['Change7'] = kospi_test['Close']/kospi_test['Close'].shift(7) - 1\n",
    "kospi_test['Change15'] = kospi_test['Close']/kospi_test['Close'].shift(15) - 1\n",
    "kospi_test['Change30'] = kospi_test['Close']/kospi_test['Close'].shift(30) - 1\n",
    "print(kospi_test.head())\n",
    "print(kospi_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c764202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2018-02-13  2402.889893  2421.800049  2388.540039  2395.189941  2395.189941   \n",
      "2018-02-14  2412.469971  2426.629883  2408.020020  2421.830078  2421.830078   \n",
      "2018-02-19  2452.520020  2455.120117  2428.149902  2442.820068  2442.820068   \n",
      "2018-02-20  2433.350098  2438.479980  2411.229980  2415.120117  2415.120117   \n",
      "2018-02-21  2417.729980  2432.449951  2404.020020  2429.649902  2429.649902   \n",
      "\n",
      "            Volume   Change1   Change7  Change15  Change30  \n",
      "Date                                                        \n",
      "2018-02-13  423400  0.004113 -0.051556 -0.055748 -0.034061  \n",
      "2018-02-14  305700  0.011122 -0.028061 -0.045772 -0.025950  \n",
      "2018-02-19  322100  0.008667 -0.004276 -0.046604 -0.009585  \n",
      "2018-02-20  421500 -0.011339  0.007744 -0.062002 -0.032993  \n",
      "2018-02-21  432300  0.006016  0.009150 -0.064868 -0.033275  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1',\n",
      "       'Change7', 'Change15', 'Change30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kospi_test = kospi_test.dropna()\n",
    "print(kospi_test.head())\n",
    "print(kospi_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48c0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2018-02-13    2395.189941\n",
      "2018-02-14    2421.830078\n",
      "2018-02-19    2442.820068\n",
      "2018-02-20    2415.120117\n",
      "2018-02-21    2429.649902\n",
      "                 ...     \n",
      "2023-01-25    2428.570068\n",
      "2023-01-26    2468.649902\n",
      "2023-01-27    2484.020020\n",
      "2023-01-30    2450.469971\n",
      "2023-01-31    2441.469971\n",
      "Name: Close, Length: 1220, dtype: float64 Date\n",
      "2018-02-13    0.004113\n",
      "2018-02-14    0.011122\n",
      "2018-02-19    0.008667\n",
      "2018-02-20   -0.011339\n",
      "2018-02-21    0.006016\n",
      "                ...   \n",
      "2023-01-25    0.013907\n",
      "2023-01-26    0.016503\n",
      "2023-01-27    0.006226\n",
      "2023-01-30   -0.013506\n",
      "2023-01-31   -0.003673\n",
      "Name: Change1, Length: 1220, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kospi_test_close = kospi_test['Close']\n",
    "kospi_test_c1 = kospi_test['Change1']\n",
    "kospi_test_c7 = kospi_test['Change7']\n",
    "kospi_test_c15 = kospi_test['Change15']\n",
    "kospi_test_c30 = kospi_test['Change30']\n",
    "print(kospi_test_close, kospi_test_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8396c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41125768  1.11223484  0.86669953 ...  0.6226123  -1.35063521\n",
      " -0.36727649]\n"
     ]
    }
   ],
   "source": [
    "kospi_train_close = kospi_train_close.values\n",
    "kospi_train_c1 = 100 * kospi_train_c1.values\n",
    "kospi_train_c7 = 100 * kospi_train_c7.values\n",
    "kospi_train_c15 = 100 * kospi_train_c15.values\n",
    "kospi_train_c30 = 100 * kospi_train_c30.values\n",
    "\n",
    "kospi_test_close = kospi_test_close.values\n",
    "kospi_test_c1 = 100 * kospi_test_c1.values\n",
    "kospi_test_c7 = 100 * kospi_test_c7.values\n",
    "kospi_test_c15 = 100 * kospi_test_c15.values\n",
    "kospi_test_c30 = 100 * kospi_test_c30.values\n",
    "print(kospi_test_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1334a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_window = 60\n",
    "x_train_1, y_train_1 = [], []\n",
    "x_train_7, y_train_7 = [], []\n",
    "x_train_15, y_train_15 = [], []\n",
    "x_train_30, y_train_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad8662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_train_close)-1):\n",
    "    x_train_1.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_1.append(kospi_train_c1[i])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train_close)-6):\n",
    "    x_train_7.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_7.append(kospi_train_c7[i+6])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train_close)-14):\n",
    "    x_train_15.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_15.append(kospi_train_c15[i+14])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_train_close)-29):\n",
    "    x_train_30.append(kospi_train_close[i - lookback_window:i])\n",
    "    y_train_30.append(kospi_train_c30[i+29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02aedcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_train_1)):\n",
    "    if y_train_1[index]>= -0.1 and y_train_1[index] < 0.1:\n",
    "        y_train_1[index] = 'neutral'\n",
    "    elif y_train_1[index] >= 0.1:\n",
    "        y_train_1[index] = 'increase'\n",
    "    else:\n",
    "        y_train_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_train_7)):\n",
    "    if y_train_7[index]>= -0.1 and y_train_7[index] < 0.1:\n",
    "        y_train_7[index] = 'neutral'\n",
    "    elif y_train_7[index] >= 0.1:\n",
    "        y_train_7[index] = 'increase'\n",
    "    else:\n",
    "        y_train_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_15)):\n",
    "    if y_train_15[index]>= -0.1 and y_train_15[index] < 0.1:\n",
    "        y_train_15[index] = 'neutral'\n",
    "    elif y_train_15[index] >= 0.1:\n",
    "        y_train_15[index] = 'increase'\n",
    "    else:\n",
    "        y_train_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_train_30)):\n",
    "    if y_train_30[index]>= -0.1 and y_train_30[index] < 0.1:\n",
    "        y_train_30[index] = 'neutral'\n",
    "    elif y_train_30[index] >= 0.1:\n",
    "        y_train_30[index] = 'increase'\n",
    "    else:\n",
    "        y_train_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ef8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4607, 60, 1) (4602, 60, 1) (4594, 60, 1) (4579, 60, 1)\n",
      "(4607,) (4602,) (4594,) (4579,)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(x_train_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "x_train_1 = x_train_1.reshape((4607, -1, 1))\n",
    "#y_train_1 = y_train_1.reshape((-1, 1))\n",
    "\n",
    "x_train_7 = np.array(x_train_7)\n",
    "y_train_7 = np.array(y_train_7)\n",
    "x_train_7 = x_train_7.reshape((4602, -1, 1))\n",
    "#y_train_7 = y_train_7.reshape((-1, 1))\n",
    "\n",
    "x_train_15 = np.array(x_train_15)\n",
    "y_train_15 = np.array(y_train_15)\n",
    "x_train_15 = x_train_15.reshape((4594, -1, 1))\n",
    "#y_train_15 = y_train_15.reshape((-1, 1))\n",
    "\n",
    "x_train_30 = np.array(x_train_30)\n",
    "y_train_30 = np.array(y_train_30)\n",
    "x_train_30 = x_train_30.reshape((4579, -1, 1))\n",
    "#y_train_30 = y_train_30.reshape((-1, 1))\n",
    "\n",
    "print(x_train_1.shape, x_train_7.shape, x_train_15.shape, x_train_30.shape)\n",
    "print(y_train_1.shape, y_train_7.shape, y_train_15.shape, y_train_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "612667a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1, y_test_1 = [], []\n",
    "x_test_7, y_test_7 = [], []\n",
    "x_test_15, y_test_15 = [], []\n",
    "x_test_30, y_test_30 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77c5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(kospi_test_close)-1):\n",
    "    x_test_1.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_1.append(kospi_test_c1[i])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test_close)-6):\n",
    "    x_test_7.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_7.append(kospi_test_c7[i+6])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test_close)-14):\n",
    "    x_test_15.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_15.append(kospi_test_c15[i+14])\n",
    "\n",
    "for i in range(lookback_window, len(kospi_test_close)-29):\n",
    "    x_test_30.append(kospi_test_close[i - lookback_window:i])\n",
    "    y_test_30.append(kospi_test_c30[i+29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb64b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(y_test_1)):\n",
    "    if y_test_1[index]>= -0.1 and y_test_1[index] < 0.1:\n",
    "        y_test_1[index] = 'neutral'\n",
    "    elif y_test_1[index] >= 0.1:\n",
    "        y_test_1[index] = 'increase'\n",
    "    else:\n",
    "        y_test_1[index] = 'decrease'\n",
    "        \n",
    "for index in range(len(y_test_7)):\n",
    "    if y_test_7[index]>= -0.1 and y_test_7[index] < 0.1:\n",
    "        y_test_7[index] = 'neutral'\n",
    "    elif y_test_7[index] >= 0.1:\n",
    "        y_test_7[index] = 'increase'\n",
    "    else:\n",
    "        y_test_7[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_15)):\n",
    "    if y_test_15[index]>= -0.1 and y_test_15[index] < 0.1:\n",
    "        y_test_15[index] = 'neutral'\n",
    "    elif y_test_15[index] >= 0.1:\n",
    "        y_test_15[index] = 'increase'\n",
    "    else:\n",
    "        y_test_15[index] = 'decrease'\n",
    "\n",
    "for index in range(len(y_test_30)):\n",
    "    if y_test_30[index]>= -0.1 and y_test_30[index] < 0.1:\n",
    "        y_test_30[index] = 'neutral'\n",
    "    elif y_test_30[index] >= 0.1:\n",
    "        y_test_30[index] = 'increase'\n",
    "    else:\n",
    "        y_test_30[index] = 'decrease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d9be8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = np.array(x_test_1)\n",
    "y_test_1 = np.array(y_test_1)\n",
    "x_test_1 = x_test_1.reshape((1159, -1, 1))\n",
    "#y_test_1 = y_test_1.reshape((-1, 1))\n",
    "\n",
    "x_test_7 = np.array(x_test_7)\n",
    "y_test_7 = np.array(y_test_7)\n",
    "x_test_7 = x_test_7.reshape((1154, -1, 1))\n",
    "#y_test_7 = y_test_7.reshape((-1, 1))\n",
    "\n",
    "x_test_15 = np.array(x_test_15)\n",
    "y_test_15 = np.array(y_test_15)\n",
    "x_test_15 = x_test_15.reshape((1146, -1, 1))\n",
    "#y_test_15 = y_test_15.reshape((-1, 1))\n",
    "\n",
    "x_test_30 = np.array(x_test_30)\n",
    "y_test_30 = np.array(y_test_30)\n",
    "x_test_30 = x_test_30.reshape((1131, -1, 1))\n",
    "#y_test_30 = y_test_30.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c3afe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 60, 1) (1154, 60, 1) (1146, 60, 1) (1131, 60, 1)\n",
      "(1159,) (1154,) (1146,) (1131,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_1.shape, x_test_7.shape, x_test_15.shape, x_test_30.shape)\n",
    "print(y_test_1.shape, y_test_7.shape, y_test_15.shape, y_test_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd5460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_1)\n",
    "\n",
    "y_train_1_e = to_categorical(encoder.transform(y_train_1))\n",
    "y_train_7_e = to_categorical(encoder.transform(y_train_7))\n",
    "y_train_15_e = to_categorical(encoder.transform(y_train_15))\n",
    "y_train_30_e = to_categorical(encoder.transform(y_train_30))\n",
    "\n",
    "y_test_1_e = to_categorical(encoder.transform(y_test_1))\n",
    "y_test_7_e = to_categorical(encoder.transform(y_test_7))\n",
    "y_test_15_e = to_categorical(encoder.transform(y_test_15))\n",
    "y_test_30_e = to_categorical(encoder.transform(y_test_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8cb8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 03:05:51.938272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-01-31 03:05:51.938309: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-31 03:05:51.938331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2023-01-31 03:05:51.938667: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 64)                91136     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_1 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_2 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_3 (TCN)                 (None, 64)                91136     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,331\n",
      "Trainable params: 91,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_7 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_7.summary()\n",
    "model_7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_15 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_15.summary()\n",
    "model_15.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "####\n",
    "model_30 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 1),\n",
    "        kernel_size=2,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False\n",
    "        ),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_30.summary()\n",
    "model_30.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac14f04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model_1...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 6s 27ms/step - loss: 1269.7397 - accuracy: 0.4139\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 408.3159 - accuracy: 0.4159\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 295.8859 - accuracy: 0.4265\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 221.8284 - accuracy: 0.4170\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 126.8653 - accuracy: 0.4089\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 138.0829 - accuracy: 0.4142\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 171.4542 - accuracy: 0.4098\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 95.8597 - accuracy: 0.4163\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 103.5776 - accuracy: 0.4233\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 91.7844 - accuracy: 0.4137\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 93.7143 - accuracy: 0.4070\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 115.1749 - accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 65.8513 - accuracy: 0.4204\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 61.2221 - accuracy: 0.4042\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 77.5795 - accuracy: 0.4189\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 83.3710 - accuracy: 0.4146\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 67.1566 - accuracy: 0.4176\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 65.8492 - accuracy: 0.4074\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 71.2400 - accuracy: 0.4165\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 59.8936 - accuracy: 0.4066\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 60.8173 - accuracy: 0.4168\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 44.9899 - accuracy: 0.4174\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 57.4781 - accuracy: 0.4259\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 59.5362 - accuracy: 0.4204\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 61.4046 - accuracy: 0.4170\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 49.5562 - accuracy: 0.4241\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.1843 - accuracy: 0.4144\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 34.7789 - accuracy: 0.4402\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 30.3475 - accuracy: 0.4161\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 57.5013 - accuracy: 0.4270\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 39.1225 - accuracy: 0.4213\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.7395 - accuracy: 0.4191\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.3987 - accuracy: 0.4181\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 38.1151 - accuracy: 0.4220\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 36.9734 - accuracy: 0.4107\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 42.2071 - accuracy: 0.4172\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 38.9227 - accuracy: 0.3979\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 28.3105 - accuracy: 0.4248\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 37.6902 - accuracy: 0.4113\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 35.4817 - accuracy: 0.4220\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.5502 - accuracy: 0.4263\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 31.1111 - accuracy: 0.4246\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 29.2229 - accuracy: 0.4165\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 81.8878 - accuracy: 0.4122\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.1270 - accuracy: 0.4168\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 26.9300 - accuracy: 0.4094\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 31.8695 - accuracy: 0.4146\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.3607 - accuracy: 0.4144\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.8977 - accuracy: 0.4309\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.8012 - accuracy: 0.4267\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 28.3865 - accuracy: 0.4235\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 22.7387 - accuracy: 0.4296\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.4840 - accuracy: 0.4263\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.4078 - accuracy: 0.4217\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.2124 - accuracy: 0.4181\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.5651 - accuracy: 0.4157\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.2091 - accuracy: 0.4202\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.6180 - accuracy: 0.4137\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 26.0181 - accuracy: 0.4174\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 4s 25ms/step - loss: 17.3150 - accuracy: 0.4187\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.6572 - accuracy: 0.4150\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.9953 - accuracy: 0.4228\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.3101 - accuracy: 0.4209\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 27.2359 - accuracy: 0.4170\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.4781 - accuracy: 0.4241\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.8862 - accuracy: 0.4217\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.4977 - accuracy: 0.4248\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.9880 - accuracy: 0.4063\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.0280 - accuracy: 0.4172\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.4717 - accuracy: 0.4246\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.2442 - accuracy: 0.4248\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 19.7414 - accuracy: 0.4113\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.0318 - accuracy: 0.4352\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.5064 - accuracy: 0.4085\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.3670 - accuracy: 0.4194\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.4854 - accuracy: 0.4244\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.2442 - accuracy: 0.4246\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.4162 - accuracy: 0.4263\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.7658 - accuracy: 0.4063\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 19.2191 - accuracy: 0.4102\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.9741 - accuracy: 0.4215\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.5623 - accuracy: 0.4235\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.6367 - accuracy: 0.4244\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.0009 - accuracy: 0.4150\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.0895 - accuracy: 0.4278\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.9248 - accuracy: 0.4172\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.7164 - accuracy: 0.4191\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.5056 - accuracy: 0.4198\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 11.0877 - accuracy: 0.4215\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.9180 - accuracy: 0.4363\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.1179 - accuracy: 0.4137\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.1997 - accuracy: 0.4013\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.3588 - accuracy: 0.4220\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.1167 - accuracy: 0.4346\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.8033 - accuracy: 0.4181\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.9516 - accuracy: 0.4057\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 12.0105 - accuracy: 0.4328\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 9.8617 - accuracy: 0.4150\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.8991 - accuracy: 0.4235\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.8282 - accuracy: 0.4300\n",
      "37/37 [==============================] - 1s 9ms/step\n",
      "Train model_7...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 6s 26ms/step - loss: 1223.8569 - accuracy: 0.4859\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 332.2178 - accuracy: 0.4746\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 254.2603 - accuracy: 0.4778\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 197.3152 - accuracy: 0.4904\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 133.2189 - accuracy: 0.4807\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 114.6642 - accuracy: 0.4896\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 100.9386 - accuracy: 0.4859\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 105.4801 - accuracy: 0.4796\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 124.6877 - accuracy: 0.4839\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 62.0857 - accuracy: 0.4902\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 59.3004 - accuracy: 0.4809\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 55.3089 - accuracy: 0.4844\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 60.1221 - accuracy: 0.4783\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 61.4974 - accuracy: 0.4852\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 34.4764 - accuracy: 0.4824\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 57.2476 - accuracy: 0.4880\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 54.1924 - accuracy: 0.4852\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.8448 - accuracy: 0.4837\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 39.5936 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 82.4125 - accuracy: 0.4744\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 48.2113 - accuracy: 0.4791\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 32.0229 - accuracy: 0.4724\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 27.7086 - accuracy: 0.4846\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 30.5905 - accuracy: 0.4765\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 23.5032 - accuracy: 0.4950\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 44.6372 - accuracy: 0.4922\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 28.2838 - accuracy: 0.4802\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 34.0079 - accuracy: 0.4928\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 30.7222 - accuracy: 0.4883\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.1556 - accuracy: 0.4802\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.7182 - accuracy: 0.4726\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 18.3859 - accuracy: 0.4824\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.0719 - accuracy: 0.4930\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 35.0256 - accuracy: 0.4748\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.3336 - accuracy: 0.4663\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.6492 - accuracy: 0.4954\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.6761 - accuracy: 0.4930\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 24.9516 - accuracy: 0.4804\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.9351 - accuracy: 0.4913\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 26.6635 - accuracy: 0.4837\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 22.2599 - accuracy: 0.4791\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.9276 - accuracy: 0.4839\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.8299 - accuracy: 0.4837\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.6535 - accuracy: 0.4896\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 21.8201 - accuracy: 0.4726\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.0354 - accuracy: 0.4822\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.6446 - accuracy: 0.4746\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.8318 - accuracy: 0.4746\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.2428 - accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.9250 - accuracy: 0.4876\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.6373 - accuracy: 0.4844\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.1946 - accuracy: 0.4939\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.3964 - accuracy: 0.4944\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.0037 - accuracy: 0.4867\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.4042 - accuracy: 0.4737\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.7191 - accuracy: 0.4750\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 26ms/step - loss: 14.3342 - accuracy: 0.4800\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.8483 - accuracy: 0.4848\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.8935 - accuracy: 0.4804\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.0374 - accuracy: 0.4691\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.6686 - accuracy: 0.4804\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.5565 - accuracy: 0.4668\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.5763 - accuracy: 0.4828\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.8046 - accuracy: 0.4883\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.8527 - accuracy: 0.4735\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.2312 - accuracy: 0.4898\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9338 - accuracy: 0.4800\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.3479 - accuracy: 0.4889\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.9464 - accuracy: 0.4857\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 10.9435 - accuracy: 0.4789\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 12.1137 - accuracy: 0.4859\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.4706 - accuracy: 0.4783\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.8856 - accuracy: 0.5043\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.1971 - accuracy: 0.4750\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.7111 - accuracy: 0.4900\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.0551 - accuracy: 0.4694\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.1225 - accuracy: 0.4828\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.9721 - accuracy: 0.4857\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.9547 - accuracy: 0.4802\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.7160 - accuracy: 0.4809\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.9674 - accuracy: 0.4820\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.8224 - accuracy: 0.4770\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.2253 - accuracy: 0.4761\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.8616 - accuracy: 0.4933\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.5354 - accuracy: 0.4889\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9890 - accuracy: 0.4798\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.4046 - accuracy: 0.4887\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.1999 - accuracy: 0.4783\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.7128 - accuracy: 0.4813\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 9.5694 - accuracy: 0.4898\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.0431 - accuracy: 0.4891\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.5297 - accuracy: 0.4757\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 12.2523 - accuracy: 0.4867\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.7523 - accuracy: 0.4741\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 8.8672 - accuracy: 0.4833\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.1510 - accuracy: 0.4900\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.1834 - accuracy: 0.4835\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.9797 - accuracy: 0.4898\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 7.4559 - accuracy: 0.4839\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.8316 - accuracy: 0.4652\n",
      "37/37 [==============================] - 1s 8ms/step\n",
      "Train model_15...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 6s 26ms/step - loss: 1017.6662 - accuracy: 0.4893\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 386.6330 - accuracy: 0.5057\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 173.7243 - accuracy: 0.4898\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 138.8188 - accuracy: 0.4902\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 112.9735 - accuracy: 0.5104\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 94.7464 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 95.0849 - accuracy: 0.5028\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 85.3704 - accuracy: 0.4972\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 86.7300 - accuracy: 0.4963\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 98.3747 - accuracy: 0.4956\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 94.2976 - accuracy: 0.5013\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 55.8824 - accuracy: 0.4850\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 57.3307 - accuracy: 0.5122\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 45.8831 - accuracy: 0.5041\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 45.5627 - accuracy: 0.4965\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 58.2618 - accuracy: 0.4889\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 44.3020 - accuracy: 0.4898\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 39.9619 - accuracy: 0.5109\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 27.9440 - accuracy: 0.5081\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 40.9247 - accuracy: 0.4946\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 34.2600 - accuracy: 0.4980\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.6186 - accuracy: 0.5028\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 35.7156 - accuracy: 0.4928\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 34.8259 - accuracy: 0.4933\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 45.1157 - accuracy: 0.4928\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 37.2833 - accuracy: 0.5039\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 49.8786 - accuracy: 0.5041\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 28.5152 - accuracy: 0.5020\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 21.3389 - accuracy: 0.4980\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.6304 - accuracy: 0.4891\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 28.7272 - accuracy: 0.4882\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 32.0945 - accuracy: 0.4970\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 28.3804 - accuracy: 0.5083\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 35.4631 - accuracy: 0.4939\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 33.3510 - accuracy: 0.4913\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 27.3261 - accuracy: 0.4880\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 25.5539 - accuracy: 0.4978\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.8971 - accuracy: 0.4896\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 30.3848 - accuracy: 0.4946\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 25.6143 - accuracy: 0.4800\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.3039 - accuracy: 0.4832\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 29.7053 - accuracy: 0.4985\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 20.1278 - accuracy: 0.4839\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.5908 - accuracy: 0.4989\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.5628 - accuracy: 0.4913\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 37.2895 - accuracy: 0.4856\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 48.2378 - accuracy: 0.5054\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 41.5764 - accuracy: 0.4893\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 23.5676 - accuracy: 0.4885\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 22.7638 - accuracy: 0.4937\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 36.7862 - accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 20.2385 - accuracy: 0.5104\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.0682 - accuracy: 0.4950\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.9057 - accuracy: 0.5041\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 16.6985 - accuracy: 0.5048\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 16.5604 - accuracy: 0.4909\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.6667 - accuracy: 0.5059\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 24.9091 - accuracy: 0.4900\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 20.3636 - accuracy: 0.4893\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.7601 - accuracy: 0.4983\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.7962 - accuracy: 0.4980\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 22.6572 - accuracy: 0.5007\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.7315 - accuracy: 0.5052\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 33.2083 - accuracy: 0.4991\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 31.4124 - accuracy: 0.4915\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.6021 - accuracy: 0.4956\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 4s 27ms/step - loss: 18.6555 - accuracy: 0.4996\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.4470 - accuracy: 0.5081\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 18.2567 - accuracy: 0.5002\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 13.2306 - accuracy: 0.5035\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 10.9137 - accuracy: 0.4848\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.9087 - accuracy: 0.5002\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 14.9397 - accuracy: 0.5041\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.5690 - accuracy: 0.5128\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 17.3492 - accuracy: 0.4963\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.0712 - accuracy: 0.4967\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 15.3022 - accuracy: 0.4837\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 12.9349 - accuracy: 0.5024\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.2261 - accuracy: 0.5139\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 4s 26ms/step - loss: 11.8138 - accuracy: 0.4985\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 16.2539 - accuracy: 0.4993\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.8507 - accuracy: 0.5094\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.1695 - accuracy: 0.5050\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.3960 - accuracy: 0.4976\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.3560 - accuracy: 0.5085\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.7542 - accuracy: 0.4928\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.8483 - accuracy: 0.4983\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.3985 - accuracy: 0.5057\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.9910 - accuracy: 0.4963\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.5748 - accuracy: 0.4985\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.2804 - accuracy: 0.4967\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.7009 - accuracy: 0.5078\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.0720 - accuracy: 0.5017\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.0177 - accuracy: 0.4926\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.8803 - accuracy: 0.4876\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.3549 - accuracy: 0.4993\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.5010 - accuracy: 0.4987\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.7255 - accuracy: 0.5020\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.4363 - accuracy: 0.4974\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.2605 - accuracy: 0.5078\n",
      "36/36 [==============================] - 1s 19ms/step\n",
      "Train model_30...\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 4s 17ms/step - loss: 1166.9102 - accuracy: 0.5086\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 272.4789 - accuracy: 0.5165\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 154.0094 - accuracy: 0.5014\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 200.8838 - accuracy: 0.4979\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 125.6638 - accuracy: 0.5161\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 88.7618 - accuracy: 0.5069\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 94.3117 - accuracy: 0.5027\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 85.3566 - accuracy: 0.5091\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 75.0105 - accuracy: 0.4986\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 71.3460 - accuracy: 0.4999\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 86.6586 - accuracy: 0.5099\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 49.1595 - accuracy: 0.5040\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 16ms/step - loss: 41.1174 - accuracy: 0.5012\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 46.8597 - accuracy: 0.5088\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 58.7942 - accuracy: 0.5003\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 41.2540 - accuracy: 0.5054\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 37.8624 - accuracy: 0.5165\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 58.0896 - accuracy: 0.5047\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 48.2518 - accuracy: 0.5119\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 52.0990 - accuracy: 0.5143\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 45.4627 - accuracy: 0.5056\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 55.4244 - accuracy: 0.5001\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.8475 - accuracy: 0.5119\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 40.3172 - accuracy: 0.5008\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.7949 - accuracy: 0.5071\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 35.9482 - accuracy: 0.5095\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 31.2466 - accuracy: 0.5219\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 35.7669 - accuracy: 0.5204\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 40.1295 - accuracy: 0.4964\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 34.1998 - accuracy: 0.5182\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 29.6849 - accuracy: 0.5086\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 25.3896 - accuracy: 0.5204\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 31.0221 - accuracy: 0.5054\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 23.7024 - accuracy: 0.5270\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 29.5574 - accuracy: 0.5165\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 37.2404 - accuracy: 0.5110\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 22.7419 - accuracy: 0.5163\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 26.1617 - accuracy: 0.4927\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.6007 - accuracy: 0.5136\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 27.4330 - accuracy: 0.5067\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 28.2685 - accuracy: 0.5034\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.6159 - accuracy: 0.5134\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.2693 - accuracy: 0.5069\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 29.4734 - accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 20.5144 - accuracy: 0.5102\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.3448 - accuracy: 0.5110\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.3639 - accuracy: 0.5021\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.9278 - accuracy: 0.5099\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.1459 - accuracy: 0.5104\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.2741 - accuracy: 0.5171\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.1663 - accuracy: 0.5200\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 23.0254 - accuracy: 0.4955\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 21.9294 - accuracy: 0.5047\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.4104 - accuracy: 0.5078\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.1433 - accuracy: 0.5171\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.4167 - accuracy: 0.5209\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.0013 - accuracy: 0.5121\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.0852 - accuracy: 0.5064\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 23.0722 - accuracy: 0.5069\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.7731 - accuracy: 0.5110\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.2907 - accuracy: 0.5187\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.7993 - accuracy: 0.5043\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.0896 - accuracy: 0.5034\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.2095 - accuracy: 0.5274\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.8255 - accuracy: 0.5119\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.7840 - accuracy: 0.5084\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 18.5750 - accuracy: 0.5047\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.0423 - accuracy: 0.5049\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 19.2897 - accuracy: 0.5088\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.5746 - accuracy: 0.5246\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.7933 - accuracy: 0.5084\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.4947 - accuracy: 0.5134\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.3910 - accuracy: 0.4984\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.1844 - accuracy: 0.5102\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 17ms/step - loss: 14.2947 - accuracy: 0.5095\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.0692 - accuracy: 0.5178\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.6529 - accuracy: 0.5134\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.7677 - accuracy: 0.5019\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 11.4350 - accuracy: 0.5102\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.9401 - accuracy: 0.5067\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 10.0473 - accuracy: 0.5032\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.5080 - accuracy: 0.5106\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.3578 - accuracy: 0.5045\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 9.7813 - accuracy: 0.5213\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.4061 - accuracy: 0.5108\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.9963 - accuracy: 0.5167\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.2117 - accuracy: 0.5005\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.3064 - accuracy: 0.4962\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 15.1506 - accuracy: 0.4927\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.2691 - accuracy: 0.5075\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.4789 - accuracy: 0.5158\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.8513 - accuracy: 0.5016\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 8.1199 - accuracy: 0.5056\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.8173 - accuracy: 0.5128\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 13.2260 - accuracy: 0.4859\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 14.7730 - accuracy: 0.5051\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 16.0327 - accuracy: 0.5012\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 17.1403 - accuracy: 0.4929\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 11.9702 - accuracy: 0.5161\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 12.2934 - accuracy: 0.5167\n",
      "36/36 [==============================] - 1s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Train model_1...')\n",
    "model_1.fit(x_train_1, y_train_1_e, epochs=100, verbose=1)\n",
    "p_test_1 = model_1.predict(x_test_1)\n",
    "\n",
    "print('Train model_7...')\n",
    "model_7.fit(x_train_7, y_train_7_e, epochs=100, verbose=1)\n",
    "p_test_7 = model_7.predict(x_test_7)\n",
    "\n",
    "print('Train model_15...')\n",
    "model_15.fit(x_train_15, y_train_15_e, epochs=100, verbose=1)\n",
    "p_test_15 = model_15.predict(x_test_15)\n",
    "\n",
    "print('Train model_30...')\n",
    "model_30.fit(x_train_30, y_train_30_e, epochs=100, verbose=1)\n",
    "p_test_30 = model_30.predict(x_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11fc61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('/home/work/nlp/TCN_models/classification_model/v6/kospi_1day_classification_v6.h5')\n",
    "model_7.save('/home/work/nlp/TCN_models/classification_model/v6/kospi_7days_classification_v6.h5')\n",
    "model_15.save('/home/work/nlp/TCN_models/classification_model/v6/kospi_15days_classification_v6.h5')\n",
    "model_30.save('/home/work/nlp/TCN_models/classification_model/v6/kospi_30days_classification_v6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0178c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 23ms/step - loss: 50.7914 - accuracy: 0.1001\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 18.6252 - accuracy: 0.4636\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 28.5765 - accuracy: 0.4878\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 34.5452 - accuracy: 0.4872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4871794879436493"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(x_test_1, y_test_1_e)[1]\n",
    "model_7.evaluate(x_test_7, y_test_7_e)[1]\n",
    "model_15.evaluate(x_test_15, y_test_15_e)[1]\n",
    "model_30.evaluate(x_test_30, y_test_30_e)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.13 (NGC 22.05/Python 3.8 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

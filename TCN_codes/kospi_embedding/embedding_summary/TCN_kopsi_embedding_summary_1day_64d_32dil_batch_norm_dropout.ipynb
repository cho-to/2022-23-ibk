{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tcn in /home/work/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (1.21.1)\n",
      "Requirement already satisfied: tensorflow-addons in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (0.19.0)\n",
      "Requirement already satisfied: tensorflow in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (63.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (22.12.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.29.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (4.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (3.19.6)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: finance-datareader in /home/work/.local/lib/python3.8/site-packages (0.9.50)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.2)\n",
      "Requirement already satisfied: requests-file in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.64.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from requests-file->finance-datareader) (1.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn\n",
    "!pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ffe65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-02-08 08:38:56.415504: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 08:38:56.712376: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-08 08:39:01.022907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-02-08 08:39:01.023196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-02-08 08:39:01.023222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452f7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2006-01-03  1393.140015  1394.920044  1376.170044  1394.869995  1394.869995   \n",
      "2006-01-04  1408.189941  1412.150024  1400.079956  1402.109985  1402.109985   \n",
      "2006-01-05  1405.310059  1405.310059  1378.959961  1395.510010  1395.510010   \n",
      "2006-01-06  1399.229980  1412.790039  1395.260010  1412.780029  1412.780029   \n",
      "2006-01-09  1421.900024  1421.900024  1405.050049  1408.329956  1408.329956   \n",
      "\n",
      "              Volume   Change1  \n",
      "Date                            \n",
      "2006-01-03  541300.0  0.004031  \n",
      "2006-01-04  528000.0  0.005190  \n",
      "2006-01-05  538100.0 -0.004707  \n",
      "2006-01-06  587900.0  0.012375  \n",
      "2006-01-09  531500.0 -0.003150  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1'], dtype='object')\n",
      "(3442, 7)\n"
     ]
    }
   ],
   "source": [
    "kospi_train = fdr.DataReader('KS11', '2006-01-01','2019-12-31')\n",
    "kospi_train['Change1'] = kospi_train['Close']/kospi_train['Close'].shift(1) - 1\n",
    "\n",
    "kospi_train = kospi_train.dropna()\n",
    "print(kospi_train.head())\n",
    "print(kospi_train.columns)\n",
    "print(kospi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c875dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2020-01-03  2192.580078  2203.379883  2165.389893  2176.459961  2176.459961   \n",
      "2020-01-06  2154.969971  2164.419922  2149.949951  2155.070068  2155.070068   \n",
      "2020-01-07  2166.600098  2181.620117  2164.270020  2175.540039  2175.540039   \n",
      "2020-01-08  2156.270020  2162.320068  2137.719971  2151.310059  2151.310059   \n",
      "2020-01-09  2182.199951  2186.449951  2172.159912  2186.449951  2186.449951   \n",
      "\n",
      "            Volume   Change1  \n",
      "Date                          \n",
      "2020-01-03  631600  0.000593  \n",
      "2020-01-06  592700 -0.009828  \n",
      "2020-01-07  568200  0.009499  \n",
      "2020-01-08  913800 -0.011137  \n",
      "2020-01-09  592600  0.016334  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1'], dtype='object')\n",
      "(696, 7)\n"
     ]
    }
   ],
   "source": [
    "kospi_test = fdr.DataReader('KS11', '2020-01-01','2022-10-31')\n",
    "kospi_test['Change1'] = kospi_test['Close']/kospi_test['Close'].shift(1) - 1\n",
    "\n",
    "kospi_test = kospi_test.dropna()\n",
    "print(kospi_test.head())\n",
    "print(kospi_test.columns)\n",
    "print(kospi_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44840c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2006-01-03', '2006-01-04', '2006-01-05', '2006-01-06', '2006-01-09',\n",
      "       '2006-01-10', '2006-01-11', '2006-01-12', '2006-01-13', '2006-01-16',\n",
      "       ...\n",
      "       '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
      "       '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27', '2019-12-30'],\n",
      "      dtype='object', name='Date', length=3442)\n",
      "Index(['2020-01-03', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09',\n",
      "       '2020-01-10', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16',\n",
      "       ...\n",
      "       '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21', '2022-10-24',\n",
      "       '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', '2022-10-31'],\n",
      "      dtype='object', name='Date', length=696)\n"
     ]
    }
   ],
   "source": [
    "kospi_train.index = kospi_train.index.strftime('%Y-%m-%d')\n",
    "print(kospi_train.index)\n",
    "\n",
    "kospi_test.index = kospi_test.index.strftime('%Y-%m-%d')\n",
    "print(kospi_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4237d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "embedding = open('/home/work/nlp/embedding/result/news_summary_64_2006.json', encoding='utf-8')\n",
    "em_dict = json.load(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b224bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ke_vec_train = []\n",
    "ke_vec_test = []\n",
    "\n",
    "for index, row in kospi_train.iterrows():\n",
    "    a = em_dict[index].copy()\n",
    "    a.insert(0, row['Close'])\n",
    "    ke_vec_train.append(a)\n",
    "\n",
    "for index, row in kospi_test.iterrows():\n",
    "    a = em_dict[index].copy()\n",
    "    a.insert(0, row['Close'])\n",
    "    ke_vec_test.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141d13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1394.869995, 0.08540033549070358, -0.4674851894378662, -0.5362037420272827, -0.25901123881340027, -0.26654699444770813, 0.017446843907237053, 0.3900393843650818, 0.04290249943733215, 0.042930614203214645, -0.05205506831407547, 0.2535240948200226, -0.35728463530540466, -0.3169534206390381, -0.3042212724685669, -0.1683989018201828, 0.057889893651008606, 0.2807113230228424, -0.3238532245159149, 0.167076975107193, 0.08664888888597488, -0.49496519565582275, 0.07980471849441528, 0.1096445620059967, -0.028023697435855865, -0.09358430653810501, -0.30323222279548645, 0.5093612670898438, -0.19800728559494019, -0.3265606760978699, 0.1687026023864746, -0.31198549270629883, -0.46485716104507446, 0.34240132570266724, 0.022288605570793152, 0.16348792612552643, 0.09795103222131729, -0.29747506976127625, 0.10231968015432358, -0.30191770195961, -0.0827576071023941, -0.1480548083782196, -0.3621669411659241, -0.16694578528404236, 0.16708868741989136, 0.22266316413879395, -0.16095221042633057, 0.2952434718608856, -0.29723864793777466, 0.02061513625085354, 0.13731922209262848, 0.21450093388557434, 0.2377847582101822, 0.257647842168808, 0.44589346647262573, -0.20979905128479004, 0.5033661723136902, -0.4795709252357483, -0.07318859547376633, 0.41529878973960876, 0.36414727568626404, 0.007914000190794468, -0.20945754647254944, 0.2143191248178482, 0.13179931044578552] [2176.459961, 0.00754555594176054, -0.022922685369849205, 0.09754372388124466, 0.059170257300138474, -0.28968098759651184, -0.035869427025318146, 0.34742143750190735, 0.0739482194185257, 0.3929077088832855, -0.37612929940223694, 0.13636578619480133, -0.4178209900856018, -0.238460510969162, -0.03192814439535141, -0.17725145816802979, -0.06714872270822525, 0.06294499337673187, 0.21782153844833374, 0.3845929205417633, -0.21065841615200043, -0.09373984485864639, -0.21949857473373413, 0.2994770407676697, 0.12980444729328156, -0.2005622684955597, 0.27311548590660095, 0.2512895464897156, -0.02903573587536812, -0.40548941493034363, -0.34657353162765503, -0.371040403842926, -0.17418916523456573, 0.057474296540021896, -0.0016096080653369427, 0.30909815430641174, -0.5408772826194763, -0.20111533999443054, 0.004839339759200811, 0.004525921307504177, -0.14768166840076447, -0.06978046149015427, -0.4956618845462799, -0.08085911720991135, 0.008457441814243793, 0.5127493739128113, 0.3531882166862488, -0.10625842213630676, -0.2978626787662506, -0.024088839069008827, 0.07816101610660553, 0.23251552879810333, 0.04174691066145897, -0.25778865814208984, -0.0004083327658008784, -0.273910790681839, -0.17915822565555573, -0.19586989283561707, -0.17307980358600616, -0.11984800547361374, 0.5911785364151001, 0.01878845877945423, -0.006819161120802164, 0.3186325430870056, -0.022022614255547523]\n"
     ]
    }
   ],
   "source": [
    "print(ke_vec_train[0], ke_vec_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5262a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kospi_train_c1 = kospi_train['Change1']\n",
    "kospi_train_c1 = 100 * kospi_train_c1.values\n",
    "\n",
    "kospi_test_c1 = kospi_test['Change1']\n",
    "kospi_test_c1 = 100 * kospi_test_c1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20983e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_window = 60\n",
    "x_train_1, y_train_1 = [], []\n",
    "x_test_1, y_test_1 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60fe6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(ke_vec_train)-1):\n",
    "    x_train_1.append(ke_vec_train[i - lookback_window:i])\n",
    "    y_train_1.append(kospi_train_c1[i])\n",
    "    \n",
    "for index in range(len(y_train_1)):\n",
    "    if y_train_1[index] >= 0:\n",
    "        y_train_1[index] = 'increase'\n",
    "    else:\n",
    "        y_train_1[index] = 'decrease' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f1b8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3381, 60, 65) (3381,)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(x_train_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "print(x_train_1.shape, y_train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5fe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(ke_vec_test)-1):\n",
    "    x_test_1.append(ke_vec_test[i - lookback_window:i])\n",
    "    y_test_1.append(kospi_test_c1[i])\n",
    "    \n",
    "for index in range(len(y_test_1)):\n",
    "    if y_test_1[index] >= 0:\n",
    "        y_test_1[index] = 'increase'\n",
    "    else:\n",
    "        y_test_1[index] = 'decrease'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe4d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635, 60, 65) (635,)\n"
     ]
    }
   ],
   "source": [
    "x_test_1 = np.array(x_test_1)\n",
    "y_test_1 = np.array(y_test_1)\n",
    "print(x_test_1.shape, y_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4486d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3381, 2) (635, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_1)\n",
    "\n",
    "y_train_1_e = to_categorical(encoder.transform(y_train_1))\n",
    "y_test_1_e = to_categorical(encoder.transform(y_test_1))\n",
    "\n",
    "print(y_train_1_e.shape, y_test_1_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90d2ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 08:39:09.656383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 08:39:10.375277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22597 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:d5:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 100)               245600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,802\n",
      "Trainable params: 243,402\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_1 (TCN)                 (None, 100)               362100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 362,302\n",
      "Trainable params: 359,902\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_2 (TCN)                 (None, 100)               478600    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 478,802\n",
      "Trainable params: 476,402\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 65),\n",
    "        nb_filters=100,\n",
    "        kernel_size=2,\n",
    "        dilations=[1, 2, 4, 8, 16, 32],\n",
    "        use_batch_norm=True,\n",
    "        dropout_rate=0.2\n",
    "        ),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "###################################################################\n",
    "model_2 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 65),\n",
    "        nb_filters=100,\n",
    "        kernel_size=3,\n",
    "        dilations=[1, 2, 4, 8, 16, 32],\n",
    "        use_batch_norm=True,\n",
    "        dropout_rate=0.2\n",
    "        ),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.summary()\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "###################################################################\n",
    "model_3 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 65),\n",
    "        nb_filters=100,\n",
    "        kernel_size=4,\n",
    "        dilations=[1, 2, 4, 8, 16, 32],\n",
    "        use_batch_norm=True,\n",
    "        dropout_rate=0.2\n",
    "        ),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.summary()\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "573ee7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model_1...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 08:39:19.061487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "2023-02-08 08:39:23.519839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-08 08:39:23.621250: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f7c4d3002a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 08:39:23.621308: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): CUDA GPU, Compute Capability 8.6\n",
      "2023-02-08 08:39:23.627529: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-08 08:39:23.762444: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 39s 187ms/step - loss: 1.0508 - accuracy: 0.5155\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 5s 51ms/step - loss: 0.9216 - accuracy: 0.5072\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 5s 46ms/step - loss: 0.8094 - accuracy: 0.5140\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 5s 46ms/step - loss: 0.7806 - accuracy: 0.5102\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 5s 44ms/step - loss: 0.7587 - accuracy: 0.5111\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7362 - accuracy: 0.5075\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7263 - accuracy: 0.5081\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7159 - accuracy: 0.5200\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7144 - accuracy: 0.5188\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7082 - accuracy: 0.5188\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7081 - accuracy: 0.5170\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7017 - accuracy: 0.5194\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7045 - accuracy: 0.5173\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6966 - accuracy: 0.5285\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6984 - accuracy: 0.5149\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6988 - accuracy: 0.5211\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6989 - accuracy: 0.5120\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6968 - accuracy: 0.5129\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6958 - accuracy: 0.5129\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6950 - accuracy: 0.5271\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6959 - accuracy: 0.5223\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6910 - accuracy: 0.5353\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6918 - accuracy: 0.5318\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6908 - accuracy: 0.5288\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6965 - accuracy: 0.5217\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6941 - accuracy: 0.5232\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6918 - accuracy: 0.5241\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6925 - accuracy: 0.5256\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6922 - accuracy: 0.5300\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6909 - accuracy: 0.5288\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6911 - accuracy: 0.5377\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6904 - accuracy: 0.5359\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6898 - accuracy: 0.5336\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6902 - accuracy: 0.5241\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6911 - accuracy: 0.5416\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6891 - accuracy: 0.5383\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6889 - accuracy: 0.5392\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6891 - accuracy: 0.5368\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6883 - accuracy: 0.5433\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6883 - accuracy: 0.5560\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6880 - accuracy: 0.5457\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6877 - accuracy: 0.5492\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6858 - accuracy: 0.5498\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6875 - accuracy: 0.5460\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6852 - accuracy: 0.5569\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6858 - accuracy: 0.5534\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6846 - accuracy: 0.5593\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6839 - accuracy: 0.5572\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6871 - accuracy: 0.5534\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6836 - accuracy: 0.5629\n",
      "Train model_2...\n",
      "Epoch 1/50\n",
      "106/106 [==============================] - 21s 72ms/step - loss: 1.0584 - accuracy: 0.4981\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.8426 - accuracy: 0.5052\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7914 - accuracy: 0.4936\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7596 - accuracy: 0.5161\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7396 - accuracy: 0.5250\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7277 - accuracy: 0.4996\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7162 - accuracy: 0.5135\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7162 - accuracy: 0.5176\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7077 - accuracy: 0.5197\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7019 - accuracy: 0.5259\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6997 - accuracy: 0.5327\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6994 - accuracy: 0.5300\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7011 - accuracy: 0.5185\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6983 - accuracy: 0.5164\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6955 - accuracy: 0.5179\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6958 - accuracy: 0.5253\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6946 - accuracy: 0.5226\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6912 - accuracy: 0.5377\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6938 - accuracy: 0.5253\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6910 - accuracy: 0.5380\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6916 - accuracy: 0.5410\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6946 - accuracy: 0.5241\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6910 - accuracy: 0.5380\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6905 - accuracy: 0.5300\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6909 - accuracy: 0.5256\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6940 - accuracy: 0.5259\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6909 - accuracy: 0.5232\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6897 - accuracy: 0.5413\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6887 - accuracy: 0.5410\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6897 - accuracy: 0.5359\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6894 - accuracy: 0.5386\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6884 - accuracy: 0.5386\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6886 - accuracy: 0.5445\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6840 - accuracy: 0.5531\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 5s 44ms/step - loss: 0.6881 - accuracy: 0.5451\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6843 - accuracy: 0.5569\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6896 - accuracy: 0.5504\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6839 - accuracy: 0.5442\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6855 - accuracy: 0.5492\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6809 - accuracy: 0.5679\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6846 - accuracy: 0.5658\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6852 - accuracy: 0.5466\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6788 - accuracy: 0.5720\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6813 - accuracy: 0.5626\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6795 - accuracy: 0.5676\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6755 - accuracy: 0.5673\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6753 - accuracy: 0.5809\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6805 - accuracy: 0.5534\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 4s 43ms/step - loss: 0.6749 - accuracy: 0.5797\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6782 - accuracy: 0.5643\n",
      "Train model_3...\n",
      "Epoch 1/50\n",
      "106/106 [==============================] - 21s 71ms/step - loss: 1.0358 - accuracy: 0.5022\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.8873 - accuracy: 0.4960\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 5s 44ms/step - loss: 0.7905 - accuracy: 0.4978\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7583 - accuracy: 0.5235\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7317 - accuracy: 0.5268\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7245 - accuracy: 0.5179\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7321 - accuracy: 0.4969\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7079 - accuracy: 0.5238\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7122 - accuracy: 0.5170\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7051 - accuracy: 0.5149\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7033 - accuracy: 0.5161\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6998 - accuracy: 0.5220\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6994 - accuracy: 0.5188\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6972 - accuracy: 0.5226\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6965 - accuracy: 0.5167\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6927 - accuracy: 0.5339\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6955 - accuracy: 0.5158\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6924 - accuracy: 0.5182\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6933 - accuracy: 0.5250\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6931 - accuracy: 0.5214\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6927 - accuracy: 0.5268\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6911 - accuracy: 0.5342\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6907 - accuracy: 0.5280\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6938 - accuracy: 0.5321\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6907 - accuracy: 0.5274\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6912 - accuracy: 0.5294\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6897 - accuracy: 0.5398\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6909 - accuracy: 0.5232\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6899 - accuracy: 0.5282\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6893 - accuracy: 0.5386\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6888 - accuracy: 0.5419\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6900 - accuracy: 0.5395\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6878 - accuracy: 0.5424\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6867 - accuracy: 0.5516\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6873 - accuracy: 0.5424\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6834 - accuracy: 0.5510\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6810 - accuracy: 0.5682\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6819 - accuracy: 0.5623\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6786 - accuracy: 0.5608\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6774 - accuracy: 0.5691\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6729 - accuracy: 0.5791\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6773 - accuracy: 0.5652\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6716 - accuracy: 0.5800\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6724 - accuracy: 0.5800\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6710 - accuracy: 0.5806\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 5s 44ms/step - loss: 0.6690 - accuracy: 0.5880\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 5s 44ms/step - loss: 0.6690 - accuracy: 0.5827\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6644 - accuracy: 0.5954\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6688 - accuracy: 0.5844\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6685 - accuracy: 0.5912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83ac829af0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train model_1...')\n",
    "model_1.fit(x_train_1, y_train_1_e, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "print('Train model_2...')\n",
    "model_2.fit(x_train_1, y_train_1_e, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "print('Train model_3...')\n",
    "model_3.fit(x_train_1, y_train_1_e, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1183d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 100ms/step - loss: 1.0319 - accuracy: 0.4504\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.6848 - accuracy: 0.5496\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 0.7068 - accuracy: 0.4583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4582677185535431"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(x_test_1, y_test_1_e)[1]\n",
    "model_2.evaluate(x_test_1, y_test_1_e)[1]\n",
    "model_3.evaluate(x_test_1, y_test_1_e)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.05 / TensorFlow 2.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

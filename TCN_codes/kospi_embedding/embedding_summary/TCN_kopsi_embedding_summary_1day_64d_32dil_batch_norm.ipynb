{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c654451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tcn in /home/work/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tcn) (1.21.1)\n",
      "Requirement already satisfied: tensorflow in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-addons in /home/work/.local/lib/python3.8/site-packages (from keras-tcn) (0.19.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (3.19.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (1.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (22.12.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.29.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (63.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (21.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/work/.local/lib/python3.8/site-packages (from tensorflow->keras-tcn) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-tcn) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->keras-tcn) (3.0.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-tcn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: finance-datareader in /home/work/.local/lib/python3.8/site-packages (0.9.50)\n",
      "Requirement already satisfied: requests-file in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.5.0)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/work/.local/lib/python3.8/site-packages (from finance-datareader) (1.5.2)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from finance-datareader) (4.64.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (3.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from requests-file->finance-datareader) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn\n",
    "!pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ffe65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "2023-02-08 08:06:08.115617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 08:06:08.403679: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-08 08:06:12.622334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-02-08 08:06:12.622650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/usr/include/x86_64-linux-gnu\n",
      "2023-02-08 08:06:12.622679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452f7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2006-01-03  1393.140015  1394.920044  1376.170044  1394.869995  1394.869995   \n",
      "2006-01-04  1408.189941  1412.150024  1400.079956  1402.109985  1402.109985   \n",
      "2006-01-05  1405.310059  1405.310059  1378.959961  1395.510010  1395.510010   \n",
      "2006-01-06  1399.229980  1412.790039  1395.260010  1412.780029  1412.780029   \n",
      "2006-01-09  1421.900024  1421.900024  1405.050049  1408.329956  1408.329956   \n",
      "\n",
      "              Volume   Change1  \n",
      "Date                            \n",
      "2006-01-03  541300.0  0.004031  \n",
      "2006-01-04  528000.0  0.005190  \n",
      "2006-01-05  538100.0 -0.004707  \n",
      "2006-01-06  587900.0  0.012375  \n",
      "2006-01-09  531500.0 -0.003150  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1'], dtype='object')\n",
      "(3442, 7)\n"
     ]
    }
   ],
   "source": [
    "kospi_train = fdr.DataReader('KS11', '2006-01-01','2019-12-31')\n",
    "kospi_train['Change1'] = kospi_train['Close']/kospi_train['Close'].shift(1) - 1\n",
    "\n",
    "kospi_train = kospi_train.dropna()\n",
    "print(kospi_train.head())\n",
    "print(kospi_train.columns)\n",
    "print(kospi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c875dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2020-01-03  2192.580078  2203.379883  2165.389893  2176.459961  2176.459961   \n",
      "2020-01-06  2154.969971  2164.419922  2149.949951  2155.070068  2155.070068   \n",
      "2020-01-07  2166.600098  2181.620117  2164.270020  2175.540039  2175.540039   \n",
      "2020-01-08  2156.270020  2162.320068  2137.719971  2151.310059  2151.310059   \n",
      "2020-01-09  2182.199951  2186.449951  2172.159912  2186.449951  2186.449951   \n",
      "\n",
      "            Volume   Change1  \n",
      "Date                          \n",
      "2020-01-03  631600  0.000593  \n",
      "2020-01-06  592700 -0.009828  \n",
      "2020-01-07  568200  0.009499  \n",
      "2020-01-08  913800 -0.011137  \n",
      "2020-01-09  592600  0.016334  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Change1'], dtype='object')\n",
      "(696, 7)\n"
     ]
    }
   ],
   "source": [
    "kospi_test = fdr.DataReader('KS11', '2020-01-01','2022-10-31')\n",
    "kospi_test['Change1'] = kospi_test['Close']/kospi_test['Close'].shift(1) - 1\n",
    "\n",
    "kospi_test = kospi_test.dropna()\n",
    "print(kospi_test.head())\n",
    "print(kospi_test.columns)\n",
    "print(kospi_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44840c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2006-01-03', '2006-01-04', '2006-01-05', '2006-01-06', '2006-01-09',\n",
      "       '2006-01-10', '2006-01-11', '2006-01-12', '2006-01-13', '2006-01-16',\n",
      "       ...\n",
      "       '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20',\n",
      "       '2019-12-23', '2019-12-24', '2019-12-26', '2019-12-27', '2019-12-30'],\n",
      "      dtype='object', name='Date', length=3442)\n",
      "Index(['2020-01-03', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09',\n",
      "       '2020-01-10', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16',\n",
      "       ...\n",
      "       '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21', '2022-10-24',\n",
      "       '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', '2022-10-31'],\n",
      "      dtype='object', name='Date', length=696)\n"
     ]
    }
   ],
   "source": [
    "kospi_train.index = kospi_train.index.strftime('%Y-%m-%d')\n",
    "print(kospi_train.index)\n",
    "\n",
    "kospi_test.index = kospi_test.index.strftime('%Y-%m-%d')\n",
    "print(kospi_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4237d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "embedding = open('/home/work/nlp/embedding/result/news_summary_64_2006.json', encoding='utf-8')\n",
    "em_dict = json.load(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b224bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ke_vec_train = []\n",
    "ke_vec_test = []\n",
    "\n",
    "for index, row in kospi_train.iterrows():\n",
    "    a = em_dict[index].copy()\n",
    "    a.insert(0, row['Close'])\n",
    "    ke_vec_train.append(a)\n",
    "\n",
    "for index, row in kospi_test.iterrows():\n",
    "    a = em_dict[index].copy()\n",
    "    a.insert(0, row['Close'])\n",
    "    ke_vec_test.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141d13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1394.869995, 0.08540033549070358, -0.4674851894378662, -0.5362037420272827, -0.25901123881340027, -0.26654699444770813, 0.017446843907237053, 0.3900393843650818, 0.04290249943733215, 0.042930614203214645, -0.05205506831407547, 0.2535240948200226, -0.35728463530540466, -0.3169534206390381, -0.3042212724685669, -0.1683989018201828, 0.057889893651008606, 0.2807113230228424, -0.3238532245159149, 0.167076975107193, 0.08664888888597488, -0.49496519565582275, 0.07980471849441528, 0.1096445620059967, -0.028023697435855865, -0.09358430653810501, -0.30323222279548645, 0.5093612670898438, -0.19800728559494019, -0.3265606760978699, 0.1687026023864746, -0.31198549270629883, -0.46485716104507446, 0.34240132570266724, 0.022288605570793152, 0.16348792612552643, 0.09795103222131729, -0.29747506976127625, 0.10231968015432358, -0.30191770195961, -0.0827576071023941, -0.1480548083782196, -0.3621669411659241, -0.16694578528404236, 0.16708868741989136, 0.22266316413879395, -0.16095221042633057, 0.2952434718608856, -0.29723864793777466, 0.02061513625085354, 0.13731922209262848, 0.21450093388557434, 0.2377847582101822, 0.257647842168808, 0.44589346647262573, -0.20979905128479004, 0.5033661723136902, -0.4795709252357483, -0.07318859547376633, 0.41529878973960876, 0.36414727568626404, 0.007914000190794468, -0.20945754647254944, 0.2143191248178482, 0.13179931044578552] [2176.459961, 0.00754555594176054, -0.022922685369849205, 0.09754372388124466, 0.059170257300138474, -0.28968098759651184, -0.035869427025318146, 0.34742143750190735, 0.0739482194185257, 0.3929077088832855, -0.37612929940223694, 0.13636578619480133, -0.4178209900856018, -0.238460510969162, -0.03192814439535141, -0.17725145816802979, -0.06714872270822525, 0.06294499337673187, 0.21782153844833374, 0.3845929205417633, -0.21065841615200043, -0.09373984485864639, -0.21949857473373413, 0.2994770407676697, 0.12980444729328156, -0.2005622684955597, 0.27311548590660095, 0.2512895464897156, -0.02903573587536812, -0.40548941493034363, -0.34657353162765503, -0.371040403842926, -0.17418916523456573, 0.057474296540021896, -0.0016096080653369427, 0.30909815430641174, -0.5408772826194763, -0.20111533999443054, 0.004839339759200811, 0.004525921307504177, -0.14768166840076447, -0.06978046149015427, -0.4956618845462799, -0.08085911720991135, 0.008457441814243793, 0.5127493739128113, 0.3531882166862488, -0.10625842213630676, -0.2978626787662506, -0.024088839069008827, 0.07816101610660553, 0.23251552879810333, 0.04174691066145897, -0.25778865814208984, -0.0004083327658008784, -0.273910790681839, -0.17915822565555573, -0.19586989283561707, -0.17307980358600616, -0.11984800547361374, 0.5911785364151001, 0.01878845877945423, -0.006819161120802164, 0.3186325430870056, -0.022022614255547523]\n"
     ]
    }
   ],
   "source": [
    "print(ke_vec_train[0], ke_vec_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5262a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kospi_train_c1 = kospi_train['Change1']\n",
    "kospi_train_c1 = 100 * kospi_train_c1.values\n",
    "\n",
    "kospi_test_c1 = kospi_test['Change1']\n",
    "kospi_test_c1 = 100 * kospi_test_c1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20983e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_window = 60\n",
    "x_train_1, y_train_1 = [], []\n",
    "x_test_1, y_test_1 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60fe6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(ke_vec_train)-1):\n",
    "    x_train_1.append(ke_vec_train[i - lookback_window:i])\n",
    "    y_train_1.append(kospi_train_c1[i])\n",
    "    \n",
    "for index in range(len(y_train_1)):\n",
    "    if y_train_1[index] >= 0:\n",
    "        y_train_1[index] = 'increase'\n",
    "    else:\n",
    "        y_train_1[index] = 'decrease' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f1b8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3381, 60, 65) (3381,)\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = np.array(x_train_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "print(x_train_1.shape, y_train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5fe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lookback_window, len(ke_vec_test)-1):\n",
    "    x_test_1.append(ke_vec_test[i - lookback_window:i])\n",
    "    y_test_1.append(kospi_test_c1[i])\n",
    "    \n",
    "for index in range(len(y_test_1)):\n",
    "    if y_test_1[index] >= 0:\n",
    "        y_test_1[index] = 'increase'\n",
    "    else:\n",
    "        y_test_1[index] = 'decrease'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe4d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635, 60, 65) (635,)\n"
     ]
    }
   ],
   "source": [
    "x_test_1 = np.array(x_test_1)\n",
    "y_test_1 = np.array(y_test_1)\n",
    "print(x_test_1.shape, y_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4486d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3381, 2) (635, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_1)\n",
    "\n",
    "y_train_1_e = to_categorical(encoder.transform(y_train_1))\n",
    "y_test_1_e = to_categorical(encoder.transform(y_test_1))\n",
    "\n",
    "print(y_train_1_e.shape, y_test_1_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90d2ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 08:06:21.055396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 08:06:21.791464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22597 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:d5:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 100)               245600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,802\n",
      "Trainable params: 243,402\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_1 (TCN)                 (None, 100)               362100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 362,302\n",
      "Trainable params: 359,902\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn_2 (TCN)                 (None, 100)               478600    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 478,802\n",
      "Trainable params: 476,402\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 65),\n",
    "        nb_filters=100,\n",
    "        kernel_size=2,\n",
    "        dilations=[1, 2, 4, 8, 16, 32],\n",
    "        use_batch_norm=True\n",
    "        ),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.summary()\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "###################################################################\n",
    "model_2 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 65),\n",
    "        nb_filters=100,\n",
    "        kernel_size=3,\n",
    "        dilations=[1, 2, 4, 8, 16, 32],\n",
    "        use_batch_norm=True\n",
    "        ),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.summary()\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "###################################################################\n",
    "model_3 = Sequential([\n",
    "    TCN(input_shape=(lookback_window, 65),\n",
    "        nb_filters=100,\n",
    "        kernel_size=4,\n",
    "        dilations=[1, 2, 4, 8, 16, 32],\n",
    "        use_batch_norm=True\n",
    "        ),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.summary()\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "573ee7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model_1...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 08:06:30.083117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "2023-02-08 08:06:33.887125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-08 08:06:33.982429: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1e887e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 08:06:33.982490: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): CUDA GPU, Compute Capability 8.6\n",
      "2023-02-08 08:06:33.988574: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-08 08:06:34.115727: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 46s 258ms/step - loss: 0.8337 - accuracy: 0.4957\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 5s 46ms/step - loss: 0.7655 - accuracy: 0.4898\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7429 - accuracy: 0.5004\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7283 - accuracy: 0.5031\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7197 - accuracy: 0.5052\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7182 - accuracy: 0.5223\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7282 - accuracy: 0.5155\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.7121 - accuracy: 0.5206\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 4s 38ms/step - loss: 0.7177 - accuracy: 0.5090\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.7037 - accuracy: 0.5235\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.7151 - accuracy: 0.5114\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.7070 - accuracy: 0.5214\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7083 - accuracy: 0.5135\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6978 - accuracy: 0.5309\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7057 - accuracy: 0.5291\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7076 - accuracy: 0.5271\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7026 - accuracy: 0.5398\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6968 - accuracy: 0.5451\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6991 - accuracy: 0.5368\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.7080 - accuracy: 0.5368\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7022 - accuracy: 0.5336\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6987 - accuracy: 0.5294\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6962 - accuracy: 0.5380\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6972 - accuracy: 0.5427\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6993 - accuracy: 0.5386\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6955 - accuracy: 0.5519\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6924 - accuracy: 0.5490\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6902 - accuracy: 0.5620\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6885 - accuracy: 0.5546\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6890 - accuracy: 0.5424\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6815 - accuracy: 0.5705\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6923 - accuracy: 0.5560\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6930 - accuracy: 0.5549\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6842 - accuracy: 0.5626\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6903 - accuracy: 0.5608\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6870 - accuracy: 0.5631\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6824 - accuracy: 0.5735\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6884 - accuracy: 0.5590\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6811 - accuracy: 0.5738\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6854 - accuracy: 0.5691\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6773 - accuracy: 0.5794\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6822 - accuracy: 0.5682\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6813 - accuracy: 0.5593\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6732 - accuracy: 0.5874\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6753 - accuracy: 0.5824\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6728 - accuracy: 0.5909\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6811 - accuracy: 0.5723\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6756 - accuracy: 0.5824\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6820 - accuracy: 0.5676\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6783 - accuracy: 0.5871\n",
      "Train model_2...\n",
      "Epoch 1/50\n",
      "106/106 [==============================] - 25s 86ms/step - loss: 0.8548 - accuracy: 0.5211\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7587 - accuracy: 0.5081\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7335 - accuracy: 0.5084\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7480 - accuracy: 0.5164\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7195 - accuracy: 0.5188\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7187 - accuracy: 0.5173\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7118 - accuracy: 0.5291\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7208 - accuracy: 0.5188\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7074 - accuracy: 0.5327\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.7097 - accuracy: 0.5179\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7060 - accuracy: 0.5294\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7039 - accuracy: 0.5309\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7071 - accuracy: 0.5229\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6990 - accuracy: 0.5282\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7086 - accuracy: 0.5194\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7038 - accuracy: 0.5333\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6960 - accuracy: 0.5472\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6945 - accuracy: 0.5451\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6847 - accuracy: 0.5623\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6901 - accuracy: 0.5380\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6827 - accuracy: 0.5702\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6896 - accuracy: 0.5543\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6824 - accuracy: 0.5676\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6854 - accuracy: 0.5667\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6874 - accuracy: 0.5640\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6854 - accuracy: 0.5528\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6815 - accuracy: 0.5806\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6786 - accuracy: 0.5830\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6807 - accuracy: 0.5827\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6825 - accuracy: 0.5658\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6751 - accuracy: 0.5901\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 5s 42ms/step - loss: 0.6830 - accuracy: 0.5779\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6845 - accuracy: 0.5720\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6763 - accuracy: 0.5827\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.6684 - accuracy: 0.5924\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6661 - accuracy: 0.5889\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6598 - accuracy: 0.6019\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6624 - accuracy: 0.6049\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6622 - accuracy: 0.5972\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6652 - accuracy: 0.5998\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6601 - accuracy: 0.6122\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6560 - accuracy: 0.6128\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6569 - accuracy: 0.6102\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6535 - accuracy: 0.6146\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6546 - accuracy: 0.6090\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6687 - accuracy: 0.5871\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6587 - accuracy: 0.5983\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6508 - accuracy: 0.6117\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6522 - accuracy: 0.6158\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6449 - accuracy: 0.6220\n",
      "Train model_3...\n",
      "Epoch 1/50\n",
      "106/106 [==============================] - 23s 83ms/step - loss: 0.8704 - accuracy: 0.4996\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7624 - accuracy: 0.5149\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7233 - accuracy: 0.5090\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7154 - accuracy: 0.5149\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7493 - accuracy: 0.5087\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7218 - accuracy: 0.5241\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 5s 43ms/step - loss: 0.7093 - accuracy: 0.5211\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7158 - accuracy: 0.5214\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7110 - accuracy: 0.5211\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7136 - accuracy: 0.5209\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6949 - accuracy: 0.5383\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7224 - accuracy: 0.5170\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.7049 - accuracy: 0.5300\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6946 - accuracy: 0.5353\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7001 - accuracy: 0.5436\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6908 - accuracy: 0.5492\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6991 - accuracy: 0.5504\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6938 - accuracy: 0.5427\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6902 - accuracy: 0.5617\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6792 - accuracy: 0.5800\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.7007 - accuracy: 0.5558\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6918 - accuracy: 0.5560\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6667 - accuracy: 0.5998\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6800 - accuracy: 0.5735\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6750 - accuracy: 0.5904\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6758 - accuracy: 0.5762\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6685 - accuracy: 0.5871\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6727 - accuracy: 0.5844\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6824 - accuracy: 0.5732\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6772 - accuracy: 0.5856\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6610 - accuracy: 0.6090\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6635 - accuracy: 0.6010\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6577 - accuracy: 0.6105\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6608 - accuracy: 0.6087\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6616 - accuracy: 0.6034\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6557 - accuracy: 0.6155\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6747 - accuracy: 0.5921\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6660 - accuracy: 0.5812\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6605 - accuracy: 0.5998\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6663 - accuracy: 0.5921\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6542 - accuracy: 0.6267\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6398 - accuracy: 0.6276\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6505 - accuracy: 0.6235\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6368 - accuracy: 0.6223\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 4s 41ms/step - loss: 0.6451 - accuracy: 0.6247\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6440 - accuracy: 0.6273\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 4s 40ms/step - loss: 0.6337 - accuracy: 0.6421\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6364 - accuracy: 0.6436\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 4s 42ms/step - loss: 0.6325 - accuracy: 0.6353\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 4s 39ms/step - loss: 0.6456 - accuracy: 0.6306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63605eb340>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train model_1...')\n",
    "model_1.fit(x_train_1, y_train_1_e, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "print('Train model_2...')\n",
    "model_2.fit(x_train_1, y_train_1_e, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "print('Train model_3...')\n",
    "model_3.fit(x_train_1, y_train_1_e, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bcbb0",
   "metadata": {},
   "source": [
    "model_1.evaluate(x_test_1, y_test_1_e)[1]\n",
    "model_2.evaluate(x_test_1, y_test_1_e)[1]\n",
    "model_3.evaluate(x_test_1, y_test_1_e)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (NGC 22.05 / TensorFlow 2.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
